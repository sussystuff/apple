com.apple.corespeechd
<?xml version="1.0"encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC"-// Apple //DTD PLIST 1.0//EN""http://www.apple.com/DTDs/Property List-1.0.dtd">
<plist version="1.0">
<dict>
	<key>application-identifier</key>
	<string></string>
	<key>com.apple.airplay.carplayavvc</key>
	<true/>>
	<key>com.apple.assistant.analytics</key>
	<true/>
	<key>com.apple.assistant.client</key>
	<true/>>
	<key>com.apple.assistant.dictation.prerecorded</key>
	<true/>
	<key>com.apple.assistant.multiuser.service</key>
	<true/>
	<key>com.apple.assistant.settings</key>
	<true/>
	<key>com.apple.avfoundation.allow-system-wide-context</key>
	<true/>
	<key>com.apple.avfoundation.allows-access-to-device-list</key>
	<true/>
	<key>com.apple.bluetooth.system</key>
	<true/>>
	<key>com.apple.callkit</key>
	<array>
		<string>private-controller-api</string>
	</array>
	<key>com.apple.coreaudio.CanRecordPastData</key>
	<true/>
	<key>com.apple.coreaudio.CanRecordWithoutSessionActivation</key>
	<true/>>
	<key>com.apple.coreaudio.i-am-siri</key>
	<true/>
	<key>com.apple.coreaudio.register-internal-aus</key>
	<true/>
	<key>com.apple.coreduetd.context</key>
	<true/>
	<key>com.apple.corespeech.cat.xpc</key>
	<true/>
	<key>com.apple.hid.system.user-access-fast-path</key>
	<true/>
	<key>com.apple.homepodaccessorysettings.client</key>
	<true/>
	<key>com.apple.managedconfiguration.profiled.profile-list-read</key>
	<true/>
	<key>com.apple.nano.nanoregistry.generalaccess</key>
	<true/>
	<key>com.apple.private.DistributedEvaluation.RecordAccess-com.apple.fides.asr</key>
	<true/>
	<key>com.apple.private.DistributedEvaluation.RecordAccess-com.apple.fides.borealis</key>
	<true/>
	<key>com.apple.private.DistributedEvaluation.RecordAccess-com.apple.fides.phs</key>
	<true/>
	<key>com.apple.private.Shazamkit</key>
	<true/>
	<key>com.apple.private.assets.accessible-asset-types</key>
	<array>
		<string>com.apple.MobileAsset.Trial.Siri.SiriUnderstandingAsrUaap</string>
		<string>com.apple.MobileAsset.Trial.Siri.SiriUnderstandingAsrAssistant</string> 
		<string>com.apple.MobileAsset.Trial.Siri.SiriUnderstandingAsrHammer</string>
		<string>com.apple.MobileAsset.Trial.Siri.SiriDictationAssets</string>
		<string>com.apple.MobileAsset.Trial.Siri.SiriUnderstandingAttentionAssets</string>
		<string>com.apple.MobileAsset.AdBlockerAssets</string>
		<string>com.apple.MobileAsset.VoiceTriggerAssets</string>
		<string>com.apple.MobileAsset.VoiceTriggerAssetsIPad</string>
		<string>com.apple.MobileAsset.VoiceTriggerAssetsWatch</string>
		<string>com.apple.MobileAsset.VoiceTriggerAssetsMarsh</string>
		<string>com.apple.MobileAsset.VoiceTriggerAssetsTV</string>
		<string>com.apple.MobileAsset.SpeechEndpointAssets</string>
		<string>com.apple.MobileAsset.SpeechEndpointAssetsWatch</string>
		<string>com.apple.MobileAsset.SpeechEndpointAssets TV</string>
		<string>com.apple.MobileAsset.RaiseToSpeakAssets</string>
		<string>com.apple.MobileAsset.VoiceTriggerAssetsMac</string> 
		<string>com.apple.MobileAsset.SpeakerRecognitionAssets</string>
		<string>com.apple.MobileAsset.EmbeddedSpeech</string>
		<string>com.apple.MobileAsset.VoiceTriggerHSAssets</string>
		<string>com.apple.MobileAsset.VoiceTriggerHSAssetsIPad</string>
		<string>com.apple.MobileAsset.Voice TriggerHSAssetsWatch</string>
	</array>
	<key>com.apple.private.assets.bypass-asset-types-check</key>
	<true/>
	<key>com.apple.private.attentionawareness</key>
	<true/>
	<key>com.apple.private.attentionawareness.samplewhileabsent</key>
	<true/>
	<key>com.apple.private.attribution.implicitly-assumed-identity</key>
	<dict>
	<key>type</key>
	<string>path</string>
	<key>value</key>
	<string>/System/Library/PrivateFrameworks/CoreSpeech.framework/corespeechd</string>
	</dict>
	<key>com.apple.private.audio.dark-wake-audio</key>
	<true/>
	<key>com.apple.private.audio.hal.aop-audio.user-access</key>
	<true/>
	<key>com.apple.private.audio.notification-wake-audio</key>
	<true/>
	<key>com.apple.private.audio.suppress-mic-indicator</key>
	<true/>
	<key>com.apple.private.avfoundation.capture.nonstandard-client.allow</key>
	<true/>
	<key>com.apple.private.avfoundation.capture.nonstandard-client.allowed-media-types</key>
	<dict>
	<key>AVMediaTypeMetadataObject</key>
	<array>
		<string>AVMetadataObjectTypeTrackedFaces</string>
	</array>
	</dict>
	<key>com.apple.private.biome.client-identifier</key>
	<string>com.apple.corespeechd</string>
	<key>com.apple.private.biome.read-only</key>
	<string>Dictation.UserEdit</string>
	<key>com.apple.private.biome.read-write</key>
	<string>Siri.VoiceTriggerStatistics</string>
	<key>com.apple.private.bmk.allow</key>
	<true/>
	<key>com.apple.private.coreaudio.viewInterruptorName.allow</key>
	<true/>
	<key>com.apple.private.corespeech.xpc.remote</key>
	<true/>
	<key>com.apple.private.corespeechd.activation</key>
	<true/>
	<key>com.apple.private.healthkit</key>
	<true/>>
	<key>com.apple.private.healthkit.medicaliddata</key>
	<true/>
	<key>com.apple.private.hid.client.event-monitor</key>
	<true/>
	<key>com.apple.private.homehubd</key>
	<array>
		<string>endpoint-read</string>
	</array>
	<key>com.apple.private.homekit.siri-audio-connection</key>
	<true/>
	<key>com.apple.private.iokit.darkwake-control</key>
	<true/>
	<key>com.apple.private.mediaexperience.allowrecording duringcall</key>
	<true/>
	<key>com.apple.private.media safetynet.exception.announcemessage</key>
	<true/>
	<key>com.apple.private.mobiletimerd</key>
	<true/>
	<key>com.apple.private.siri.activation</key>
	<true/>
	<key>com.apple.private.siri.invoke</key>
	<true/>
	<key>com.apple.private.speech-model-training</key>
	<true/>
	<key>com.apple.private.tcc.allow</key>
	<array>
		<string>KTCCService Microphone</string>
		<string>KTCCServiceCamera</string>
	</array>
	<key>com.apple.private.tcc.manager.access.read</key>
	<array>
		<string>KTCCServiceAll</string>
	</array>
	<key>com.apple.proactive.eventtracker</key>
	<true/>
	<key>com.apple.rootless.storage.CoreSpeech</key>
	<true/>
	<key>com.apple.runningboard.assertions.appshack</key>
	<true/>
	<key>com.apple.security.exception.files.absolute-path.read-only</key>
	<array>
		<string>/private/var/MobileAsset/</string>
		<string>/Library/Audio/Tunings/</string>
	</array>
	<key>com.apple.security.exception.files.home-relative-path.read-only</key>
	<array>
		<string>/Library/Caches/com.apple.corespeech.cat.xpc/</string>
	</array>
	<key>com.apple.security.exception.files.home-relative-path.read-write</key>
	<array>
		<string>/Library/VoiceTrigger/</string>
		<string>/Library/Logs/CrashReporter/Assistant/</string>
		<string>/Library/Logs/CrashReporter/VoiceTrigger/</string>
		<string>/Library/Logs/CrashReporter/ssr/</string>
		<string>/Library/Logs/CrashReporter/Core Speech/</string>
		<string>/Library/Logs/CrashReporter/RTS/</string>
		<string>/Library/Caches/VoiceTrigger/</string>
		<string>/Library/Caches/com.apple.core speechd/</string>
		<string>/Documents/Logs/CoreSpeech/</string>
		<string>/Library/Assistant/</string>
	</array>
	<key>com.apple.security.exception.iokit-user-client-class</key>
	<array>
		<string>AppleSPUHIDDriverUserClient</string>
		<string>IOHIDEvent Service FastPathUserClient</string>
		<string>AGXDeviceUserClient</string>
		<string>IOSurfaceRootUserClient</string>
		<string>AGXSharedUserClient</string>
		<string>AGXCommandQueue</string>
		<string>AGXDevice</string>
		<string>H11ANEInDirectPathClient</string>
	</array>
	<key>com.apple.security.exception.mach-lookup.global-name</key>
	<array>
		<string>com.apple.telephonyutilities.callservicesdaemon.conversationprovidermanager</string>
		<string>com.apple.telephonyutilities.callservicesdaemon.callprovidermanager</string>
		<string>com.apple.telephonyutilities.callservicesdaemon.callcapabilities</string>
		<string>com.apple.telephonyutilities.callservicesdaemon.callstatecontroller</string>
		<string>com.apple.telephonyutilities.callservicesdaemon.conversationmanager</string>
		<string>com.apple.sirittsd</string>
		<string>com.apple.carousel.backlightxpc</string>
		<string>com.apple.usernotifications.usernotificationservice</string>
		<string>com.apple.frontboard.systemappservices</string>
		<string>com.apple.mobile asset.autoasset</string>
		<string>com.apple.assistant.settings</string>
		<string>com.apple.MobileTimer.timerserver</string>
		<string>com.apple.MobileTimer.alarmserver</string>
		<string>com.apple.audio.voice trigger.xpc</string>
		<string>com.apple.audio.AudioComponentRegistrar</string>
		<string>com.apple.voicetrigger.voicetriggerservice</string>
		<string>com.apple.audio.AudioQueueServer</string>
		<string>com.apple.server.bluetooth</string>
		<string>com.apple.SystemConfiguration.NetworkInformation</string>
		<string>com.apple.mediaremoted.xpc</string>
		<string>com.apple.coremedia.carplayavvc.xpc</string>
		<string>com.apple.iohideventsystem</string>
		<string>com.apple.siri.activation</string>
		<string>com.apple.siri.activation.horseman</string>
		<string>com.apple.siri.activation.blackbird</string>
		<string>com.apple.assistant.analytics</string>
		<string>com.apple.audio.SystemSoundServer-iOS</string>
		<string>com.apple.BTLEAudioController.xpc</string>
		<string>com.apple.healthd.server</string>
		<string>com.apple.SystemConfiguration.configd</string>
		<string>com.apple.managed configuration.profiled</string>
		<string>com.apple.locationd.registration</string>
		<string>com.apple.backlightd</string>
		<string>com.apple.carousel.wakegesturemonitor</string>
		<string>com.apple.homekit.audio.xpc</string>
		<string>com.apple.SBUserNotification</string>
		<string>com.apple.nsurlsessiond.NSURLSessionProxyService</string>
		<string>com.apple.nsurlstorage-cache</string>
		<string>com.apple.commcenter.xpc</string>
		<string>com.apple.mediasafetynet.exceptions</string>
		<string>com.apple.symptom_diagnostics</string>
		<string>com.apple.corespeech.mockremoteplugin.xpc</string>
		<string>com.apple.systemstatus.activityattribution</string>
		<string>com.apple.assistant.multiuser.service</string>
		<string>com.apple.callkit.callcontrollerhost</string>
		<string>com.apple.siri.morphunassetsupdaterd</string>
		<string>com.apple.homehubd.manage</string>
		<string>com.apple.AttentionAwareness</string>
		<string>com.apple.corespeech.speechmodeltraining.xpc</string>
		<string>com.apple.siri.analytics.assistant</string>
		<string>com.apple.remoted</string>
		<string>com.apple.Pairing Manager</string>
		<string>com.apple.biome.access.system</string>
		<string>com.apple.biome.access.user</string>
		<string>com.apple.homepodaccessorysettings.server</string>
	</array>
	<key>com.apple.security.exception.shared-preference.read-only</key>
	<array>
		<string>com.apple.assistant</string>
		<string>com.apple.nano</string>
		<string>com.apple.raisetospeak</string>
		<string>com.apple.assistant.backedup</string>
		<string>com.apple.assistant.support</string>
		<string>com.apple.CoreMotion</string>
		<string>com.apple.airplay</string>
		<string>com.apple.mediaremote</string>
	</array>
	<key>com.apple.security.exception.shared-preference.read-write</key>
	<array>
		<string>com.apple.niservices</string>
		<string>com.apple.voice trigger</string>
		<string>com.apple.voicetrigger.notbackedup</string>
		<string>com.apple.avfoundation.avvc</string>
		<string>com.apple.audio.virtualaudio</string>
		<string>com.apple.speakerrecognition</string>
		<string>com.apple.coreaudio</string>
		<string>com.apple.coremedia</string>
		<string>com.apple.raisetospeak</string>
	</array>
	<key>com.apple.security.exception.sysctl.read-only</key>
	<array>
		<string>net.routetable.0.0.3.0</string>
	</array>
	<key>com.apple.security.ts.ane-client </key>
	<true/>
	<key>com.apple.security.ts.mobile-keybag-access </key>
	<true/>
	<key>com.apple.security.ts.opengl-or-metal</key>
	<true/>
	<key>com.apple.security.ts.play-audio</key>
	<true/
	<key>com.apple.security.ts.play-media</key>
	<true/>
	<key>com.apple.security.ts.power-assertions</key>
	<true/>
	<key>com.apple.security.ts.read-any-bundle</key>
	<true/>
	<key>com.apple.security.ts.tmpdir</key>
	<string></string>
	<key>com.apple.sensorkit.writer.allow</key>
	<array>
		<string>com.apple.Sensorkit.speechMetrics.siri</string>
		<string>com.apple.Sensorkit.speechEmotion.siri</string>
		<string>com.apple.Sensorkit.soundDetection.siri</string>
	</array>
	<key>com.apple.siri.activation</key>
	<true/>
	<key>com.apple.siri.embeddedspeech</key>
	<true/>
	<key>com.apple.siri.external_request</key>
	<true/>
	<key>com.apple.systemstatus.activityattribution</key>
	<true/>
	<key>com.apple.systemstatus.publisher.domains</key>
	<array>
		<string>media</string>
	</array>
	<key>com.apple.telephonyutilities.callservicesd</key>
	<array>
		<string>access-calls</string>
		<string>access-call-providers</string>
	</array>
	<key>com.apple.trial.client</key>
	<array>
		<string>200</string>
		<string>322</string>
		<string>404</string>
		<string>372</string>
		<string>401</string>
		<string>751</string>
		<string>756</string>
		<string>757</string>
	</array>
	<key>com.apple.voicetrigger.voice triggerservice</key>
	<true/>
	<key>keychain-access-groups</key>
	<array>
		<string>com.apple.corespeech</string>
	</array>
	<key>platform-application</key>
	<true/>
	<key>seatbelt-profiles</key>
	<array>
		<string>temporary-sandbox</string>
	</array>
</dict>
</plist>


/System/Library/Frameworks/Foundation.framework/Versions/C/Foundation
/System/Library/Frameworks/AVFAudio.framework/Versions/A/AVFAudio
/System/Library/Frameworks/AudioToolbox.framework/Versions/A/AudioToolbox
/System/Library/PrivateFrameworks/AssistantServices.framework/Versions/A/AssistantServices
/System/Library/PrivateFrameworks/MobileAsset.framework/Versions/A/MobileAsset
/System/Library/Frameworks/Accelerate.framework/Versions/A/Accelerate
/System/Library/PrivateFrameworks/MediaRemote.framework/Versions/A/MediaRemote
/System/Library/PrivateFrameworks/IDS.framework/Versions/A/IDS
/System/Library/PrivateFrameworks/MobileBluetooth.framework/Versions/A/MobileBluetooth
/System/Library/PrivateFrameworks/CoreAnalytics.framework/Versions/A/CoreAnalyticsx/System/Library/PrivateFrameworks/Speaker Recognition.framework/Versions/A/SpeakerRecognition
/System/Library/Frameworks/IOKit.framework/Versions/A/IOKit
/usr/lib/libcompression.dylib
/System/Library/PrivateFrameworks/CoreSpeechFoundation.framework/Versions/A/CoreSpeechFoundation
/System/Library/PrivateFrameworks/SiriInstrumentation.framework/Versions/A/SiriInstrumentation/System/Library/Frameworks/CoreAudio.framework/Versions/A/CoreAudio
/System/Library/PrivateFrameworks/MobileKeyBag.framework/Versions/A/MobileKeyBag
/System/Library/PrivateFrameworks/CrashReporterSupport.framework/Versions/A/CrashReporterSupport
/System/Library/PrivateFrameworks/VoiceTrigger.framework/Versions/A/VoiceTriggerh/System/Library/Frameworks/SoundAnalysis.framework/Versions/A/SoundAnalysis
/System/Library/PrivateFrameworks/MediaExperience.framework/Versions/A/MediaExperience/System/Library/PrivateFrameworks/EmbeddedAcousticRecognition.framework/Versions/A/EmbeddedAcousticRecognition
/System/Library/PrivateFrameworks/DistributedEvaluation.framework/Versions/A/DistributedEvaluation
/System/Library/PrivateFrameworks/RemoteXPC.framework/Versions/A/RemoteXPC
/System/Library/PrivateFrameworks/RemoteServiceDiscovery.framework/Versions/A/RemoteServiceDiscovery
/usr/lib/libMobileGestalt.dylibp/System/Library/PrivateFrameworks/SpeechDetector.framework/Versions/A/SpeechDetector/System/Library/PrivateFrameworks/SiriAnalytics.framework/Versions/A/SiriAnalytics
/System/Library/PrivateFrameworks/LocalSpeechRecognitionBridge.framework/Versions/A/LocalSpeechRecognitionBridge
/System/Library/PrivateFrameworks/CoreEmbeddedSpeechRecognition.framework/Versions/A/CoreEmbeddedSpeechRecognition
/usr/lib/libobjc.A.dylib
/usr/lib/libc++.1.dylib
/usr/lib/libSystem.B.dylib
/System/Library/Frameworks/AppKit.framework/Versions/C/AppKit
/System/Library/Frameworks/CoreFoundation.framework/Versions/A/CoreFoundation
/System/Library/Frameworks/Shazamkit.framework/Versions/A/ShazamKit
/System/Library/PrivateFrameworks/SoftLinking.framework/Versions/A/SoftLinking


@N@$@@mcplsupoxepsmanlbolgnartbolg nIdbolgtuOdbolgA@
knNZF#vedbolgnartbolgcrsstpni
ff@àÁÍÌÌ⇒?@Ï@ mcpl
Ù? (@
manlbolgtuOdbolg @cneasupolppaVoiceTrigger/assetVoiceTrigger/SAT/model/VoiceTrigger/SAT/audio/-[CSRemoteControlClient
initWithRemoteDevice:] CSRemoteControlClientv16@?0@"OS_remote_device"8-[CSRemoteControlClient addObserver:]v8@?0-[CSRemoteControlClient invalidate]-[CSRemoteControlClient dealloc]-[CSRemoteControlClient didDeviceConnect:]-[CSRemoteControlClient
didDeviceConnect:]_block_invokecom.apple.corespeech.xpc.remote.controlcom.apple.corespeech.xpc.remote.control.darwin
v16@?0@"NSObject<OS_xpc_object>"8-
[CSRemoteControlClient didDeviceDisconnect:]-[CSRemoteControlClient waiting For Connection: error:] deviceUUID (% @), device Type (%@) -[CSRemoteControlClient _handleServerEvent:]-[CSRemoteControlClient handleServerError:] COMMAND %s -[CSRemoteControlClient
_handleServerMessage:]notifyVoice TriggernotifySelf TriggernotifyBootFromHibernate requestAssetDownload voice TriggerAssetConfig VersionlanguageCode-[CSRemoteControlClient readVoiceTriggeredTokenWithCompletion:]readVoiceTriggeredTokenreplyReadVoiceTriggeredToken-[CSRemoteControlClient readVoiceTriggeredTokenWithCompletion:]_block_invoke-[CSRemoteControlClient
readAndClearVoice TriggeredTokenWithCompletion:]readAndClearVoiceTriggered Token replyReadAnd Clear Voice TriggeredTokenvoice TriggerEvent InfotokenFetchMachTime-[CSRemoteControlClient readAndClearVoice TriggeredTokenWithCompletion:]_block_invoke-[CSRemoteControlClient _transferFile: at: completion:]reasonsrc path or dst path is nilfile does not existwriteFilefilePath-[CSRemoteControlClient transferFile: at: completion:]_block_invokev12@?0i8creation of file transfer object failedfileTxremote connection does not exist -[CSRemoteControlClient transferVoice Trigger Speaker Model: forAsset:] v16@?0@"NSError"8-[CSRemoteControlClient transferVoiceTriggerAsset: forLanguageCode: completion:].assetVoice Trigger asset file transmission timed outsetVoiceTriggerAsset voice Trigger AssetHashvoiceTriggerAssetLanguageCodevoice Trigger AssetPath-[CSRemoteControlClient
transferVoiceTriggerAsset: forLanguageCode: completion:]_block_invokeAttempt to send message while connection does not exist -[CSRemoteControlClient setVoiceTriggerEnable: withCompletion:] enableVoice Triggerdisable Voice Trigger-[CSRemoteControlClient setVoiceTriggerEnable: with Completion:]_block_invoke-[CSRemoteControlClient voice TriggerEnabledWithCompletion:] voice TriggerEnabledreplyVoiceTriggerEnabled-[CSRemoteControlClient voiceTriggerEnabledWithCompletion:]_block_invoke-[CSRemoteControlClient invalidateInterstitialWith Level:] invalidate InterstitialAudiointerstitialLevel-[CSRemoteControlClient invalidate InterstitialWithLevel:]_block_invoke-[CSRemoteControlClient transfer InterstitialAudioFiles: interstitial Level: completion:]interstitial files array is emptyinterstitial audio file does not existfile transfer timeoutupdate InterstitialAudio-[CSRemoteControlClient transfer InterstitialAudioFiles: interstitialLevel: completion:]_block_invoke-[CSRemoteControlClient get TriggerCount:]get Trigger CountreplyGetTriggerCount-[CSRemoteControlClient getTriggerCount:]_block_invoke-[CSRemoteControlClient clearTriggerCount:]clearTriggerCount replyClearTrigger Count-[CSRemoteControlClient clearTriggerCount:]_block_invoke-[CSRemoteControlClient
getFirstPassRunningMode:] getFirstPassRunningMode replyGetFirstPassRunningMode-[CSRemoteControlClient getFirstPassRunningMode:]_block_invoke-[CSRemoteControlClient _dictionaryWithContents OfXPCObject:]_block_invokeB24@?Or*8@"NSObject<OS_xpc_object>"16myriad Hash-[CSRemoteControlClient
notifyVoiceTriggerAsset ChangeWithSiriLanguageCode:]NotifyVTAssetChange-[CSRemoteControlClient notifyVoice TriggerAssetChangeWithSiriLanguageCode:]_block_invoke-[CSRemoteControlClient exchange RemoteDevice ProtocolInfo:] exchange ProtocolInfohost ProtocolInfo replyResult-[CSRemoteControlClient
exchange RemoteDevice Protocol Info:]_block_invoke_2accessory ProtocolInfo-[CSRemoteControlClient exchangeRemote Device ProtocolInfo:]_block_invoke-[CSRemoteControlClient createRemote VoiceProfileWithAudioFiles: aesKey: encryptedAudioSampleBype Depth: LanguageCode: completion:]training audio files array is emptytraining audio file does not exist -[CSRemoteControlClient
createRemoteVoiceProfileWithAudio Files: aesKey: encryptedAudioSampleBypeDepth: LanguageCode: completion:]_block_invokev32@?
O@"NSData"8Q16@"NSError"24createRemote Voice ProfileexplicitTrainingAudioFiles-[CSRemoteControlClient
createRemoteVoiceProfileWithAudioFiles: aesKey: encrypted AudioSampleBypeDepth: LanguageCode: completion:]_block_invoke_2-[CSRemoteControlClient
notifyBluetooth Wireless SplitterStateChanged: should DisableSpeakerVerificationInSplitterMode:]
YESNOnotifySplitterStateChangesplitterState shouldDisableSpeaker Verification-[CSRemoteControlClient
notifyBluetooth Wireless SplitterStateChanged: should DisableSpeaker VerificationInSplitter Mode:]_block_invoke-[CSRemoteControlClient
fetchAndClearCachedVoiceTriggerEventsWithCompletion:] fetchAndClearCachedVTEvents voice TriggerFirstPassEventssecondPassRejectedEventssecondPassCancelledEvents-[CSRemoteControlClient fetchAndClearCachedVoiceTriggerEventsWithCompletion:]_block_invoke-[CSRemoteControlClient
_fetchDataFromAudioFileUrl: aesKey: encryptedAudioSampleBypeDepth: completion:]_block_invokev32@?0^v8Q16@"NSError"24encReader not
existwriteFileFromAudio DatanumberOfSamplesaudioData-[CSRemoteControlClient _transferAudioData: numSamples: remoteWavFilePath: completion:]_block_invoke-[CSRemoteControlClient setSelfTriggerEnable: with Completion:] enableSelfTriggerdisableSelf Trigger-[CSRemoteControlClient
setSelfTriggerEnable: with Completion:]_block_invoketype-[CSAudio MetricProviding Proxy handle XPCMessage: message Body: client:]-[CSAudioMetricProviding Proxy _handleMetricProvidingRequestTypeAudioMetricMessage:messageBody: client:]resultaudioMetricv16@?0Q8CSTimer Monitor queue-[CSTimer Monitor _startMonitoringWithQueue:]-[CSTimer Monitor _stopMonitoring]-[CSVoiceTriggerAsset DownloadMonitor _startMonitoringWithQueue:]-[CSVoiceTriggerAssetDownload Monitor _stopMonitoring]-[CSVoiceTriggerAsset Download Monitor did InstalledNewVoiceTriggerAsset] v16@?0@8com.apple.MobileAsset.VoiceTriggerAssets.ma.new-asset- installedcom.apple.MobileAsset.VoiceTriggerAssets IPad.ma.new-asset-installedcom.apple.MobileAsset.VoiceTrigger HSAssets IPad.ma.new-asset- installedcom.apple.MobileAsset.VoiceTriggerAssetsWatch.ma.new-asset-installedcom.apple.MobileAsset.VoiceTriggerHSAssetsWatch.ma.new-asset- installedcom.apple.MobileAsset.VoiceTriggerAssets Marsh.ma.new-asset-installedcom.apple.MobileAsset.VoiceTriggerAssets Mac.ma.new-asset-installedcom.apple.MobileAsset.VoiceTriggerAssetsTV.ma.new-asset-installedcom.apple.MobileAsset.VoiceTrigger HSAssets.ma.new-asset- installedCSAudioInjection HearstEngine-[CSAudioInjection Hearst Engine dealloc]-[CSAudioInjectionHearst Engine start]_block_invokev20@? Oc8@"NSError"12CSAudioRouteChangeMonitor ImplWatch queue-[CSAudioRouteChangeMonitorImplWatch activeAudio Route DidChange:]_block_invoke-[CSAudioRouteChangeMonitorImplWatch _startMonitoringWithQueue:]-[CSAudioRouteChangeMonitorImplWatch _stopMonitoring]-[CSAudio RouteChangeMonitor ImplWatch _notifyHearst RoutedState:]-[CSAudio RouteChangeMonitor ImplWatch _notifySiriInputSourceOutOfBandState:]-[CSAudio RouteChangeMonitorImplWatch _systemController Died:]{ wordCount: %ld, trailingSilDuration: %ld, eosLikelihood: %f, pauseCounts: (%@), silencePosterior: %f, taskName: %@, processed Audio DurationInMilliseconds: %ld}, WordCountTrailingSilDurationEOSLikelihoodPauseCountsSilencePosterior ProcessedAudioDurationInMillisecondsc8@?0-[CSSmartSiriVolume EnablePolicy HomePod _addSmartSiriVolumeEnabledConditions]_block_invoke-[CSAudioFileLog closeAudioFile]-[CSAudioFileLog startRecording]_block_invoke-input.wav-[CSAudioFileLog appendAudioData:]_block_invoke-[CSAudioFileLog stopRecording]_block_invokeLogs/CrashReporter/CoreSpeech/audio/-[CSAudioFileLog getOrCreateAudioLogDirectory]/ tmpen_US_POSIXyyyy MMdd-HHmms s%@/% @% @%@ _set option allowVoiceTriggerAssets Download ? %@; allowEndpointAssetDownload ? %@; allowSpeaker Recognition Asset Download ?
allowLanguage DetectorAssetDownload ? %@;
allowAdBlocker Asset Download ? %@;
%@keywordDetectorconfigFileRecognizerthresholdwait TimeSince VTkeyword_detector.json-[CSSmartSiriVolume RunPolicy HomePod _addSmartSiriVolumeEnabledConditions]_block_invokeAdaptive Siri Volume Disablednearmediumfar-[CSSmartSiriVolumeUserIntent apply Lower And Upper Bounds To Volume:]-[CSSmartSiriVolume UserIntent apply Lower And UpperBounds To VolumeOffset:]-[CSLanguage Code UpdateMonitor _start MonitoringWithQueue:] CSLanguageCodeUpdateMonitor.m-[CSLanguageCodeUpdateMonitor _stopMonitoring]-[CSLanguageCodeUpdateMonitor notifySiriLanguage CodeChanged:]-[CSSiriEnabledMonitor _startMonitoringWithQueue:]EnabledDisabled-[CSSiriEnabledMonitor _stopMonitoring] _Assistant PrefsChanged Notification-[CSShadowMic ScoreCreator calculateShadowMicScore] firstPass RemoraTriggerEndTimecom.apple.corespeech.remoram.voicetriggersecond passq.%@, com.apple.corespeech.remoram.voice triggersecondpass.%@.stateq, -[CSRemoraSecondPass Request initWithDeviceID:]-[CSRemoraSecondPassRequest dealloc] CSRemora SecondPass Requestcom.apple.corespeech.firstpass remora-[CSVoiceTriggerFirstPass Remora start]_block_invokev24@?0@"CSAsset"8@"NSError"16-[CSVoiceTriggerFirstPass Remora _setIsSecondPassing: forDeviceId:]-[CSVoiceTriggerFirstPassRemora activationEventNotificationHandler: event: completion:]_block_invokev24@?0@"NSError"8@"CSRemoraSecondPassRequest"16-[CSVoiceTriggerFirstPass Remora _createSecondPassRequestIfNecessaryForActivationEvent: completion:]@"CSRemoraSecondPassRequest"8@?0-[CSVoiceTriggerFirstPass Remora accessorySiriClientBehavior Monitor: didStart StreamWithContext: successfully: option: withEvent UUID: for Accessory:]_block_invoke-[CSVoiceTriggerFirstPassRemora _handleRemora TriggerEvent: secondPassRequest:completion:]_block_invoke-[CSVoiceTriggerFirstPass Remora _handleRemora TriggerEvent: secondPassRequest:completion:]-[CSVoiceTriggerFirstPass Remora _handleRemora TriggerEvent: secondPassRequest: completion:]_block_invoke_2v24@?0@"CSVoiceTrigger SecondPass ResultHolder"8@"NSError"16-[CSVoiceTriggerFirstPass Remora _handleSecondPass Result: secondPass Request: deviceId: error: completion:]-[CSVoiceTriggerFirstPass Remora _cancelAudioStreamHolding For AccessoryWithId:]-[CSVoiceTriggerFirstPass Remora cancelSecondPass Running]_block_invoke Unique Device IDCSRemote Darwin DeviceInfo Queue-[CSRemoteDarwin DeviceInfo deviceConnectedWithUUID:]-[CSRemoteDarwin Device Info deviceConnectedWithUUID:]_block_invoke-[CSRemoteDarwin Device Info allDeviceDisconnected]_block_invoke-[CSRemote Darwin DeviceInfo fetch Device UUIDString FromUID:]-[CSRemoteDarwinDeviceInfo fetchDeviceUUIDStringFromUID:]_block_invoke-[CSRemote Darwin Device Info isPrimaryVoiceTriggerDeviceWithUUID:]_block_invoke-[CSRemote Darwin DeviceInfo fetchRichDeviceUIDStringFromUUID:]-[CSRemote Darwin DeviceInfo addDevice IDPairToMapTable:withDeviceUID:]_block_invokeCSVoiceTriggerAssetHandler-[CSVoiceTriggerAssetHandler getVoiceTriggerAssetWithEndpointId: completion:] CSVoiceTriggerAssetHandler.m-[CSVoiceTriggerAssetHandler defaultFallback ModelIfNil:] triggerEndMach Time CSDarwinVoiceTriggerHandler-[CSDarwinVoiceTrigger Handler dealloc]-[CSDarwinVoiceTriggerHandler start]_block_invokeRUNNINGSTOPPED v20@?0c8Q12v20@?0Q8c16-[CSDarwinVoiceTriggerHandler _startRetryTimer] v12@?0c8-[CSDarwinVoiceTriggerHandler _stopRetryTimer]-[CSDarwinVoiceTriggerHandler _registerPower Notification] Voice TriggerMonitor-[CSDarwinVoiceTriggerHandler onUserSession Active:]-[CSDarwinVoiceTriggerHandler onUserSession Resign:]-[CSDarwinVoiceTrigger Handler on EarlyWake]_block_invoke_2-[CSDarwinVoiceTriggerHandler _connectRemoteCoreSpeechIfNeeded] com.apple.voice trigger.remotedarwin.EverConnected-[CSDarwinVoiceTriggerHandler handleRemoteCoreSpeechFirstTimeConnected] en-US-[CSDarwinVoiceTriggerHandler _disconnect RemoteCore Speech]-[CSDarwinVoiceTriggerHandler handleDevice Disconnection] VoiceTriggered-[CSDarwinVoiceTriggerHandler _getPowerAssertion IfNeeded For RemoteClient:]_block_invoke_2ExitSilent Running-[CSDarwinVoiceTriggerHandler_getPowerAssertion IfNeeded For RemoteClient:]_block_invoke-[CSDarwinVoiceTriggerHandler _getPower Assertion IfNeeded For RemoteClient:]-[CSDarwinVoiceTriggerHandler _wakeSiriIfNeeded FromFullWake:completion:]-[CSDarwinVoiceTriggerHandler _wakeSiriIfNeeded FromFullWake: completion:]_block_invoke_2-[CSDarwinVoiceTriggerHandler _wakeSiriIfNeeded FromFullWake: completion:]_block_invokev36@?0c8@"NSData"12@"NSDictionary"20Q28v32@?0@"NSArray"8@"NSArray"16@"NSArray"24-[CSDarwinVoiceTriggerHandler _releaseFullWake Assertion]-[CSDarwinVoiceTriggerHandler _writeMyriad HashFile:]-[CSDarwinVoiceTriggerHandler didReceiveConnection Invalidated:]_block_invoke-[CSDarwinVoiceTrigger Handler didReceiveVoice Triggered:]-[CSDarwinVoiceTriggerHandler didReceiveSelfTriggerDetected: myriad Hash:] com.apple.siri.corespeech.selftrigger-[CSDarwinVoiceTriggerHandler handleSelf TriggerDetected: myriad Hash:]_block_invoke-[CSDarwinVoiceTriggerHandler didReceiveVoiceTriggerAssets Downloading Request: withConfigVersion: languageCode:]-[CSDarwinVoiceTriggerHandler didReceiveVoiceTriggerAssets DownloadingRequest: withConfigVersion: LanguageCode:]_block_invoke-[CSDarwinVoiceTriggerHandler didReceiveVoiceTriggerAssets DownloadingRequest: withConfigVersion: Language Code:]_block_invoke_2-[CSDarwinVoiceTriggerHandler _startPreventSleepAssertionTimer]-[CSDarwinVoiceTriggerHandler _startPreventSleepAssertionTimer]_block_invoke-[CSDarwinVoiceTriggerHandler _stopPreventSleepAssertionTimer]-[CSDarwinVoiceTriggerHandler _updateSystemSleepPowerAssertionState]-[CSDarwinVoiceTriggerHandler CSSystemUserActivity Monitor: activeStateChanged:]-[CSDarwinVoiceTriggerHandler _retryVoice TriggerEnable:]-[CSDarwinVoiceTriggerHandler _retryVoiceTriggerEnable:]_block_invoke_2-[CSDarwinVoiceTrigger Handler _retryVoiceTriggerEnable:]_block_invokev16@?0c8c12-[CSDarwinVoiceTriggerHandler transferDarwinVoice TriggerAsset: LanguageCode:]-[CSDarwinVoiceTriggerHandler _markRemoteVoiceTriggerEnabled] v16@?0@"CSDarwinVoiceTriggerHandler"8-[CSDarwinVoiceTriggerHandler _enableRemote Voice Trigger]-[CSDarwinVoiceTriggerHandler _enableRemoteVoice Trigger]_block_invoke-[CSDarwinVoiceTriggerHandler _disable Remote Voice Trigger]_block_invoke-[CSDarwinVoiceTriggerHandler Ln 19,169, Col 8,311 _disable Remote VoiceTrigger]-[CSDarwinVoiceTriggerHandler CSVoiceTriggerAsset DownloadMonitor: did InstallNewAsset:]-[CSDarwinVoiceTriggerHandler CSLanguageCodeUpdateMonitor: didReceive LanguageCodeChanged:]-[CSDarwinVoiceTriggerHandler handleAsset Change]_block_invoke-[CSDarwinVoiceTriggerHandler _safeAssetChangeHandler]-[CSDarwinVoiceTriggerHandler CSScreenLockMonitor: didReceiveScreenLockStateChanged:]_block_invokepowerNotificationEventHandlerCSBuilt In Speaker StateMonitor queue-[CSBuiltinSpeakerStateMonitor _fetchSpeaker State Muted Info]_block_invoke_2-[CSBuiltinSpeakerStateMonitor _fetchSpeakerStateMuted Info]_block_invokemuted not muted-[CSBuiltin SpeakerStateMonitor _fetchSpeaker State ActiveInfo]_block_invoke_2-[CSBuiltinSpeakerStateMonitor _fetchSpeaker State ActiveInfo]_block_invokein-[CSBuiltinSpeakerStateMonitor _startMonitoringWithQueue:]_block_invoke_2active-[CSBuiltinSpeakerStateMonitor _startMonitoringWithQueue:]_block_invokev16@?0@"NSDictionary"8-[CSBuiltinSpeakerStateMonitor _startMonitoringWithQueue:]-[CSBuiltinSpeakerStateMonitor _stopMonitoring]_block_invoke-[CSBuiltinSpeakerStateMonitor _stopMonitoring]-[CSBuiltinSpeakerStateMonitor CSAudioServerCrashMonitorDid ReceiveServerRestart:]_block_invoke-[CSLanguageCodeUpdateMonitorImpl _startMonitoringWithQueue:]-[CSLanguageCodeUpdateMonitorImpl _stopMonitoring]-[CSLanguageCodeUpdateMonitorImpl _didReceiveLanguageCodeUpdate] Builtin Microphone [Context = %ld ][DeviceId = %@][Announced = %d][streamHandleId = %d][startHostTime = %llu][startAlert = %d][stopAlert = %d][stopOnErrorAlert = %d][ skipAlert % @]-[CSAudioRecorder initWithQueue: error:]-[CSAudioRecorder userSession Activate Monitor: didReceivedUserSessionActiveHas Changed:]_block_invoke-[CSAudioRecorder willDestroy]-[CSAudioRecorder dealloc]-[CSAudioRecorder _destroyVoiceController]-[CSAudioRecorder _voiceControllerWithError:]_block_invoke-[CSAudioRecorder _voiceControllerWithError:]-[CSAudioRecorder setAnnounceCallsEnabled: withStreamHandleID:]-[CSAudioRecorder setContext:completion:]-[CSAudioRecorder setCurrentContext: streamHandleId: error:]-[CSAudioRecorder prepareAudioStreamRecord: recordDevice Indicator: error:]-[CSAudioRecorder _startAudioStreamForAudio InjectionWithAVVCContext:]-[CSAudioRecorder startAudioStreamWithOption: recordDevice Indicator: error:] context-[CSAudioRecorder stopAudioStreamWithRecordDevice Indicator: error:]-[CSAudioRecorder isSessionCurrentlyActivated]-[CSAudioRecorder recordDeviceInfoWithStreamHandleId: recordDevice Indicator:]-[CSAudioRecorder recording SampleRateWithStreamHandleId:]-[CSAudioRecorder isNarrowBandWithStreamHandleId:]-[CSAudioRecorder prewarmAudioSessionWithStreamHandleId: error:]-[CSAudioRecorder setRecord Mode: streamHandleId: error:]-[CSAudioRecorder activate AudioSessionWithReason: streamHandleId: error:]-[CSAudioRecorder deactivate AudioSession: error:]-[CSAudioRecorder deactivateAudio Session: streamHandleId: error:]-[CSAudioRecorder setDuckMixWithOthersForStream: duckOthers: duckToLevelInDB: mixWithOthers:]-[CSAudioRecorder enableMiniDucking:]-[CSAudioRecorder configureAlertBehavior: audioStreamHandleId:]i-[CSAudioRecorder voice Trigger InfoWith RecordDevice Indicator:]-[CSAudioRecorder _updateLanguage Code ForRemote VTEIResult:]-[CSAudioRecorder shouldUse RemoteRecordForContext: JuseRemoteBuilt In Mic-[CSAudioRecorder _processAudioBuffer: audioStreamHandleId: arrivalTimestampToAudio Recorder:]-[CSAudioRecorder compensateChannelDataIfNeeded: received NumChannels:]-[CSAudioRecorder _trackRemoteAccessoryStreamIdIfNeeded:]-[CSAudioRecorder playRecordStartingAlertAndResetEndpointer FromStream:]-[CSAudioRecorder playAlertSoundForType: recordDevideIndicator:]-[CSAudioRecorder alertStartTime]-[CSAudioRecorder voiceControllerDidStart Recording: forStream: successfully: error:]-[CSAudioRecorder voiceControllerAudioCallback: forStream: buffer:]-[CSAudioRecorder voiceControllerDidStopRecording: forStream: for Reason:]-[CSAudioRecorder voiceControllerStreamInvalidated: forStream:]-[CSAudioRecorder voiceControllerRecordHardwareConfigurationDidChange:toConfiguration:]-[CSAudioRecorder voiceController Did FinishAlertPlayback: of Type: error:]-[CSAudioRecorder voiceController EncoderErrorDidOccur: error:]-[CSAudioRecorder voiceController Media ServicesWere Lost:]-[CSAudioRecorder voiceControllerMediaServicesWere Reset:]-[CSAudioRecorder remoteRecord Two Shot DetectedAtTime:]_block_invoke-[CSAudioRecorder hasLocalPending TwoShot]_block_invoke-[CSAudioRecorder _getRecordSettingsWithRequest:]-[CSAudioRecorder _fetchRemoteRecordClientWithDeviceId: streamHandleId:] CSAudio Route ChangeMonitorImplMac queuev20@?018r^{AudioObjectPropertyAddress=III}12-[CSDefaultAudioRouteChangeMonitor Mac _startMonitoringWithQueue:]-[CSDefault Audio RouteChangeMonitorMac stopMonitoring]-[CSDefaultAudioRouteChangeMonitorMac _getAudioDevice Name:]-[CSDefaultAudioRouteChangeMonitor Mac _getAudio Device Transport Type: to:]-[CSDefault Audio RouteChangeMonitorMac _getAudioDevice DataSourceID: propertyScope: to:]-[CSDefaultAudioRouteChangeMonitor Mac _fetchIsDefaultInputBultInMic]-[CSDefaultAudioRouteChangeMonitorMac _fetchIsDefaultOutputBuiltInSpeaker] com.apple.siri.myriad.in.ear+ [CSMyriad Notifier notifyInEarMyriad Trigger]+[CSAudioRecorderFactory audioRecorderWithQueue: error:][requestHistoricalAudioDataWithHostTime = % @][requestHistoricalAudioDataSampleCount = %@][use OpportunisticZLL = %@][ startRecording HostTime = %llu][startRecording SampleCount = %llu][alert Behavior = %llu %llu %llu][skipAlertBehavior = %@][requireSingleChannelLookup = %@][ selectedChannel = %u][estimatedStartHostTime = %llu [disableEndpointer = %d][disableLocalSpeechRecognizer= %d][disable PrewarmLocalSpeechRecognizer= %d][ %d]requestHistoricalAudioDataWith HostTimerequestHistoricalAudioDataSampleCount startRecording HostTimestartRecording SampleCount use OpportunisticZLLstartAlertBehavior stopAlertBehaviorerrorAlertBehaviorskipAlertBehaviorrequireSingle ChannelLookupselectedChannelestimatedStartHostTime disableEndpointerdisableLocalSpeechRecognizerdi sable PrewarmLocalSpeechRecognizerdisable BoostForDoAP requestMHUUIDsiriSessionUUIDAcousticSLTaskTypeVoice Trigger AcousticSLTaskTypeContConvCSGibraltarVoiceTrigger Handler-[CSGibraltarVoiceTriggerHandler start]_block_invoke-[CSGibraltarVoiceTriggerHandler _startRetryTimer]-[CSGibraltarVoiceTriggerHandler _stopRetryTimer]-[CSGibraltarVoiceTriggerHandler _registerPower Notification]-[CSGibraltarVoiceTriggerHandler onUserSession Active:]-[CSGibraltarVoiceTrigger Handler onUserSession Resign:]-[CSGibraltarVoiceTriggerHandler _connectRemoteCoreSpeech IfNeeded]-[CSGibraltarVoiceTriggerHandler disconnectRemoteCoreSpeech] IOPMrootDomainWake Reason-[CSGibraltarVoiceTriggerHandler isWake ReasonVoiceTrigger] EC.SiriIOPMSystemSleepType-[CSGibraltarVoiceTriggerHandler _isWakeFromS3 Sleep]-[CSGibraltarVoiceTriggerHandler _getPower Assertion IfWakenByVoice TriggerNotFromS3Sleep]-[CSGibraltarVoiceTriggerHandler _getPower Assertion IfNeeded]_block_invoke-[CSGibraltar Voice TriggerHandler getPowerAssertion IfNeeded]-[CSGibraltarVoiceTriggerHandler _wakeSiriIfNeeded FromFullWake:]-[CSGibraltarVoiceTriggerHandler _wakeSiriIfNeeded FromFullWake:]_block_invoke-[CSGibraltarVoiceTriggerHandler _releaseFullWake Assertion] v16@?0@"<AFMyriadContextMutating>"8-[CSGibraltarVoiceTriggerHandler _wakeSiriWith MyriadPHash:]_block_invokev16@?0@"AFSiriActivation Result"8-[CSGibraltarVoiceTriggerHandler _writeMyriad HashFile:]-[CSGibraltarVoiceTriggerHandler didReceiveVoice Triggered:]-[CSGibraltarVoiceTriggerHandler didReceiveBootFromHibernate:]-[CSGibraltarVoiceTriggerHandler didReceiveSelfTriggerDetected: myriad Hash:]-[CSGibraltar Voice TriggerHandler handleSelfTrigger Detected:]_block_invoke-[CSGibraltarVoiceTriggerHandler _sendSelfTriggerEnabledToRemote: force:]-[CSGibraltarVoiceTriggerHandler _sendSelfTriggerEnabledToRemote: force:]_block_invoke-[CSGibraltarVoiceTriggerHandler
disableBoostForDOAP = _retryVoiceTriggerEnable:]-[CSGibraltarVoiceTriggerHandler _retryVoice TriggerEnable:]_block_invoke_2-[CSGibraltarVoiceTriggerHandler _retryVoiceTriggerEnable:]_block_invoke-[CSGibraltarVoiceTriggerHandler _enableRemote Voice TriggerWithAsset:]-[CSGibraltarVoiceTriggerHandler _enableRemote Voice TriggerWithAsset:]_block_invoke-[CSGibraltarVoiceTriggerHandler _enableRemote Voice TriggerWithAsset:]_block_invoke_2-[CSGibraltarVoiceTriggerHandler _transfer Speaker Model]-[CSGibraltarVoiceTriggerHandler _enableRemote Voice TriggerWithAsset: with Speaker Profile:]_block_invoke_2-[CSGibraltarVoiceTriggerHandler _transferVoiceTriggerAsset: with Completion:]_block_invoke_2-[CSGibraltarVoiceTriggerHandler _disable RemoteVoiceTrigger]_block_invoke-[CSGibraltarVoiceTriggerHandler CSVoiceTriggerAssetDownload Monitor: did InstallNewAsset:]-[CSGibraltarVoiceTriggerHandler CSLanguageCodeUpdateMonitor: didReceive LanguageCodeChanged:]-[CSGibraltarVoiceTriggerHandler handleAssetChange]_block_invoke-[CSGibraltarVoiceTriggerHandler _safeAssetChangeHandler]-[CSGibraltarVoiceTriggerHandler CSScreen LockMonitor: didReceiveScreen LockStateChanged:]_block_invoke-[CSAttSiriConnectionManager initWithAttSiriController: supportsAttentiveSiri: supportsSpeechRecognitionOnDevice: supports SSR:] com.apple.CoreSpeech.Connection.Listener.endpointercom.apple.corespeech.corespeechd.endpointer.service-[CSAtt SiriConnectionManager _setupEndpointListener] com.apple.CoreSpeech.Connection.Listener.asr-[CSAttSiriConnectionManager _setupLocalSpeech RecognitionListener] com.apple.corespeech.core speechd.attsiri.service-[CSAtt SiriConnectionManager _setupAttSiriServiceListener] com.apple.CoreSpeech.Connection.Listener.ssrcom.apple.corespeech.corespeechd.ssr.service-[CSAttSiriConnectionManager _setupSSRListener] com.apple.CoreSpeech.Connection.Listener.rchandlingcom.apple.corespeech.corespeechd.rchandling.service-[CSAttSiriConnectionManager _setupRCProcessing Listener]-[CSCoreSpeechDaemonState Monitor notifyDaemonStateChanged:]com.apple.corespeech.corespeechd.Launch-[CSCore SpeechDaemon State Monitor _startMonitoringWithQueue:]-[CSCore SpeechDaemonStateMonitor _stop Monitoring]-[CSCoreSpeechDaemonStateMonitor _didReceive DaemonStateChanged:] CSMediaPlaying Monitor queuetriggerEndSecondsshadowMicScoreshadowMicScore ThresholdForVADremoteMicVADScoreremoteMicVADThreshold remoteMicVADMyriad Thresholdtriggered Phrase-[CSHearstSecondPassRequest dealloc] CSHearst SecondPassRequestVoice TriggerFirstPassHearst Queue-[CSVoiceTriggerFirstPass Hearst start]_block_invoke-[CSVoiceTriggerFirstPassHearst _setAsset:]-[CSVoiceTriggerFirstPassHearst activationEvent NotificationHandler: event: completion:]_block_invoke-[CSVoiceTriggerFirstPassHearst siriClientBehaviorMonitor: didStartStreamWithContext: successfully: option: withEventUUID:]_block_invoke-[CSVoiceTriggerFirstPassHearst _handleRemote MicVADEventWithSecondPassRequest:]-[CSVoiceTriggerFirstPassHearst handleRemoteMicVoice TriggerEvent: secondPass Request: completion:]_block_invoke_2-[CSVoiceTriggerFirstPass Hearst handleRemoteMicVoice TriggerEvent: secondPass Request: completion:]_block_invoke-[CSVoiceTriggerFirstPass Hearst _handleRemote MicVoiceTrigger Event: secondPassRequest: completion:]-[CSVoiceTriggerFirstPassHearst
_handleSecondPassResult:secondPassRequest:deviceId: error: completion:]-[CSVoiceTriggerFirstPassHearst
_requestStartAudio StreamWitContext: secondPass Request: startStreamOption: completion:]-[CSContinuousAudioFingerprintEnabled PolicyHomePod _addContinous Audio FingerprintEnabledConditions]_block_invokeCSSmartSiriVolume Run Policy queue-[CSSmartSiriVolume RunPolicy _addSmartSiriVolumeEnabledConditions]_block_invoke-[CSAudioStream Providing Proxy setAudioStream Providing For Proxy:] resultErrorDomain resultErrorCode-[CSAudioStreamProviding Proxy CSXPCConnectionReceivedClientError:clientError:client:]-[CSAudio Stream Providing Proxy handleXPCMessage: message Body: client:]-[CSAudioStreamProviding Proxy _handleSupportsDuckingWithStreamHandleID: messageBody: client:]-[CSAudioStreamProvidingProxy _handleSetCurrentConextMessage: message Body: client:]audioStreamRequest-[CSAudioStreamProviding Proxy _handleAudioStreamRequestMessage: messageBody: client:]-[CSAudioStreamProviding Proxy _handleAudioStreamPrepareMessage:messageBody: client:]startAudioStreamOption-[CSAudioStreamProvidingProxy _handleStartAudioStream Message: message Body: client:]-[CSAudio StreamProviding Proxy _handleStopAudioStreamMessage:message Body: client:]-
[CSAudioStream Providing Proxy _handleVoice Trigger InfoMessage: messageBody: client:] voice Trigger InfortsTrigger Info-[CSAudioStream ProvidingProxy _handleIsRecording Message: message Body: client:]-[CSAudioStreamProviding Proxy _handleRecordRouteMessage:messageBody: client:]recordRoute-[CSAudioStream Providing Proxy _handleRecordDeviceInfo:messageBody: client:]recordDevice Info-[CSAudioStream Providing Proxy _handleAudioDevice Info:message Body: client:]audio DeviceInfo-[CSAudioStream Providing Proxy _handleRecordSettings:message Body: client:]recordSettings-[CSAudioStream Providing Proxy _handleIsNarrowband: messageBody: client:]-[CSAudioStreamProviding Proxy _handlePlaybackRouteMessage: messageBody: client:]playbackRoute-[CSAudioStreamProviding Proxy
audioStreamProvider: didStopStreamUnexpectly:] stopReasonchunk-[CSAudioStreamProvidingProxy audioStreamProvider: didHardwareConfigurationChange:]hardwareConfig-[CSAudioStreamProviding Proxy audioStream Provider: remoteRecorder DidDetectedTwoShotAtTime:] two Shot Timebodyoverride-asset-[CSAttSiriMitigationAssetHandler setCachedAsset:]_block_invoke-[CSAttSiriMitigationAssetHandler _receivedNewAssetUpdate:]-[CSAttSiriMitigationAssetHandler
trialAsset DownloadMonitorDelegate: did InstallNewAsset: assetType:]-[CSAudio RecordContext(AVVC)
avvcContextSettings] triggerScoreconfigVersion firstPassTriggerSourcecom.apple.corespeech.aopFirstPass TriggerWakeup Latencylatencydevice@"NSDictionary"8@? Ocom.apple.corespeech.SecondPassWakeUp unknownmodelVersionfirstPassSourcetriggerAPWakeup-[CSVoiceTrigger StatAggregator LogFalseWake Up: withPhrase:]-[CSVoiceTrigger StatAggregatorLogTriggerLengthSampleCountStatistics: with FirstPassDeterministic TriggerLengthSampleCount:] com.apple.
exprAOPSecondPassnewTrigger Length SampleCountold Trigger Length SampleCount sampleCount Deltacom.apple.corespeech.AudioZeroRunduration -[CSAtt SiriAttending AudioSrcNode initWithAttSiriController:] CSAttSiriAudioSrcNode Attending queue-[CSAttSiriAttendingAudioSrcNode initWithSpeechManager: audioStream Provider: streamName:streamRequest:] CSAtt SiriAudioSrc Node-[CSAttSiriAttendingAudioSrcNode
startAudioStreamWithOption: completion:]_block_invoke_2CSAttSiriAttendingAudioSrc Node-[CSAttSiriAttendingAudioSrcNode addReceiver:]_block_invoke-[CSAttSiriAttendingAudioSrcNode dealloc]-[CSAttSiriAttending AudioSrcNode
_handleDidStop] firstPassDetectedChannelfirstPassOnsetChannelfirstPassOnsetScorefirstPassChannelSelectionScores firstPassChannelSelection Delay SecondsfirstPassMasterChannelScoreBoostfirstPassStartSampleCountfirstPassEndSampleCountfirstPassFireSampleCountnumSamplesFromHistoricalBuffersecondPassAnalyerStartSampleCountsecondPassAnalyerEndSampleCounttriggerStartSampleCountclientStartSampleCounttriggerEndSampleCounttriggerFireSampleCounttriggerStartSeconds
triggerFireSecondsextraSamplesAtStartanalyzerPrependingSamples analyzer TrailingSamples totalSampleCounteffective Threshold recognizer Scorerecognizer ThresholdOffsetrecognizer ScaleFactorearlyDetectFiredMachTimetriggerStartMachTime triggerFireMach TimetriggerStartTimetrigger End TimetriggerFiredTimehardware SamplerateisContinuoussatScoresatNumTrainingUttssatThresholds atTriggeredtdSpeakerRecognizerScoretdSpeakerRecognizerCombinedScoretdSpeakerRecognizerCombined ThresholdtdSpeakerRecognizerCombinationWeighttriggerDurationtotalSamplesAtTrigger Start totalSamplesAtTriggerEndtotalSamplesAtEndOfCapturebuild Version configPathis Second Chanceactive Channeltwo Shot AudibleFeedbackDelaycumulativeUptimecu mulativeDowntime is Media PlayingmediaVolume audioProviderUUIDonBattery PowerdidWakeAPbiometric CluesatBeingTrained device HandHeld uptime downtime lastConsecutivePHSRejects earlyDetectFiredTime numberOfHSUtterancesdeltaTimeFromlastPHSRejectconfigDataHashsiriIsActiveOrOtherAssertion trigger Explicit SatScoretriggerExplicit TDSRSatScoreAppl icationProcessorApplication ProcessorWithRingtone Application ProcessorWithConnectedCallBuiltInAlwaysOnProcessorHearst HearstAPJarvisWatchDefaultselfLoggingMHUUIDfirstPass InfoGenerated Time firstPass InfoProcessedTime secondPass AssetQueryStartTime secondPassAssetQueryComplete Time secondPassAssetLoadStartTime secondPassAsset Load CompleteTimesecondPassAudioStreamStartTime secondPassAudioStreamReadyTime secondPassFirstAudioPacketReceptionTime secondPassLastAudioPacketReceptionTime secondPassChecker Mo delKeywordDetectionStartTime secondPassCheckerModelKeywordDetectionEndTimeRemoratriggered PhraseIdresult = %lu, isSecondChanceCandidate=%d, voiceTriggerEventInfo = % @VoiceTrigger SecondPass Queuecom.apple.corespeech.voice triggersecond pass.stateq-[CSVoiceTrigger SecondPass initWithPHSEnabled: speech Manager: stateQueue: secondPassQueue:]-[CSVoiceTrigger SecondPass dealloc]-[CSVoiceTriggerSecondPass _setAsset:]Qv16@?0q8v12@?0f8-[CSVoiceTrigger SecondPass clearTriggerCandidate ]-[CSVoiceTrigger SecondPass _requestStartAudioStreamWitContext: audioProviderUUID: startStreamOption: completion:]-[CSVoiceTrigger SecondPass _handle Voice TriggerFirstPassFromAP: audioProviderUUID: completion:]-[CSVoiceTrigger SecondPass _handleVoiceTriggerFirstPassFromHearst: deviceId: audio Provider UUID: firstPass Info:completion:]-[CSVoiceTrigger SecondPass _handleVoiceTriggerFirstPassFromRemora: deviceId: audio ProviderUUID: firstPass Info: completion:]-[CSVoiceTrigger SecondPass _handleVoiceTriggerFirstPassFromHearstAP: deviceId: audioProvider UUID: firstPassInfo: completion:]-[CSVoiceTrigger SecondPass _handleVoiceTriggerFirstPass FromJarvis: deviceId: audio ProviderUUID: firstPass Info: completion:]-[CSVoiceTrigger SecondPass cancelCurrentRequest]-[CSVoiceTrigger SecondPass _voiceTriggerFirstPass Did DetectKeywordFrom: completion:]com.apple.voicetrigger.builtin.Early Detect-[CSVoiceTriggerSecondPass _voiceTriggerFirstPassDid DetectKeywordFrom: completion:]_block_invokecom.apple.voice trigger.Early Detect-[CSVoiceTrigger SecondPass _notifySecondPassReject: result:isSecond Chance Candidate:]-[CSVoiceTriggerSecondPass _prepareStartAudioStream]-[CSVoiceTriggerSecondPass _didStartAudioStream:]-[CSVoiceTrigger SecondPass didStopAudioStream]-[CSVoiceTriggerSecondPass audioStreamProvider: didStopStreamUnexpectly:]-[CSVoiceTriggerSecondPass _handleAudioChunk:]n/a-[CSVoiceTrigger SecondPass _setKeywordDetectorStartMach Time: detectorEnd MachTime: LastAudioPacketAnalyzed MachTime:]-[CSVoiceTriggerSecondPass _analyzeForChannel: keywordDetectorResult:]-[CSVoiceTrigger SecondPass voiceTrigger PhraseNDEAPIScorerDid DetectedKeyword: bestStartSampleCount:bestEndSampleCount:]-[CSVoiceTrigger SecondPass _markSecondPassTrigger MachAbsolute Time:]_block_invoke-[CSVoiceTrigger SecondPass _handleSecondPass Success:] SiriXenable Telemetry=YES-[CSVoiceTrigger SecondPass _logUptimeWithVTSwitch Changed: VTEnabled:]-[CSVoiceTrigger SecondPass _resetUpTime] trigger-time trigger-config-blob-[CSVoiceTrigger SecondPass _handleVoice TriggerFirstPassFromAOP: audioProvider UUID: completion:]trigger-length trigger-woke-ap-[CSVoiceTriggerSecondPass _addPHSInfoTOVTEI: fromSpeakerInfo: with Threshold:]-[CSVoiceTrigger SecondPass _handle PHSResults: voiceTriggerEvent Info: forPhId:]-[CSVoiceTriggerSecondPass CSAudioServerCrash Monitor Did ReceiveServerRestart:] % @%@%@.wav-activation%@%@.wav+ [CSVoiceTriggerSecondPass secondPassAudioLogDirectory] secondPass Result UnknownsecondPass ResultTriggered secondPassResultRejected secondPass Result NearMisssecondPassResultCannotStartsecondPassR esultUnexpectedStopsecondPass ResultCanceled secondPass ResultErrorsecondPass Result PendingCandidatesecondPassResultPHSRejected secondPass ResultTimeoutSecondPass Result Summary:
Locale: %@
FirstPassSource: %@ AnalyzedSecs: %.3f NdapiScore: %.3f
CheckerScore: %.3f
CombinedVTScore: %.3f
PHS Summary:
DNNScore: %.3f
LSTMScore: %.3f
CombinedPHSScore: %.3f
NumSATVectors: %lu
Decision: %@-[CSVoiceTrigger SecondPass LogSecondPass Result: withVTEI:]-[CSVoiceTriggerSecondPass _setStartAnalyze Time:]-[CSVoiceTrigger SecondPass _scheduleSecondPassCompletionWatchDog]-[CSVoiceTrigger SecondPass scheduleDidStart SecondPassCompletionWatchDogWithToken:]-[CSVoiceTriggerSecondPass _clearSecondPassCompletionWatchDog]-[CSAudioPreprocessor resetWithSampleRate: contains Voice Trigger: voice Trigger Info:]-[CSAudio Preprocessor flush] ZeroFilterMetrics-[CSAudioPreprocessor _fetchCurrentMetrics] BeepCancellerMetricscorespeechd xpc connection client queue-[CSXPCConnection sendMessageToClient:]-[CSXPCConnection sendMessageToClient:]_block_invoke-[CSXPCConnection _handleClientEvent:]-[CSXPCConnection _handleClientMessage: client:]-[CSXPCConnection
_handleAudioProvidingMessage: messageBody: client:]clientType-[CSXPCConnection _handleAudio Providing RequestTypeSwitch Message: message Body: client:]-[CSXPC Connection _handleSetXPCClientType Message: message Body: client:]xpcClient Type-[CSXPCConnection _handleClientError: client:]-[CSXPCConnection _handlePingPongMessage:client:]voiccarplayhearstraise to speak auto-[CSVoiceTriggerEnabledPolicyMac _addVoiceTriggerEnabledConditions]_block_invoke-[CSHomePodSettings Monitor _stopMonitoring] VoiceTriggerEvent Notifier queue
voiceTriggerEventInfo: {
%@: %@
VoiceTrigger Metrics: {
-[CSVoiceTriggerEventsCoordinator _print Voice TriggerMetricsString:]-[CSVoiceTriggerEventsCoordinator
_notifyWakeKeyword SpokenEvent: deviceId:] com.apple.voice trigger.Keyword Spoken-[CSVoiceTriggerEvents Coordinator _notifyTriggerEvent: deviceId: completion:]-[CSVoiceTriggerEventsCoordinator _notify TriggerEvent: deviceId: completion:]_block_invokecom.apple.coreaudio.borealis Trigger-[CSVoiceTriggerEventsCoordinator _shouldIgnore Voice TriggerEvent:]-[CSVoiceTriggerEventsCoordinator
_notifyRemote TriggerEvent: myriad Hash: remote TriggerType: remoteDeviceId: isTriggeredFromFullWake: completion:]-[CSVoiceTriggerEvents Coordinator
_notifyRemote Trigger Event: myriad Hash: remote TriggerType: remoteDeviceId:isTriggeredFromFullWake: completion:]_block_invokefirstPass GoodnessvtEndTime [%@][%llu][ %f] BuiltInAOPVoice Trigger RemoteMicVoiceTrigger RemoteMicVADJarvis VoiceTriggermediaserverd Launched RemoraVoiceTriggerUnknownuuiddeviceIdactivation InfovadScorehosttim e-[CSVoiceTrigger AlwaysOnProcessor enableVoiceTriggerOnAlwaysOnProcessorWithAsset: completion:]_block_invokexx-XX-[CSVoiceTrigger AlwaysOnProcessor enableVoiceTriggerOnAlwaysOnProcessorWithAsset: completion:]_block_invoke_2-[CSVoiceTrigger AlwaysOnProcessor disableVoiceTriggerOnAlwaysOnProcessorWithCompletion:]_block_invoke-[CSAudioStreamHolding dealloc] CSAudioFileReader Queue-[CSAudioFileReader initWithURL:]-[CSAudioFileReader prepareRecording:]-[CSAudioFileReader startRecording]-[CSAudioFileReader _readAudioBufferAndFeed]-[CSAudioFileReader stopRecording] CSDarwinVoiceTriggerHandler Poolv20@? @"OS_remote_device"8B16-[CSDarwinVoiceTriggerHandler Pool
didReceive Darwin DeviceDisconnected:]_block_invokeCSAudioInjectionProvider ATVRemote InputBuiltInMic-[CSAudioInjectionProvider dealloc]-[CSAudioInjectionProvider stop]-[CSAudioInjectionProvider startAudioStreamWithOption: recordDevice Indicator: error:]-[CSAudioInjectionProvider stopAudioStreamWithRecordDevice Indicator: error:] IBuiltInSpeaker announcemessage -[CSAssetManagerEnablePolicy
_addAsset ManagerEnabledConditions]_block_invokeCSVoiceTriggerXPCListenercom.apple.corespeech.voice triggerservice-[CSVoiceTriggerXPCListener listen]-[CSVoiceTriggerXPCListener _handleListenerEvent:]-[CSVoiceTriggerXPCListener handleListenerError:]-[CSVoiceTriggerXPCListener _handleNewRemoteConnection:] voice trigger.voicetriggerservice-[CSVoiceTriggerXPCListener CSXPCConnectionReceivedClientError:clientError: client:]_block_invoke-[CSVoiceTriggerEnabledMonitor RemoteDarwin _startMonitoringWithQueue:]-[CSVoiceTriggerEnabledMonitor Remote Darwin _startMonitoringWithQueue:]_block_invoke-[CSVoiceTriggerEnabledMonitor Remote Darwin _checkVoice TriggerEnabled] DarwinCSVoiceTriggerStatistics queue-[CSVoiceTrigger Statistics init]_block_invokech%tu-[CSAudioSampleRateConverter create SampleRateConverterWithInASBD: outASBD: 1132@?0^18^{AudioBufferList =I [1{AudioBuffer=II^v}]}16^^{AudioStreamPacketDescription}24-[CSAudioSampleRateConverter convertSampleRateOfBuffer:]-[CSSoftwareUpdateCheckingMonitor _startMonitoringWithQueue:]-[CSSoftware UpdateCheckingMonitor _stopMonitoring]-[CSSoftwareUpdateCheckingMonitor _checkSoftware UpdateCheckingState] com.apple.duetscheduler.restartCheckNotification-[NSNumber (XPCObject) _cs_initWithXPCObject:]-[NSNumber (XPCObject) _cs_xpcObject]+[CSUtils (Audio Hardware) is Remote DarwinWithDeviceId:]+[CSUtils (AudioHardware) _gibraltarHasBuilt In Mic] MKBUserSessionIDcom.apple.mobile.keybagd.lock_status-[CSScreen LockMonitor _startMonitoringWithQueue:]_block_invoke-[CSScreen LockMonitor _stopMonitoring]-[CSScreenLockMonitor screenLockStateChanged] LockedUnlocked-[NSData (XPCObject) _cs_initWithXPCObject:] Audio/VideoAlarmCSVolumeMonitor queue-[CSVolumeMonitor _startMonitoringWithQueue:]-[CSVolumeMonitor fetchVolume FromAVSystemController For AudioCategory:]_block_invoke-[CSVolumeMonitor systemControllerDied:]-[CSVolumeMonitor startObserving System Volumes]-[CSVolumeMonitor
_startObserving SystemControllerLifecycle ] com.apple.corespeech.CSAccessorySiriClientBehaviour Monitor-[CSAccessorySiriClientBehavior Monitor notifyWillStartStreamWithContext: option: for Accessory:]_block_invoke-[CSAccessory SiriClient Behavior Monitor
notifyDidStartStreamWithContext: successfully: option: with EventUUID: for Accessory:]_block_invoke-[CSAccessorySiriClientBehavior Monitor notifyWillStopStream: reason: forAccessory:]_block_invoke-[CSAccessorySiriClientBehaviorMonitor
notifyDidStopStream: reason: withEventUUID: forAccessory:]_block_invokecom.apple.Siri.SiriLockscreenEnabledChanged/System/Library/PrivateFrameworks/ SiriFoundation.framework/SiriFoundationSRFUserDefaultsController-[CSSRFUserSetting Monitor _startMonitoringWithQueue:]-[CSSRFUserSetting Monitor _stopMonitoring]-[CSSRFUserSetting Monitor didReceiveSRFUserSettingChanged:]-[CSBluetoothWirelessSplitterMonitorImplDarwin updateSplitterState: should Disable Speaker VerificationInSplitterMode:]-[CSBluetoothWirelessSplitterMonitorImplDarwin splitterState]-[CSBluetoothWirelessSplitterMonitorImplDarwin _startMonitoringWithQueue:]-[CSBluetoothWirelessSplitterMonitorImplDarwin _stopMonitoring]-[CSAudioRouteChangeMonitor _startMonitoringWithQueue:] CSAudioRouteChangeMonitor.m-[CSAudioRouteChangeMonitor _stopMonitoring]-[CSAudioRouteChangeMonitor getHearstConnected:]-[CSAudioRouteChangeMonitor hears tConnected]-[CSAudio RouteChangeMonitor getHearstRouted:]-[CSAudio RouteChangeMonitor hearst Routed]-[CSAudioRouteChangeMonitor getSiriInputSource OutOfBand:]-[CSAudioRouteChangeMonitor siriInputSourceOutOfBand]-[CSAudio RouteChangeMonitor getJarvisConnected:]-[CSAudioRouteChangeMonitor jarvisConnected] com.apple.coreaudio.Borealis Toggled-[CSVoiceTriggerEnabledMonitor _startMonitoringWithQueue:]_block_invokeONOFF-[CSVoiceTriggerEnabledMonitor _startMonitoringWithQueue:]-[CSVoiceTriggerEnabledMonitor _stopMonitoring]-[CSVoiceTriggerEnabledMonitor checkVoiceTriggerEnabled]-[CSSmartSiriVolumeManager initWithSamplingRate: withAsset:]-[CSSmartSiriVolumeManager CSAlarmMonitor: didReceive AlarmChanged:]-[CSSmartSiriVolumeManager CSTimer Monitor: didReceive Timer Changed:]-[CSSmartSiriVolumeManager CSVolumeMonitor: didReceiveMusicVolume Changed:]-[CSSmartSiriVolumeManager CSVolumeMonitor: didReceiveAlarmVolumeChanged:]-[CSSmartSiriVolumeManager CSAutomaticVolume Enabled Monitor: didReceiveEnabled:] CSCore SpeechServicesListener-[CSCoreSpeech ServicesListener listen] com.apple.corespeech.corespeechservices-[CSCoreSpeech ServicesListener _servicesListenerShould AcceptNewConnection:] core speech.xpc-[CSCoreSpeechServices Listener listener:shouldAcceptNewConnection:]-[CSCore SpeechServicesListener getTestResponse:] Test-[CSCoreSpeechServicesListener setDelay InterstitialSounds: Level: completion:]-[CSCore SpeechServicesListener getTriggerCount:]-[CSCoreSpeechServicesListener clearTriggerCount:]-[CSCoreSpeech ServicesListener getFirstPassRunningMode:] CSAudioInjectionTvRemoteEngine CSAlarmMonitor queue-[CSAlarmMonitor _startMonitoringWithQueue:]-[CSAlarmMonitor _stop Monitoring] audioURL: %@, numberOfChannels: %lu, scaleFactor: %fCSActivationEventNotifier-[CSActivationEvent Notifier notifyActivationEventSynchronously: completion:]-[CSActivationEvent Notifier notifyActivationEvent: completion:]_block_invoke-[CSActivationEvent Notifier notifyActivationEvent: deviceId: activation Info: completion:]_block_invoke-[CSActivationEvent Notifier _createXPCClientConnection]+[ CSRemoteDeviceProtocolInfo LocalDevice ProtocolInfo] protocolVersion=%lu, deviceCategory=%lu, buildVersion=%@, device ProductVersion=%@, deviceProductType=%@protocol Version deviceCategorydeviceProductVersiondevice ProductTyperouteis RemoteDevice remoteDeviceUIDremoteDeviceProductIdentifierremoteDeviceU IDString%@ {route = %@, isRemoteDevice = %d, remoteDeviceUID = %@, remoteDeviceProductIdentifier = %@, remoteDeviceUIDString BuiltInMicrophoneDeviceCSVoiceTriggerEventInfoProvider Queue-[CSVoiceTriggerEvent Info Provider
= %@}
fetchVoice Trigger InfoWith Audio Context: trigger InfoProviding: resultVoice Trigger Info: resultRTSTrigger Info:]_block_invokev24@?0@"NSDictionary"8@"NSDictionary"16-[CSVoiceTrigger Event InfoProvider fetch Voice Trigger InfoWithAudioContext: trigger InfoProviding: resultVoice Trigger Info: resultRTSTriggerInfo:]-[CSVoiceTriggerEnabledPolicy MacWith Remote Darwin _addVoiceTriggerEnabledConditions]_block_invoke-[CSListeningEnabled PolicyWatch _addListeningEnabledConditions]_block_invoke-[CSAudioRecordDeviceIndicator updateWithLatestRecordContext:] CSHostDaemonMac-[CSHostDaemonMac daemon Did Launch]-[CSHostDaemonMac _daemonWillShutdown]-[CSHost Daemon Mac onUserSession Active:]-[CSHostDaemonMac onUserSession Resign:]-[CSHost DaemonMac _registerKillSignal]-[CSHostDaemonMac onHangupSignal]-[CSHost DaemonMac on TerminationSignal]-[CSHost DaemonMac
CSLanguageCodeUpdateMonitor: didReceive LanguageCodeChanged:] NumMedian P95MaxMinAvgStdWarmupaccessible-extendedaccessible- maximumFirstPkt LatencyTrailing Pkt Latency Trailing Pkt Speech Latency+ [CSEndpointLoggingHelper getMHClientEventByMhUUID:]+[CSEndpointLoggingHelper reportMHEndpointer AccessibleContextEvent With Threshold Type: MhId:]+[CSEndpointLogging Helper reportServerEndpointWithMhId:]-[CSEndpointLatency Info addPktInfoWithTimestamp: arrivalTimestamp: currentMachTime:]-[CSEndpointLatencyInfo report]-[CSEndpointLatencyInfo _emitMHEndpoint Latency Info: withRequestMHUUID:]-[CSAttSiriRCHandler initWithEndpointer Node:uresNode:]-[CSAttSiriRCHandler processRCWithId: duration : LrnnScore: Lrnn Threshold:taskId: force Accept: completionHandler:]-[CSAttSiriRCHandler processRCWithId: duration: lrnnScore: lrnnThreshold:taskId: forceAccept: completionHandler:]_block_invokev20@?0c8@"NSArray"12-[CSAttSiriRCHandler getMitigation DecisionForRCIdWithCompletion: completion:] CoreSpeechFailed to create rootless dir at path: %@, status: %d, errno: %d, err: %sCoreSpeechRootless-[NSFileManager (Rootless) convertToRootlessDirectoryAtPath: error:] Failed to convert path: %@ to rootless, status: %d, errno: %d, err: %sCSAudioInjectionXPC Queue-[CSAudioInjectionXPC createAudio Injection DeviceWithType: deviceName: deviceID:productID: completion:]-[CSAudioInjectionXPC injectAudio:toDeviceWithUUID: with ScaleFactor: completion:]-[CSAudioInjectionXPC injectAudio: to DeviceWithUUID: withScaleFactor: completion:]_block_invoke-[CSAudioInjectionXPC injectAudio: to DeviceWithUUID: withScaleFactor: with NumChannels: completion:]-[CSAudioInjectionXPC injectAudio:toDeviceWithUUID: with ScaleFactor: with NumChannels: completion:]_block_invoke-[CSAudioInjectionXPC
injectAudio:toDeviceWithUUID: with Scale Factor: with NumChannels: completion:]_block_invoke_2-[CSAudioInjectionXPC connectDeviceWithUUID: completion:]-[CSAudioInjectionXPC disconnectDeviceWithUUID: completion:]-[CSAudioInjectionXPC disconnect DeviceWithUUID: completion:]_block_invoke-[CSAudioInjectionXPC primaryInputDeviceUUIDWithCompletion:] + [CSUtils (Statistics) distributionDictionary:]average:stddev:q24@?0@8@16CSXPCClient Reply QueueCSXPCClient connection Queue-[CSXPCClient connect]_block_invokecom.apple.core speech.corespeechd.xpc-[CSXPCClient _sendXPCClient Type]-[CSXPCClient prepareAudioProviderWithContext: clientType: error:]activate ReasondynamicAttribute dictationRequestBundleIddeactivateOptionsetDuckOthers OptionaudioDevice IDduckLevelr amp DurationenableMiniDuckingalert TypeforceSetAlertsoundPathalertStartTime-[CSXPCClient alertStartTime]_block_invokealert BehaviorsetMeterEnable channelNumberpower-[CSXPCClient peak PowerForChannel:]_block_invoke-[CSXPCClient average Power ForChannel:]_block_invoke-[CSXPCClient audioMetric]_block_invoke-[CSXPCClient audioStreamWithRequest: stream Name: error:]v24@?0@"CSAudio Stream"8@"NSError"16-[CSXPCClient audioStreamWithRequest: streamName:completion:]-[CSXPCClient audioStreamWithRequest: streamName:completion:]_block_invoke-[CSXPCClient prepareAudioStreamSync: request: error:]-[CSXPCClient prepareAudioStream: request: completion:]-[CSXPCClient acousticSLResultForContext: completion:]-[CSXPCClient acousticSLResultForContext: completion:]_block_invoke_2acousticSLResult-[CSXPCClient acousticSLResultForContext: completion:]_block_invoke-[CSXPCClient triggerInfoForContext: completion:]-[CSXPCClient audioStreamId]-[CSXPCClient audioChunkFrom: to:]-[CSXPCClient audioChunkFrom: to: channelIdx:]-[CSXPCClient audioChunkToEndFrom:]-[CSXPC Client audioChunkToEndFrom: channelIdx:]-[CSXPCClient saveRecordingBuffer From: to: toURL:]-[CSXPCClient saveRecording BufferToEndFrom: toURL:]-[CSXPCClient holdAudioStreamWithDescription: timeout:]-[CSXPCClient cancelAudioStreamHold:]-[CSXPCClient is Recording]-[CSXPCClient setAnnounceCallsEnabled: withStreamHandle ID:]-[CSXPCClient attach TandemStream: toPrimaryStream: completion:] device IDsession ID-[CSXPCClient audioSessionIdForDeviceId:] sampleCount -[CSXPCClient hostTimeFromSampleCount:]_block_invokereplyHostTime-[CSXPCClient hostTimeFromSample Count:]hostTime-[CSXPCClient sampleCountFromHostTime:]_block_invokereplySampleCount-[CSXPCClient sampleCount FromHostTime:]option-[CSXPCClient _handleListenerEvent:]-[CSXPCClient handleAlertProviding Delegate Message Body:]did FinishAlertPlaybackerror DomainerrorCode-
_handleListenerMessage:]-[CSXPCClient handleListener Error:]-[CSXPCClient
[CSXPCClient handleSessionProviding DelegateMessageBody:]interruptionContext-[CSXPCClient
_handleSessionProviding DelegateBeginInterruptionWithContext:]willSetAudio Session ActivedidSetAudioSessionActivestreamHandleIdInvalidationflagdidChangeContextFlag-[CSXPCClient handleSessionInfoProviding DelegateMessage Body:] notification Info-[CSXPCClient handleSessionInfoProviding DelegateInterruption Notification:]-[CSXPCClient handleSessionInfoProviding Delegate RouteChangeNotification:]-[CSXPC Client handleSessionInfoProvidingDelegateMediaServicesWere LostNotification:]-[CSXPCClient handleSessionInfoProviding DelegateMediaServicesWere Reset Notification:]-[CSXPCClient _handleStreamProvidingDelegateMessageBody:] CSOpportuneSpeakBehavior Monitor-[CSOpportuneSpeakBehavior Monitor notifyWillStartStreamWithContext: audio Provider UUID: option:]_block_invoke-[CSOpportune SpeakBehavior Monitor notifyDidStartStreamWithContext: audioProvider UUID: successfully: option:]_block_invoke-[CSOpportune SpeakBehavior Monitor notifyWillStopStream:]_block_invoke-[CSOpportuneSpeakBehavior Monitor notifyDidStopStream:]_block_invokeRemote VAD Align Queue-[CSOpportuneSpeakListener startListenWithOption: completion:]-[CSOpportuneSpeakListener _startRequestWithCompletion:]_block_invoke-[CSOpportuneSpeakListener _startRequestWithCompletion:]-[CSOpportuneSpeakListener stopListenWithStateReset: completion:]_block_invoke-[CSOpportune SpeakListener stopListenWithStateReset:completion:]-[CSOpportuneSpeakListener audioStreamProvider: audioBuffer Available:]-[CSOpportune SpeakListener spgEndpoint Analyzer: hasSilenceScore Estimate: clientProcessed Audio TimeMS:]-[CSAudioMeterProvidingProxy handleXPCMessage:messageBody: client:]-[CSAudioMeterProvidingProxy_handleMeterProvidingRequestTypeSetMetering Enabled Message: message Body: client:]-[CSAudioMeter ProvidingProxy _handleMeterProvidingRequestTypeUpdate MetersMessage:messageBody: client:] v16@?0c8f12-[CSAudioMeterProvidingProxy
_handleMeterProvidingRequestTypePowerMessage: messageBody: client: powerType:] Serial CSAsset Manager queue-[CSAsset Manager initWithDownload Option:]-[CSAsset Manager initWithDownloadOption:]_block_invoke ENABLEDDISABLED-[CSAsset Manager setAssetDownloading Option:]_block_invoke-[CSAsset Manager _fetchRemoteMetaData]-[CSAsset Manager canFetchRemoteAsset:]-[CSAsset Manager CSLanguageCodeUpdateMonitor: didReceive LanguageCodeChanged:]-[CSAsset Manager _createPeriodicalDownloadTimer]-[CSAsset Manager _createPeriodicalDownload Timer ]_block_invoke-[CSAsset Manager _startPeriodicalDownload]-[CSAsset Manager _stopPeriodicalDownload] num ImplicitUttnumExplicitUttnumFirstPassTriggersPer DayvtStatistics vtStatistics FirstPass PeakScoreHSvtStatistics FirstPass PeakScoreJSvtStatis ticsFirstPass Trigger SourcevtStatisticsRecognizerScoreHSvtStatisticsRecognizerScoreJSvtStatistics Trigger ScoreHSvtStatistics TriggerScoreJSvtStatistics MitigationScor evtStatistics Invocation TypeIdvtStatisticsFirstPass Detection Time vtStatistics RepetitionSimilarityScore firstPassDailyMetadatafirstPassDailyMetadataConfigVersionfirst PassDailyMetadataBuildVersionfirstPass DailyMetadataHardware Sample RatefirstPass DailyMetadataMitigationAssetVersionis JSEnabled-[CSDarwinPreventSystemSleepManager _acquire PreventSystemSleepAssertionWithTimeout:]-[CSDarwin Prevent SystemSleepManager acquireAssertionForActiveUser]-[CSDarwinPreventSystemSleepManager acquireAssertionForIdleUser]-[CSUserSession ActiveMonitor handleConsoleEnabled:] NSWorkspace/System/Library/Frameworks/AppKit.framework/ AppKitNSWorkspaceSessionDid Become ActiveNotification NSWorkspaceSession Did ResignActiveNotification CGSSessionCopyCurrentSession Properties/System/Library/Frameworks/ CoreGraphics.framework/CoreGraphicskCGSSessionOnConsoleKeyCSAudioInjection Remora Engine-[CSAudioInjectionRemora Engine dealloc]-[CSAudioInjection RemoraEngine start]_block_invokeCSSpeechManager Asset Query Queue-[CSSpeechManager startManager]-[CSSpeech Manager _setupSpeaker RecognitionWithVTAsset:]-[CSSpeechManager _setupSpeaker RecognitionWith VTAsset:]_block_invoke-[CSSpeech Manager _setupVoiceTriggerWithCompletion:]VoiceTrigger Queue-[CSSpeechManager _setupVoiceTriggerWithCompletion:]_block_invoke-[CSSpeechManager _startVoiceTrigger]-[CSSpeechManager _startAllClients]-[CSSpeechManager registerSpeechController:]-[CSSpeechManager registerSiriClientProxy:]v32@?0@"NSNumber"8@"CSAudioProvider"16^c24-[CSSpeechManager audioProviderWithContext: error:]-[CSSpeechManager audioProviderWithContext: error:]_block_invokev32@?0Q8q16@"NSError"24-[CSSpeech Manager audioProviderWithStreamID:]_block_invoke-[CSSpeechManager _getAudioRecorderWithError:]-[CSSpeech Manager audioProvider Invalidated: streamHandleId:]_block_invoke-[CSSpeech Manager audio RecorderWillBeDestroyed:]_block_invoke-[CSSpeechManager voiceTriggerAssetHandler: endpointId: didChangeCachedAsset:]-[CSSpeech Manager reinitialize Voice TriggerWithAsset:]-[CSSpeechManager _handleClearLoggingFile Timer ]-[CSSpeechManager _createClear LoggingFileTimer]-[CSSpeechManager _startClear LoggingFilesTimer]-[CSSpeechManager _setupForHearstIfNeededWithPrepareCompletion: completion:]-[CSSpeech Manager _setupForJarvis IfNeededWithPrepareCompletion: completion:]-[CSSpeechManager _setupForRemoraIfNeededWithCompletion:]-[CSSpeechManager
_teardownForBluetoothDevice] com.apple.corespeech.powerassertion PreventUserIdleSystemSleepPreventSystemSleep-[CSPreventSystemSleepPowerAssertion invalidate] Timeout ActionRelease-[CSPreventSystemSleep Power Assertion acquireAssertionForType: withTimeout: assertionId: details:]Allows Device Restart-[CSPreventSystemSleepPowerAssertion _releaseAssertion For AssertionId : details:]FlexKwdSpotter recognizer_flexKwd.json flexKwdConfigFile flexKwd.Thresholds flexKwd ThresholdsFile-[NSDictionary (XPCObject) _cs_initWithXPCObject:]-[NSDictionary (XPCObject) _cs_initWithXPCObject:]_block_invoke%@-[NSDictionary (XPCObject) _cs_xpcObject]_block_invokev32@?0@8@16^c24-[CSVoiceTrigger AwareZeroFilter resetWithSample Rate: contains Voice Trigger: voiceTrigger Info:]-[CSRemote VADCircularBuffer copySamplesFrom: to:] copy SamplesCSMicUsageReporter-[CSMicUsageReporter _getAuditToken:]-[CSMicUsage Reporter reportMicUsage:]_block_invokev16@? O@"STMutableMediaStatus DomainData"8-[CSMicUsageReporter
_reportsDynamic ActivityAttribute: bundleId:] CORESPEECH_DAEMON_ACCESS_AUDIO_FOR_DICTATIONCORESPEECH_DAEMON_ACCESS_AUDIO_FOR_SIRICORE SPEECH_DAEMON_ACCESS_AUDIO_FOR_ SIRI_AND_DICTATIONSTMediaStatusDomainPublisherUnable to find class %s/System/Library/PrivateFrameworks/SystemStatus.framework/Contents/MacOS/ SystemStatusSTActivityAttribution STDynamic Activity Attribution Publisher-[CSNetworkAvailability Monitor _startMonitoringWithQueue:]-[CSNetworkAvailabilityMonitor _stopMonitoring]-[CSNetworkAvailabilityMonitor _availability Changed ]-[CSPostBuildInstallService registerPostBuildInstallService]-[CSPostBuildInstallService registerPostBuildInstallService]_block_invoke YesNocom.apple.cs.postinstall-[CSPostBuildInstallservice _performPostBuildInstallWith Completion:]_block_invoke firstPassScorefirstPassJarvis TriggerMode Voice TriggerFirstPassJarvis Queue-[CSVoiceTriggerFirstPassJarvis start]-[CSVoiceTriggerFirstPassJarvis _setAsset:]-[CSVoiceTriggerFirstPassJarvis clearTriggerCandidate ]-[CSVoiceTriggerFirstPassJarvis _didStartAudioStream]-[CSVoiceTriggerFirstPassJarvis didStopAudioStream]-[CSVoiceTriggerFirstPassJarvis audioStreamProvider: didStopStreamUnexpectly:]_block_invoke-[CSVoiceTriggerFirstPassJarvis _handleAudio Chunk:] com.apple.siri.myriad.jarvis-[CSVoiceTriggerFirstPass Jarvis keywordAnalyzer NDEAPI: hasResultAvailable: forChannel:]-[CSVoiceTriggerFirstPass Jarvis activationEvent NotificationHandler: event: completion:]-[CSVoiceTriggerFirstPassJarvis spgEndpointAnalyzer DidDetectEndpoint:]_block_invoke-[CSVoiceTriggerFirstPassJarvis
_handleJarvis Voice Trigger FromDeviceId: activation Info: trigger HostTime: completion:]_block_invoke-[CSVoiceTriggerFirstPassJarvis
_handleJarvis Voice TriggerFromDeviceId: activation Info: trigger HostTime: completion:]-[CSVoiceTriggerFirstPassJarvis
_didDetectKeywordFromDeviceId: activation Info: triggerHostTime: completion:]_block_invoke-[CSVoiceTriggerFirstPassJarvis _notifyJarvis VoiceTrigger Reject]-[CSVoiceTrigger FirstPassJarvis _reportJarvis VoiceTriggerFire]-[CSVoiceTriggerFirstPassJarvis _handleSecondPass Result: deviceId: error:]-
[CSVoiceTriggerFirstPassJarvis _handleSecondPass Result: deviceId: error:]_block_invokeCSVoiceTriggerFirstPassJarvis-[CSVoiceTriggerFirstPass Jarvis siriClientBehavior Monitor: didStartStreamWithContext: successfully: option: withEventUUID:]-[CSVoiceTriggerFirstPassJarvis
siriClientBehavior Monitor: didStartStreamWithContext: successfully: option:withEventUUID:]_block_invoke-[CSVoiceTriggerFirstPassJarvis siriClientBehavior Monitor: didStopStream: withEventUUID:]_block_invoke-[CSVoiceTriggerFirstPass Jarvis
siriClientBehavior Monitor: willStopStream: reason:]_block_invoke-jarvis+ [CSVoiceTriggerFirstPassJarvis
jarvisAudioLogDirectory]noise LevelDBmusicLevelDBmusic PlaybackVolumeDBalarmVolume finalTTSVolumeisAlarmPlaying is Timer Playingis LKFSProcessPausedremoveVoiceTriggerSamples-[CSSmartSiriVolume initWithSampling Rate: asset:]-[CSSmartSiriVolume startSmartSiriVolume]_block_invokePAUSED-[CSSmartSiriVolume _startListenPolling]-[CSSmartSiriVolume _startListen Polling With Interval: completion:]-[CSSmartSiriVolume _startListen PollingWithInterval: completion:]_block_invoke-[CSSmartSiriVolume _startListenWithCompletion:]_block_invoke_2-[CSSmartSiriVolume _startListenWithCompletion:]_block_invoke-[CSSmartSiriVolume _startListenWithCompletion:]-[CSSmartSiriVolume _stoplistening]-[CSSmartSiriVolume _stopListening ]_block_invoke-[CSSmartSiriVolume initializeMediaPlayingState]_block_invokeplayingNOT playing-[CSSmartSiriVolume initializeMediaPlayingState]-[CSSmartSiriVolume initializeAlarmState]_block_invokefiringNOT firing-[CSSmartSiriVolume initializeTimer State]_block_invoke-[CSSmartSiriVolume _setAsset:]-[CSSmartSiriVolume estimate Sound Levelby Sound Type:]_block_invoke-[CSSmartSiriVolume _pauseSSVProcessing]_block_invoke-[CSSmartSiriVolume resume SSVProcessing ]_block_invoke-[CSSmartSiriVolume
audioStreamProvider: audioBuffer Available:]_block_invoke-[CSSmartSiriVolume audioStreamProvider: didStopStreamUnexpectly:]-[CSSmartSiriVolume didDetectKeywordWithResult:]-[CSSmartSiriVolume did DetectKeywordWithResult:]_block_invoke-[CSSmartSiriVolume
estimatedTTSVolume For Noise LevelAndLKFS: LKFS:]_block_invoke-[CSSmartSiriVolume combine ResultsWithOptimalFromNoise: andOptimalFromLkfs: withUserOffset:]-[CSSmartSiriVolume CSMediaPlaying Monitor: didReceiveMediaPlaying Changed:]_block_invoke-[CSSmartSiriVolume didReceiveAlarmChanged:]_block_invoke-[CSSmartSiriVolume didReceiveTimer Changed:]_block_invoke-[CSSmartSiriVolume CSAudioServerCrashMonitorDid ReceiveServerRestart:]-[CSSmartSiriVolume siriClientBehavior Monitor: didStartStreamWithContext: successfully: option: withEventUUID:]_block_invoke-[CSSmartSiriVolume _setStartAnalyze Time:]-[CSSmartSiriVolume getVolumeForTTSType: withOverrideMediaVolume: WithRequestTime:]allocator<T>::allocate (size_t n) 'n' exceeds maximum supported sizeestimatedTTSVolumedebugLogPathcom.apple.core speech.nnvad-[CSNNVADEndpointAnalyzer resetForNewRequestWithSampleRate: recordContext:]_block_invoke-[CSNNVADEndpointAnalyzer handleVoiceTriggerWithActivationInfo:]_block_invoke-[CSNNVADEndpoint Analyzer processAudioSamplesAsynchronously:]_block_invokev24@? 0@"CSAudioChunk"8Q16-[CSNNVADEndpointAnalyzer stopEndpointer]-[CSNNVADEndpointAnalyzer recordingStopped For Reason:]_block_invoke-[CSNNVADEndpointAnalyzer _shouldEnterTwo ShotAtAudioTime InSecs:]-[CSNNVADEndpointAnalyzer _checkSNObservationForStartpoint:]-[CSNNVADEndpointAnalyzer _checkSNObservation ForEndpoint:]-[CSNNVADEndpointAnalyzer request: didProduce Result:]-[CSNNVADEndpointAnalyzer request: didProduce Result:]_block_invoke-[CSNNVADEndpointAnalyzer request: didFailWithError:]-[CSNNVADEndpointAnalyzer reportEndpointAtTsInSecs:]-[CSNNVADEndpointAnalyzer _emitEndpoint DetectedEventWithEndpoint Time: endpointBufferHostTime:]-[CSNNVADEndpointAnalyzer preheat]-[CSAtt SiriFlexKwdNode initWithAtt SiriController:]-[CSAttSiriFlexKwdNode startWithContext: audioStreamId:]_block_invoke-[CSAttSiriFlexKwdNode attSiriAudioSrc NodeDidStartRecording:successfully: error:]-[CSAttSiriFlexKwdNode trigger ReportedFromFlxKwdSpotter:]-[CSRawAudio InjectionProvider init] CSRawAudio InjectionProvider-[CSRawAudio InjectionProvider dealloc]-[CSRawAudioInjection Provider setContext: completion:]-[CSRawAudio Injection Provider setCurrentContext: streamHandleId: error:]-[CSRawAudio Injection Provider prepareAudioStreamRecord: recordDevice Indicator: error:]-[CSRawAudio Injection Provider startAudioStreamWithOption: recordDevice Indicator: error:]/var/mobile/ darwin_test.wavrb-[CSRawAudio Injection Provider stopAudioStreamWithRecordDevice Indicator: error:]-[CSRawAudio InjectionProvider isRecordingWithRecordDevice Indicator:] RawAudio Injection-[CSRawAudio Injection Provider prewarmAudioSessionWithStreamHandleId: error:]-[CSRawAudio InjectionProvider activate Audio SessionWithReason: streamHandleId: error:] com.apple.MobileAsset.VoiceTriggerAssets Mac-[CSAssetController init] Serial CSAsset Controller queueV1 Assets Clean-up queue-[CSAssetController _cleanUpMobileAssetV1Directory]-[CSAssetController assetOfType: Language:]-[CSAssetController allInstalledAssetsOfType: Language:]q24@?0@"MAAsset"8@"MAAsset"16v32@?0@"MAAsset"8Q16^c24-[CSAssetController assetOfType: Language: completion:]-[CSAsset Controller assetOfType: Language: compatibilityVersion: completion:] %Luv24@?0@"MAAsset"8@"NSError"16-[CSAsset Controller installed AssetOfType: Language:]-[CSAssetController installedAssetOfType: Language: completion:]-[CSAssetController _installedAssetOfType: with Language:]-[CSAssetController _installedAssetOfType:query: withLanguage: completion:]_block_invoke-[CSAssetController _findLatest InstalledAsset:]-[CSAssetController _assetQueryForAssetType:]-[CSAssetController _runAssetQuery: completion:]-[CSAsset Controller _runAssetQuery: completion:]_block_invoke-[CSAsset Controller fetchRemoteMetaOfType: allowRetry:]-[CSAssetController fetchRemote MetaOfType: allowRetry:]_block_invokev20@?0@"NSError"8c16-[CSAsset Controller _fetchRemoteAssetOfType: withLanguage: completion:]-[CSAssetController _fetchRemoteAssetOfType: with Language: query: completion:]_block_invoke_2-[CSAssetController _fetchRemoteAssetOfType: with Language: query: completion:]_block_invoke-[CSAssetController _downloadAssetCatalogForAssetType:complete:]_block_invoke-[CSAssetController _updateFromRemoteToLocalAssets: for AssetType: completion:]-[CSAssetController _downloadAsset: withComplete:] v16@?0d8-[CSAssetController _downloadAsset: withComplete:]_block_invoke-[CSAssetController _startDownloadingAsset: progress: completion:] v16@?0@"MAProgressNotification"8+[ CSAssetController (Utils)
addKeyValuePair ForQuery: assetType:] com.apple.MobileAsset.SpeechEndpointAssetscom.apple.Mobile Asset.SpeechEndpoint AssetsWatchcom.apple.Mobile Asset.SpeechEndpointAssets TVcom.apple.Mobile Asset.Language Detector Assetscom.apple.MobileAsset.AdBlocker Assetscom.apple.MobileAsset.SpeakerRecognition Assetsrtblobsadkblobsblobmajor VersionminorVersionsignaturecertrtlocalemapjarvislocalemapadklocalemapconfig_rtv2.txtconfig_rt.txtconfig.txt-[CSAsset (RTModel) createRTModelWith Locale:]nohash-[CSAsset (RTModel) latestHearstRTModelForLocale:]-[CSAsset (RTModel) rtModelWithAccessory RTModelType: majorVersion: minorVersion: locale:]-[CSAsset (RTModel) LocaleMapWith Name:]%02x -[CSVoiceTriggerEnabled PolicyDarwin _addVoiceTriggerEnabled Conditions]_block_invoke-[CSAudioSession Providing Proxy CSXPC ConnectionReceivedClientError:clientError: client:]-[CSAudioSession ProvidingProxy dealloc]-[CSAudioSessionProviding Proxy handleXPCMessage:message Body: client:]-[CSAudioSessionProviding Proxy
_handleSessionProviding RequestTypePrewarm Message:client:]-[CSAudioSession Providing Proxy _handle Session ProvidingRequestTypeActivateMessage: message Body:client:]-[CSAudioSession Providing Proxy _handleSessionProviding RequestTypeDeactivateMessage: messageBody: client:]-[CSAudio Session ProvidingProxy _handleSessionProvidingRequestTypeSetDuckOthersOption: messageBody: client:]-[CSAudio Session ProvidingProxy _handleSessionProviding RequestTypeDuckAudio Device: messageBody: client:]-[CSAudioSession ProvidingProxy
_handleSessionProvidingRequestTypeDuck DefaultOutputAudio Device: message Body: client:]-[CSAudioSession Providing Proxy
_handleSessionProviding RequestTypeEnable MiniDucking: messageBody: client:] ENABLEDISABLE enableSmartRoutingConsideration-[CSAudioSessionProviding Proxy _handleSessionProvidingRequestTypeEnableSmartRoutingConsideration: message Body: client:]-[CSAudioSessionProviding Proxy audioSessionProvider: provider Invalidated:] + [ CSAudioStreamRequest defaultRequestWithContext:] + [CSAudioStreamRequest requestForLpcmRecordSettingsWithContext:] + [CSAudioStreamRequest=requestForOpusRecord SettingsWithContext:] + [CSAudio StreamRequest requestForSpeexRecordSettingsWithContext:][requires HistoricalBuffer = %@][ UseCustomized RecordSettings = %@][lpcmIsFloat = %@][isSiri %@][sampleRate = %lf][ numberOfChannels = %lu] requiresHistoricalBufferuseCustomized RecordSettings audioFormatsampleRatelpcmBitDepthlpcmIsFloatNumberOfChannels encoderBitRateisSirirecordContext-[CSSpringboardStartMonitor _startMonitoringWithQueue:]-[CSSpringboardStartMonitor _stopMonitoring]-[CSSpringboardStart Monitor _checkSpringBoardStarted] com.apple.springboard.finished startupdequemeta_version.jsonenrollment_version.json CSP2P_CommandType_KeyCSP2P_CommandDict_Keycore speechcom .apple.siridebug.request.genericcom.apple.siridebug.command.remote.heysiricom.apple.siridebug.command.parallel.recordingcom.apple.siridebug.command.transfer.voiceprofilecom.apple.siridebug.command.query.voiceprofilecom.apple.siridebug.command.reverse.transfer.voice profilecom.apple.siridebug.command.fetch.voiceprofilecom.apple.siridebug.command.voiceprofile.update.triggercom.apple.siridebug.command.fetch.parallelrecordingcom.apple.siridebug.command.transfer.parallelrecordingcom.apple.siridebug.command.fetch.voicegrading datacom.apple.siridebug.command.transfer.voicegradingdatacom.apple.siridebug.command.delete.
voiceprofileCSP2P_RemoteHeySiriEnable_KeyCSP2P_Remote
HeySiriStatus_KeyCSP2P_RemoteRecordingStart_KeyCSP2P_RemoteRecordingStatus_KeyCSP2P_VoiceProfileData_KeyCSP2P _VoiceProfileFileName_KeyCSP2P_VoiceProfile SpeakerName_KeyCSP2P_VoiceProfileLocale_KeyCSP2P_VoiceProfileDataType_KeyCSP2P_VoiceProfileSegment_KeyCSP2P_ VoiceProfile TotalSegments_KeyCSP2P_Voice ProfileStatus_KeyCSP2P_Voice Profile ProfileId_KeyCSP2P_VoiceProfileHomeUserId_KeyCSP2P_VoiceProfile RelativeFilePath_ KeyCSP2P_VoiceProfileSiriProfileId_KeyCSP2P_VoiceProfileAppDomain_KeyCSP2P_Voice ProfileOnboardTimeStamp_KeyCSP2P_Voice Profile Transfer Completed_KeyCSP2P_ VoiceProfileRecordedData_KeyCSP2P_VoiceProfile RemoteFileName_KeyCSP2P_Voice DataToBeGraded_KeyCSP2P_VoiceFileNameToBeGraded_KeyCSP2P_GradingDataTransferStatus_ KeyCSP2P_Peer Identifier_KeyCSP2P_Voice Profile PeerName_KeyCSP2P_IsDataCompressed_KeyCSP2P_UncompressedDataSize_KeyCSP2P_GradingBatchTransferID_KeyCSP2P_ VoiceProfileiTunesUserID_Key CSP2P_VoiceProfileiTunesPassword_Keyremote-triggered-almost- rejectedssrmetassvmetavteimultiuseracousticSLmetacom.apple.corespeech.p2psvc-[CSP2PService process RemoteCommandWithPayload: fromPeer: withReply:]_block_invoke-[CSP2PService sendCoreSpeechGrading DataToNearby Peer]_block_invoke-[CSP2PService sendVTNearMissGradingDataToCompanion]_block_invoke-[CSP2PService sendVoiceProfileUpdatedMessageToNearby PeerForLocale:]_block_invoke-[CSP2PService sendAcoustic Grading DataToNearby Peer]_block_invoke-[CSP2PService sendGeckoSpeech Logs To Companion]_block_invoke-[CSP2PService _process Remote HeySiriCommandWithRequest: fromSenderID: with Reply:]-[CSP2PService _compressFilesInDirectory: matching Predicate: sortedByCreation Date: compressedFileAvailable:]-[CSP2PService _compressFilesInDirectory: matching Predicate: sortedByCreation Date: compressedFileAvailable:]_block_invokeq24@?0@"NSURL"8@"NSURL"16wavjsonc24@? O@"NSURL"8@"NSDictionary"16-[CSP2PService _sendVoiceTrigger GradingDataToPeerId:]_block_invokev52@?0@"NSString"8@"NSData"16Q24Q32c40@"NSError"44spxopx-[CSP2PService _sendCoreSpeechGradingDataToPeerId:]_block_invoke_2-[CSP2PService _sendCoreSpeechGradingDataToPeerId:]_block_invoke-[CSP2PService _sendGecko Speech Logs To PeerId:]_block_invoke_2-[CSP2PService _sendGecko SpeechLogs To PeerId:]_block_invokeGecko-v24@?0@"NSUUID"8@"NSError"16 [a-fA-F0-9]{8}-[a-fA- F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{12}.wav.json-[CSP2PService _sendCoreSpeech Magus Grading DataToPeerId:]_block_invoke_2-[CSP2PService _sendCoreSpeech MagusGradingDataToPeerId:]_block_invoke-[CSP2PService _sendGradingData: withFile Name: toPeerId: with CompressedFlag: with UncompressedDataSize: withBatchId: withRetain FileFlag: with FilePrefix: with Completion:] fileDatafileNamepeerId%@%@-[CSP2PService
_sendGradingData: withFile Name: to PeerId: with Compressed Flag: with UncompressedDataSize: withBatchId: with RetainFileFlag: withFilePrefix: with Completion:]_block_invokev24@ ?0@"NSDictionary"8@"NSError"16-[CSP2PService _receiveParallelRecordingFromPeerId: recording Info: withReply:] % @_% @q-[CSP2PService _receiveVoiceGradingDataFrom PeerId: request Info: withReply:]%@.%@.%@suppressnotification%@.%@-[CSP2PService
_receiveVoice Profile From PeerId: voiceProfile Info: with Reply:] CoreSpeechCacheaudiotdticom.apple.siri.corespeech.voiceprofilelist.change-[CSP2PService _processVoice ProfileDeleteCommandWithRequest: fromSenderID: withReply:]_block_invoke-[CSP2PService
_processGrading DataFetchCommandWithRequest: fromSenderID: with Reply:]-[CSP2PService
_processVoice ProfileListQueryCommandFromPeerId: request Info: with Reply:]yyyyMMddHH mms sv24@?0@"NSString"8@"NSError"16voiceprofiles-[CSP2PService _getHomeUserIdForSharedSiriId: withCompletion:]-[CSP2PService _getHomeUserIdForSharedSiriId: with Completion:]_block_invoke homeUserId query for siriProfileId %@ timedout !-[CSP2PService processFetchVoice Profile CommandFromPeerId: request Info: withReply:] Caches/Voice Trigger/SATUpdate_%d %d_% @-[CSP2PService _send VoiceProfile: to PeerId:]td/audiotdti/audioti/audio-[CSP2PService _sendVoiceProfile: toPeerId:]_block_invoke-[CSP2PService
_process Reverse Transfer Voice Profile CommandFromPeerId: request Info: withReply:]-[CSP2PService processVoice ProfileUpdate TriggerFromPeerId: request Info: withReply:]-[CSP2PService _sendVoiceProfileUpdate TriggerToPeerId: forLocale:]_block_invoke-SL.json-synced.wav-[CSP2PService _sendAcoustic GradingDataToPeerId:]_block_invoke_2-[CSP2PService _sendAcousticGradingDataToPeerId:]_block_invokeLogs/CoreSpeech/spid/grading-[CSP2PService _createDirectory IfDoes Not Exist:] VoiceProfileStoretrained_users.json Caches-[CSP2PService _getContentsOfDirectory:] sleepCallbackCSMacWake Sleep Monitor-[CSMacWakeSleep Monitor _startMonitoringWithQueue:]userIdentityClassificationuserClassified@distinctUnionOfObjects.sharedUserId-[CSAttSiriSSRNode stop]_block_invoke-[CSAttSiriSSRNode addReceiver:]_block_invoke-[CSAttSiriSSRNode setPrefetchedAsset:]_block_invokec24@?0@"SSRVoice Profile"8@"NSDictionary"16-[CSAttSiriSSRNode filtered VoiceProfileArray:]-[CSAttSiriSSRNode _setup SSRControllerWithAudioContext: with VoiceTriggerEvent Info:]-[CSAttSiriSSRNode _setupLeadingUtteranceLogger]-[CSAttSiriSSRNode _setupSpeaker Recognition For Profiles: With VTEvent Info: WithLocale:] BPVT-[CSAttSiriSSRNode _refreshSpeaker RecognitionAssets]_block_invoke_2-[CSAttSiriSSRNode refresh Speaker Recognition Assets]_block_invoke-[CSAttSiriSSRNode _refreshSpeaker RecognitionAssets]-[CSAttSiriSSRNode startXPCConnection]-[CSAttSiriSSRNode
CSSpeaker Recognition Asset Download Monitor: did InstallNewAsset: assetProvider Type:]_block_invoke-[CSAttSiriSSRNode speakerRecognitionController: hasSpeaker Info:]_block_invoke-[CSAttSiriSSRNode speakerRecognitionController: hasSpeaker Info:]_block_invoke_2-[CSAttSiriSSRNode speakerRecognitionController: hasSpeaker Info:]-[CSAttSiriSSRNode CSLanguageCodeUpdateMonitor: didReceiveLanguageCodeChanged:]-[CSAttSiriSSRNode speakerRecognition Finished Processing: withFinalSpeaker Info:]_block_invoke-[CSAttSiriSSRNode _processSpeakerRecognitionResult:]-[CSAttSiriSSRNode _mapScoresToSharedSiriId:]-[CSAttSiriSSRNode mapScoresToSharedSiriId:]_block_invokevalid_scoresinvalid_scores -[CSAttSiriSSRNode _stopProcessing] - surfacePsdWithAudioChunk:]-
[CSAttSiriSSRNode _stopProcessing]_block_invoke-[CSAttSiriSSRNode attSiriAudioSrc Node Did Stop:]_block_invoke-[CSAttSiriSSRNode _logSpeakerFalse Trigger MitigationScore: with Speaker Match Score: with SpeakerScore Threshold: withAudioDuration: withSuccess:] createFloatArraysqrtcomplex part zero vecfft magnitudes arraynormalized fft magnitudes Hamming Windowmyriad_audio_analysiswindowed array for signal estimation-[CSMyriad PHash [CSMyriadPHash pHash: Length:]-[CSMyriad PHash _copyAudio DataInBuffer: bufferSize: copyLength: fromAudio Data:]-[CSMyriad PHash _generateMyriad Info: hsStart: triggerEnd: writeFile: score: triggerSource: channel: audioProviderUUID: absolute Time:] + [CSMyriadPHash createRemoraHashResult: goodness: confidence: firstPassTriggerEndTime: frac:] + [CSMyriad PHash createHashResult: goodness: confidence: absTime: frac:] + [CSMyriad PHash decodeWithMyriad PHash:]+[CSMyriad PHash writeHashResult IntoFile:]com.apple.siri.myriad.apayload+ [CSMyriad PHash notifyAudioHashNotification]+[CSMyriad PHash notifyAudioHashless Notification]-[CSMyriad PHash _audioLogDirectory]-[CSMyriad PHash generatePHashFromVoice Trigger Info:writeFile:]_block_invokeyyyy_MM_dd- HHmmss.SSS%@/%@%@.wav Myriad-+[CSMyriad PHash (SignalEstimate) signalEstimateWithBuilder:] CSXPCListener-[CSXPCListener listen]-[CSXPCListener _handleListenerEvent:]-[CSXPCListener _handleListenerError:]-[CSXPCListener handleNewRemoteConnection:]corespeech.corespeechd.xpc-[CSXPCListener CSXPCConnection Received ClientError: clientError: client:]_block_invokeOEPO.OSPG.nnetcs_hep.jsonversion CSEndpointerAsset Manager queue-[CSEndpointer Asset Manager init]-[CSEndpointerAsset Manager checkFirstUnlocked]-[CSEndpointer Asset Manager CSLanguage CodeUpdateMonitor: didReceiveLanguageCodeChanged:]_block_invoke-[CSEndpointer Asset Manager CSAsset Manager Did DownloadNewAsset:]_block_invoke-[CSEndpointer Asset Manager CSFirstUnlockMonitor: didReceiveFirstUnlock:]_block_invoke-[CSEndpointer Asset Manager getCurrentHEPAsset]-[CSEndpointer Asset Manager _update OEPAssetsWithLanguage:]-[CSEndpointer Asset Manager _notifyAssets Update]-[CSEndpointer Asset Manager _fetchEndpoint Mobile AssetWithLanguage:] ModelInfo=:-[CSEndpointer Asset Manager getOEP Version FromPath:]-[CSEndpointer Asset Manager _getFakeEndpointAsset]-[CSAudioStream initWithAudioStream Provider: streamName:stream Request:]-[CSAudioStream dealloc]-% @-[CSAudioStream startAudioStreamWithOption: completion:]-[CSAudioStream stopAudioStreamWithOption: completion:]_block_invoke-[CSAudioStream isStreaming]-[CSAudioStream updateAudioStreamStartTime In SampleCount:]-[CSAudioStream audioStreamProvider: didStopStream Unexpectly:]-[CSAudioStream audioStreamProvider: did HardwareConfigurationChange:]-[CSAttSiriEndpointer Node initWithAttSiriController:] CSAtt SiriEndpointerNode queueCSAttSiriEndpointerNode Latency Queue-[CSAtt SiriEndpointerNode addReceiver:]_block_invoke-[CSAttSiriEndpointerNode removeReceiver:]_block_invoke-[CSAttSiriEndpointerNode reset For NewRequestWithSample Rate: recordContext: recordOption: voice Trigger Info:]_block_invoke_2-[CSAttSiriEndpointerNode endpointer:didDetectHardEndpointAtTime: with Metrics:]_block_invoke-[CSAttSiriEndpointerNode
_reportHardEndpoint ToXPCClientWithTime: endpointerMetrics:] com.apple.fides.borealis.record-creationcom.apple.fides.borealis -[CSVoiceTriggerFidesClient _LogDESRecordWithType: result:] triggerSampleCount PHSMigrationStatuscsChunk-[CSVoiceTriggerFidesClient logDESRecordWithType: result:]_block_invoke-[CSVoiceTrigger Fides Client voiceTriggerDid Detect Keyword: deviceId:]_block_invoke-[CSVoiceTriggerFidesClient
voiceTriggerDid DetectNearMiss: deviceId:]_block_invoke near-misstriggerspeaker-rejectnumChannelsnumSamplessampleByteDepthstartSampleCount-[CSAudioTimeConversionProviding Proxy handle XPCMessage: messageBody: client: audioStreamHandleId:]-[CSAudioTimeConversionProvidingProxy _handleXPCTimeConvert Providing TypeHostTime FromSampleCountMessage: messageBody: client: streamHandleId:]-[CSAudioTimeConversionProvidingProxy _handleXPCTimeConvert Providing TypeSampleCount FromHostTimeMessage: messageBody: client: streamHandleId:]-[NSString (XPCObject)
_cs_initWithXPCObject:] Bluetooth A2DPOutputBluetoothHFPBluetooth LEMicrophoneBuiltInSpeakerHeadphonesMicrophoneWired HDMI OutputLine InUSBAudioADAudio Session PortOther-[CSSiriAudioSession currentInputRoute]_block_invokev24@?0^v8Q16-[CSSiriAudioSession currentOutputRoute]_block_invoke_3_AudioObjectGetScalar Array_AudioDeviceRegisterForChanged Notificationv16@?0^v8_AudioObjectGetCFTypeRefv12@? 018_AudioObjectGet IntValue-[CSAudioAlert Providing Proxy handleXPCMessage: messageBody: client:]-[CSAudioAlertProviding Proxy _handleAlertProvidingRequestTypeSetAlert SoundMessage: message Body: client:]-[CSAudioAlert ProvidingProxy _handleAlertProvidingRequestTypePlayAlert SoundMessage: messageBody: client:]-[CSAudioAlert ProvidingProxy
_handleAlertProvidingRequestTypePlayRecordStartingAlertAndResetEndpointerMessage: message Body: client:]-[CSAudio Alert ProvidingProxy _handleAlertProvidingRequestTypeAlertStartTimeMessage: messageBody: client:]-[CSAudio Alert ProvidingProxy
_handleAlertProvidingRequestTypeConfigureAlert Behavior: messageBody: client:]-[CSAudioAlertProviding Proxy audioAlertProviding DidFinishAlertPlayback: of Type: error:]-[CSAlwaysOnProcessor State Monitor _startMonitoringWithQueue:]_block_invokecom.apple.audio.AOP.enable-[CSAlwaysOnProcessorStateMonitor _startMonitoringWithQueue:]_block_invoke_2-[CSAlwaysOnProcessor State Monitor _stopMonitoring]-[CSAlwaysOnProcessorStateMonitor _didReceiveAOPListeningStateChange:] CSVoiceTriggerFirstPassHearstAP-[CSVoiceTriggerFirstPassHearst AP _setAsset:]-[CSVoiceTriggerFirstPassHearstAP _startListenWithAudio ProviderUUID: completion:]-[CSVoiceTriggerFirstPassHearstAP _startListenWithAudioProvider UUID: completion:]_block_invoke_2-[CSVoiceTriggerFirstPassHearstAP startListenWithAudioProviderUUID: completion:]_block_invoke-[CSVoiceTriggerFirstPassHearst AP _stopListening]-[CSVoiceTriggerFirstPassHearst AP _stopListening]_block_invoke-[CSVoiceTriggerFirstPassHearstAP audioStreamProvider: audioBuffer Available:]_block_invoke-[CSVoiceTriggerFirstPassHearstAP _keywordAnalyzerNDAPI: hasResultAvailable: forChannel:]Hearst AP first pass triggered-[CSVoiceTriggerFirstPassHearstAP _handleSecondPassResult: deviceId: error:] Voice Trigger SecondPass-[CSVoiceTriggerFirstPass HearstAP _shouldHearst APModeEnabled]-[CSVoiceTriggerFirstPassHearstAP siriClientBehavior Monitor: didStartStreamWithContext: successfully: option: withEventUUID:]-[CSVoiceTriggerFirstPassHearstAP siriClientBehavior Monitor: didStartStreamWithContext: successfully: option: withEventUUID:]_block_invoke-[CSVoiceTriggerFirstPassHearstAP siriClientBehavior Monitor: didStopStream: withEventUUID:]_block_invoke-[CSVoiceTriggerFirstPassHearstAP
siriClientBehavior Monitor: willStopStream: reason:]_block_invokeCSManualDuckingHandler Queue-[CSManual DuckingHandler resetDucking]_block_invoke-[CSManualDuckingHandler duckDefaultOutputAudioDeviceWithDucked Level: ramp Duration:]_block_invoke-[CSManual DuckingHandler duckAudioDeviceWithDeviceID: duckedLevel: rampDuration:]_block_invoke-[CSManualDuckingHandler
defaultAudioRouteChangeMonitor Mac: didReceived OutputAudioRouteChangeEvent:]_block_invokecom.apple.corespeechTokenBestScoreStartSampleIdEndSample Idcom.apple.flxkwd-[CSFLexKeywordSpotter startKeywordSpottingWithCompletion:]_block_invoke_2-[CSFlexKeywordSpotter startKeyword Spotting With Completion:]_block_invokeUnexpected[CSOtherAppRecordingStateMonitor handleOtherAppRecordingStateChange:]-[CSOtherAppRecordingStateMonitor _systemController Died:]-[CSAudioStartStreamOption (AVVC) avvcStartRecordSettingsWithAudioStreamHandleId:] CSAudioInjectionBuiltInEngine-[CSAudioInjectionBuiltInEngine dealloc]-[CSAudioInjectionBuiltInEngine start]_block_invokeSampleCountHostTime-[CSAudioInjectionBuiltInEngine getBestSample CountWithOption:]-[CSAudioInjection BuiltInEngine audioEngineBuffer Available: audioStreamHandleId: buffer: remote VAD: atTime:]_block_invoke-[CSVoiceTriggerEnabled PolicyHorseman
_addVoiceTriggerEnabledConditions]_block_invoke-[CSAutomatic VolumeEnabled Monitor observeValueForKeyPath: ofObject: change: context:]_block_invoke + [ CSVoiceTriggerEnabledPolicy Helper siriInCallPolicy] CSEndpointerSettings:::disableEndpointer [disableEndpointer = %@]-[CSFallbackAudioSession Release ProvidingProxy handleXPCMessage: message Body: client:]-[CSFallbackAudioSessionRelease ProvidingProxy _handleDeactivateAudioSessionRequestMessage: messageBody: client:] CSAttSiriAudioSrcNode queue-[CSAttSiriAudioSrcNode initWithMasterAudioStream: name:]-[CSAttSiriAudioSrc Node addReceiver:]_block_invoke-[CSAttSiriAudioSrc Node dealloc]-[CSAttSiriAudioSrcNode
audioStreamProvider: didStopStream Unexpectly:]_block_invoke-[CSAttSiriAudioSrcNode _handleDidStop]-[CSAttSiriAudioSrc Node _fetchAudio DecoderForTV:]-[CSSiriLauncher notifyBuiltInVoice Trigger: myriad PHash: completion:]_block_invoke Trigger was during a ringtone-[CSSiriLauncher notifyWakeKeywordSpokenInBuiltInMic:]_block_invoke-[CSSiriLauncher notifyCarPlayVoice Trigger Prewarm: deviceId: completion:]_block_invoke-[CSSiriLauncher notifyCarPlayVoiceTrigger: deviceId: myriad PHash:completion:]_block_invoke-[CSSiriLauncher notifyWakeKeywordSpokenCarPlay: deviceId:]_block_invoke-[CSSiriLauncher notifyBluetooth Device Voice Trigger: deviceId: completion:]_block_invoke-[CSSiriLauncher notifyWake KeywordSpokenBluetoothDevice: deviceId:]_block_invoke-[CSSiriLauncher deactivateSiriActivationConnectionWithReason: withOptions: withContext:]_block_invoke-[CSSiriLauncher notifyDarwinVoiceTrigger: deviceId: myriad PHash: myriad LateActivation Expiration Time: completion:]_block_invokeSerial CSEvent Monitor queue-[CSEventMonitor _startMonitoringWithQueue:] CSEventMonitor.m-[CSEventMonitor _stop Monitoring]hfpTriggerDuringPhoneCallVoiceTriggerEnabledKeyVoice Trigger First Pass QueuebuiltInVoiceTrigger-%@-[CSBuiltInVoiceTrigger start]-[CSBuiltInVoiceTrigger start]_block_invoke-[CSBuiltInVoice Trigger setAsset:]-[CSBuiltInVoiceTrigger _setAsset:]-[CSBuilt In VoiceTrigger _setAsset:]_block_invoke-[CSBuiltInVoice Trigger _setIsSecondPassRunning:]_block_invoke@"CSAudioChunk"16@?0Q8-[CSBuiltInVoice Trigger _transitVoice Trigger Status: force:]_block_invokeendis-[CSBuiltInVoiceTrigger transitAOPMode:]-[CSBuilt In VoiceTrigger _startListenPollingWithInterval: completion:]-[CSBuiltInVoiceTrigger _startListen PollingWithInterval: completion:]_block_invoke-[CSBuiltInVoiceTrigger _startListenWithCompletion:]-[CSBuiltInVoiceTrigger _startListenWithCompletion:]_block_invoke-[CSBuiltInVoiceTrigger _startListenWithCompletion:]_block_invoke_2-[CSBuiltInVoice Trigger requestStartAudioStreamWithSource: context: completion:]-[CSBuiltInVoiceTrigger stop Listening]-[CSBuiltInVoiceTrigger _stopListening]_block_invoke-[CSBuiltInVoiceTrigger _startVoiceTriggerWithCompletion:]-[CSBuiltInVoiceTrigger _startVoiceTriggerWithCompletion:]_block_invoke-[CSBuiltInVoice Trigger _startAPVoiceTriggerWithCompletion:]-[CSBuiltInVoice Trigger _APModeValidation Timer Fired]_block_invoke-[CSBuilt In VoiceTrigger _startAOPVoice Trigger]-[CSBuiltInVoiceTrigger shouldHandleAOPVoice Trigger]-[CSBuiltInVoice Trigger stopAPVoice Trigger]-[CSBuiltInVoiceTrigger _stopAPVoiceTrigger]_block_invoke-[CSBuiltInVoiceTrigger _stopAOPVoice Trigger]-[CSBuiltInVoiceTrigger audioStream Provider: didStopStream Unexpectly:]-[CSBuiltInVoice Trigger _handleAudioChunk:]-[CSBuiltInVoice Trigger keywordAnalyzerNDAPI: hasResultAvailable: for Channel:]APVoiceTriggerDetected-[CSBuiltInVoice Trigger _handle Voice TriggerSecondPassWithSource: deviceId: event: audio Provider UUID: firstPass Info:]-[CSBuilt InVoice Trigger _handleVoiceTriggerSecondPassWithSource: deviceId: event: audio Provider UUID: firstPass Info:]_block_invoke-[CSBuilt InVoice Trigger takeFullWake Assertion]-[CSBuiltInVoice Trigger _releaseFullWakeAssertion]-[CSBuiltInVoiceTrigger _handleSecondPass Result: deviceId: error:]-[CSBuiltInVoice Trigger siriClientBehavior Monitor: didStartStreamWithContext: successfully: option: withEventUUID:]_block_invoke-[CSBuiltInVoice Trigger siriClientBehavior Monitor: didStopStream: withEventUUID:]_block_invoke-[CSBuiltInVoiceTrigger siriClientBehavior Monitor: willStopStream: reason:]_block_invoke-[CSBuiltInVoice Trigger CSAudio ServerCrashMonitor DidReceiveServerCrash:]-[CSBuiltInVoice Trigger CSAudioServerCrashMonitor Did ReceiveServerRestart:] AOPVoice Trigger-[CSBuiltInVoiceTrigger activationEvent NotificationHandler: event: completion:]_block_invoke_2-[CSBuilt InVoiceTrigger createSecondPassIfNeededWithFirstPassSource:]-[CSBuiltInVoice Trigger _notifyEvent:]-[CSBuiltInVoiceTrigger cancelSecondPassRunning]_block_invoke-[CSBuiltInVoice Trigger updateCurrentSplitterState: shouldDisableSpeaker VerificationInSplitter Mode:]-[CSBuiltInVoiceTrigger
CSAudioRouteChangeMonitor: didReceiveAudioRouteChangeEvent:]_block_invoke-[CSBuiltInVoiceTrigger receivedJarvisConnectionEvent:] ConnectDiconnect-[CSBuiltInVoice Trigger receivedHearst RoutedEvent:] RoutedNot Routed-[CSBuiltInVoice Trigger received HearstConnectedEvent:]-[CSBuiltInVoice Trigger _receivedSiriInputSourceOutOfBand Event:]isOutOfBandis NotOutOfBand-[CSBuiltInVoice Trigger attSiriStateMonitor: didRecieveAttSiriStateChange:]_block_invoke-[CSBuiltInVoice Trigger CS MacWakeSleep Monitor: deviceWillSleep:]-[CSBuiltInVoice Trigger CSMacWake Sleep Monitor: deviceTurnedOn:]-[CSBuilt In VoiceTrigger didTransitFrom: to: by:]-[CSBuiltInVoiceTrigger
didIgnoreEvent: from:]FirstPass RunningFirstPassRunning AOPOnlyFirstPassStateAOPtoAPTransition FirstPass StateStopunknown (%tu) KCSFirstPassEventBarge InOnkCSFirstPassEventBarge InOffkCSFirstPassEventStartAPFailed kCSFirstPassEventStartAPSucceedk CSFirstPassEventStopped-[CSBuiltInVoiceTrigger _firstPassVoice TriggerSignalEstimate]_block_invoke-[CSBuiltInVoice Trigger _firstPassVoiceTriggerSignalEstimate ] NA-[CSEndpointerProxy reset For NewRequestWithSample Rate: recordContext: recordOption: voice TriggerInfo:]-[CSEndpointerProxy resetForVoiceTriggerTwoShotWithSample Rate:]-[CSEndpointerProxy preheat]-[CSEndpointerProxy endpointer: didDetectStartpointAtTime:]-[CSEndpointerProxy endpointer: didDetectHardEndpointAtTime: withMetrics:]-[CSEndpointerProxy endpointer: detectedTwoShot At Time:]-[CSEndpointerProxy endpointerModelVersion]-[CSEndpointerProxy update Endpointer Threshold:]-[CSEndpointerProxy LogHybridEndpoint FeaturesWithEvent:locale:]siriVolume.json smartSiriVolumenoise LevelChannelBitsetLKFSChannelBitsetDistanceChannelBitsetenergyBufferSizenoise Lower Pe rcentilenoise Upper Percentile LKFSLower Percentile LKFSUpper Percentilenoise Time Constantnoise MicSensitivityOffsetnoise MicSensitivityOffsetDeviceSimpleLKFSTimeConstantL KFSMicSensitivityOffsetnoise TTSMapping InputRange Lownoise TTSMapping InputRangeHigh noise TTSMappingOutputRange Lownoise TTSMappingOutputRange HighLKFSTTSMapping InputRang eLowLKFSTTSMapping InputRange HighLKFSTTSMappingOutputRangeLowLKFSTTSMappingOutputRange HighuserOffsetInputRangeLowuserOffsetInputRange HighuserOffsetOutputRange Lowus erOffsetOutputRange HighTTSVolume Lower LimitDBTTSVolume Upper LimitDBnoiseWeightSSVCAMaxFrameSize SSVCA Voice TriggerBased TTS ValidForSeconds SSVCA SmartSiriVolume UnsyncedM etricLogsToRetainSSVCASmartSiriVolumeSynced MetricLogs To RetainSSVCA Voice Trigger InitialSilenceDurationSeconds SSVCADistance InputBufferDurationSeconds SSVCAListenPollingIntervalAtStartInSecondsSSVCADefault ZeroFloating Point Value SSVCAAnnouncementStatus FetchTimeout MSSSVCADefaultOutputTTS Volume SSVCANoiseActivityCountThresholdSSVCAS peakerDistance FarBoost FactorSSVCASpeaker Distance Mid Boost FactorSSVCASpeakerDistance NearBoost FactorSSVCADistance ModelConfidence ThresholdSSVCAMinimumLinearSoundLevel SSVCAMaximumLinear Sound LevelSSVCALinearToDecibelConstant MultiplierSSVCADecibelToLinearLogBaseSSVCASignalToSigmoid Noise DilationFactorSSVCASignalToSigmoid MusicDilat ionFactorDeviceDefaultSSVCASignalToSigmoid Music Dilation FactorDeviceSimpleSSVCA SignalToSigmoid Music DilationFactorDevice Simple2SSVCASignalToSigmoid SpeechDilationFac torSSVCASignalToSigmoid Noise VSpreadSSVCASignalToSigmoid MusicVSpreadDeviceDefaultSSVCASignalToSigmoid MusicVSpreadDeviceSimpleSSVCASignalToSigmoidMusicVSpreadDevice Simple2SSVCASignalToSigmoidSpeech VSpreadSSVCASignalToSigmoid Noise VOffsetSSVCASignalToSigmoid MusicVOffsetDeviceDefaultSSVCASignalToSigmoid MusicVOffsetDeviceSimpleS SVCASignalToSigmoid MusicVOffsetDeviceSimple2SSVCASignalToSigmoidSpeechVOffsetSSVCASignalToSigmoidNoiseHOffsetSSVCASignalToSigmoidMusicHOffsetDeviceDefaultSSVCASig
nalToSigmoidMusicHOffsetDeviceSimpleSSVCASignalToSigmoid MusicHOffsetDeviceSimple2SSVCASignalToSigmoidSpeechHOffsetSSVCASignalToSigmoidMusicSteepness DeviceDefaultS
SVCASignalToSigmoidMusicSteepness DeviceSimpleSSVCASignalToSigmoidMusicSteepness DeviceSimple2SSVCASignalToSigmoidNoiseSteepnessSSVCASignalToSigmoidSpeechSteepnessS SVCADBTOTTSMinimum OutputSSVCADBTOTTSMaximumOutputSSVCADBTOTTSTransitionPointSSVCADBTOTTSPreTransitionOffsetSSVCADBTOTTSPreTransition MultiplierSSVCADBTOTTSPostTran sitionOffsetSSVCADBTOTTSPost Transition DCSSVCADBTOTTSPostTransition MultiplierSSVCAMinimum DistanceUpdateWait PeriodSecondsSSVCANoiseActivityThresholdSSVCANoiseResult sBufferSizeSSVCAMusicResults BufferSizeSSVCA DefaultSpeechStrengthSSVCADefaultMusicStrengthSSVCANoiseActivityHistoricalSampleCountSSVCADspCoefsCountSSVCADspNumStageSSSVCADistanceResults BufferSizeSSVCAExponentialDistanceHistoryDegradationFactorSSVCADistanceResultSampleCountToleranceSSVCAMusicHistoricalSamplesInSecondsSSVCADeviceSimpleOutputMin TargetDBSSVCADeviceSimpleOutputMaxTargetDBSSVCADeviceSimpleOutputSlope SSVCA DeviceSimple2OutputSlopeSSVCADeviceSimpleMinTargetDBSSVCADeviceSimple MaxTargetDBSSVCADeviceSimpleDBToSystem VolSlope SSVCADeviceSimpleMicSensitivityOffsetSSVCADeviceSimplePre Trigger SilenceSampleCountSSVCA DeviceSimple2OutputMinTargetD BSSVCADeviceSimple2OutputMaxTargetDBSSVCAMinTTSSystem Volume SSVCAMaxTTSSystemVolume SSVCAMinTTSSystemVolume Simple2SSVCAMaxTTSSystem Volume Simple2SSVCAUserIntentValid ForSeconds SSVCAUserIntentVolume IncreaseFactorSSVCAUserIntentVolume DecreaseFactorSSVCAUserIntentPermanentOffsetFactorDeltaSSVCAUserIntentPermanentOffsetFactorLower BoundSSVCAUserIntentPermanentOffsetFactor UpperBoundSSVCADevice Simple MinTTSVolume SSVCADeviceSimpleMaxTTSVolume SSVCADeviceDefaultASVOffMinTTSVolume SSVCADeviceSimple ASVOffMinTTSVolume SSVCADeviceSimple2ASVOffMinTTS Volume SSVCADeviceDefaultMicSensitivityOffsetSSVCAVolume HalfLifeSeconds SSVCAHistorical VolumeBufferSizeSSVCAMaximumC ompensatedSpeechLevelNearField-[CSAsset (SmartSiriVolume) SSVCASignalToSigmoidMusicDilation FactorDeviceSimple]-[CSAsset (SmartSiriVolume) SSVCASignalToSigmoid Music VSpreadDevice Simple]-[CSAsset (SmartSiriVolume) SSVCASignalToSigmoidMusicVOffsetDeviceSimple]-[CSAsset (SmartSiriVolume) SSVCASignalToSigmoid MusicHOffsetDeviceSimple]-[CSAsset (SmartSiriVolume) SSVCASignalToSigmoidMusicSteepness DeviceSimple]-[CSAsset (SmartSiriVolume) SSVCADeviceSimpleASVOffMinTTSVolume]-[CSAsset (SmartSiriVolume) _getNumber FromASVDictionaryForKey: category: default:] com.apple.mobile.keybagd.first_unlock-[CSFirstUnlockMonitor _startMonitoringWithQueue:]-[CSFirst UnlockMonitor _stopMonitoring]-[CSFirst UnlockMonitor _checkFirstUnlocked]-[CSAudioServerCrashMonitor _startMonitoringWithQueue:]_block_invoke-[CSAudioServerCrashMonitor _startMonitoringWithQueue:] CSSelfVoice Trigger Detector Queue-[CSSelfTriggerDetector _setAsset:]-[CSSelfTriggerDetector _startListenPolling]-[CSSelf Trigger Detector _startListen PollingWithInterval: completion:]-[CSSelfTrigger Detector _startListen PollingWithInterval: completion:]_block_invoke-[CSSelfTriggerDetector _startListenWithCompletion:]_block_invoke_2-[CSSelfTriggerDetector _stopListening]_block_invoke-[CSSelfTrigger Detector handleEnablePolicyEvent:]-[CSSelfTrigger Detector audioStream Provider: didStopStreamUnexpectly:]-[CSSelfTriggerDetector audioStreamProvider: audioBuffer Available:]_block_invoke-[CSSelfTrigger Detector _keywordAnalyzer NDAPI: hasResult Available: forChannel:]-[CSSelfTriggerDetector siriClient Behavior Monitor: didStartStreamWithContext: successfully: option: withEventUUID:]_block_invoke-[CSSelfTrigger Detector siriClientBehavior Monitor: didStopStream: withEventUUID:]_block_invoke-[CSSelfTrigger Detector siriClientBehavior Monitor: willStopStream: reason:]_block_invoke-[CSSelfTriggerDetector CSAudioServerCrashMonitor DidReceiveServerRestart:]_block_invoke + [CSUtils (AudioFile) readAudioChunksFrom: block:]playbackDevice TypeList%@ {recordDeviceInfo = %@, playbackRoute = %@, playback Devices = %@-[CSSpeechEndpointAssetMetaUpdateMonitor _startMonitoringWithQueue:]-[CSSpeechEndpointAssetMetaUpdateMonitor _stopMonitoring]-[CSSpeechEndpointAssetMetaUpdateMonitor _didReceiveNewSpeechEndpointAssetMetaData] com.apple.MobileAsset.SpeechEndpoint AssetsWatch.ma.cached-metadata-
updatedcom.apple.MobileAsset.SpeechEndpointAssetsTV.ma.cached-metadata-updatedcom.apple.MobileAsset.SpeechEndpointAssets.ma.cached-metadata- updatedCSAttSiriStateMonitor queue-[CSAttSiriStateMonitor
updateState:]_block_invokeLiminalprogChecker.jsonprogressive CheckerConfigFilecontionusConversationConfigFile checkerConfigvalid InputOrigins thresholds shadowModeUnsp ecifiedVoiceTriggerButton Pressc32@?0@8@16^c24v24@?0@8^c16CSSiriAssertion Monitor queue-[CSSiriAssertionMonitor init]-[CSSiriAssertionMonitor stop Monitoring]-[CSSiriAssertionMonitor enable AssertionReceived]_block_invoke-[CSSiriAssertion Monitor disableAssertionReceived]_block_invokeCSAudioSession InfoProvider-[CSAudioSession InfoProvider CSAudioServerCrashMonitor DidReceiveServerCrash:]_block_invoke-[CSAudio Session InfoProvider CSAudioServerCrash Monitor Did ReceiveServerRestart:]_block_invoke + [CSUserIdentityClassifier pickTopScoringProfileIdFromScores:] + [CSUserIdentityClassifier classifyUserIdentity For: with Scores: withAsset:] Confident Known Unsure1UnsureN+ [CSUserIdentityClassifier stringFromClassificationCategory:] RequestContextDetectedTokenTriggerMachTime Trigger AbsStartSampleId{attendingCtx: %@, detctedToken: %@, trigger MachTime=%llu, triggerStartSampleId=%llu}CS Audio ProviderCSAudio Provider Stream Handle QueueCSAudio Provider logging-[CSAudio Provider dealloc]-[CSAudioProvider setStreamState:]-[CSAudio Provider setAudio Recorder:]_block_invoke-[CSAudio Provider supportsDuckingOnCurrentRouteWithError:]-[CSAudio Provider setCurrentContext: error:]-[CSAudioProvider setCurrentContext: error:]_block_invoke-[CSAudioProvider _audioStreamWithRequest: stream Name: error:]-[CSAudioProvider attachTandemStream: toPrimaryStream: completion:]_block_invoke_2failed successfully-[CSAudioProvider attachTandemStream: to PrimaryStream: completion:]_block_invoke-[CSAudioProvider _prepareAudioStreamSync: request: error:]-[CSAudio Provider _createCircularBuffer IfNeededWithNumChannel: playbackRoute:]-[CSAudioProvider startAudioStream: option: completion:]-[CSAudio Provider startAudioStream: option: completion:]_block_invoke-[CSAudioProvider prepareAudioStreamSync: request: error:]-[CSAudioProvider prepareAudioStream: request: completion:]-[CSAudio Provider _startAudio Stream: option: completion:]-[CSAudioProvider _startAudioStream: option: completion:]_block_invoke-[CSAudioProvider _startAudioStream: option: completion:]_block_invoke_2-[CSAudioProvider _handleDidStart Audio StreamWithResult: error:]-[CSAudio Provider _handleDidStopAudioStreamWithReason:]-[CSAudio Provider _stopAudioStream: option: completion:]-[CSAudioProvider _stopAudioStream:option: completion:]_block_invoke-[CSAudio Provider _stopAudioStream: option: completion:]_block_invoke_3CSAudioProvider.m-[CSAudioProvider _stopAudioStream: option: completion:]_block_invoke_4-[CSAudioProvider _stopAudioStream: option: completion:]_block_invoke_2-[CSAudio Provider _saveRecordingBuffer From: to: toURL:]_block_invoke-[CSAudioProvider holdAudioStreamWithDescription: timeout:]-[CSAudioProvider holdAudioStreamWithDescription: timeout:]_block_invoke_2-[CSAudio Provider holdAudioStreamWithDescription: timeout:]_block_invoke-[CSAudio Provider cancelAudioStreamHold:]-[CSAudio Provider cancelAudioStreamHold:]_block_invoke-[CSAudioProvider prewarmAudioSessionWithError:]-[CSAudio Provider activateAudioSessionWithReason: dynamicAttribute: bundleID: error:]-[CSAudio Provider _activateAudioSessionWithReason: error:]-[CSAudioProvider _isDuckingOnSpeakerOutputSupportedWithCurrent Route]-[CSAudio Provider deactivateAudioSession: error:]-[CSAudio Provider _deactivate Audio Session: error:]-[CSAudioProvider setDuckOthersOption:]-[CSAudioProvider duckAudioDevice: ducked Level: ramp Duration:]-[CSAudioProvider setAlertSoundFromURL: forType: force:]-[CSAudioProvider playAlertSoundForType:]-[CSAudio Provider _didPlayStartAlertSoundForSiri: audioStream:]-[CSAudioProvider playRecordStartingAlertAndResetEndpointer]-[CSAudioProvider alertStartTime]-[CSAudio Provider trigger InfoForContext: completion:]_block_invoke-[CSAudioProvider _shouldStopRecording]-[CSAudio Provider audioRecorderStreamHandleIdInvalidated:]-[CSAudio Provider audioRecorderWillBeDestroyed:]_block_invoke-[CSAudioProvider _fetchHistoricalAudioAndForwardToStream: remote VAD:]-[CSAudio Provider _scheduleAlert FinishTimeout:]-[CSAudio Provider _schedule Alert Finish Timeout:]_block_invoke-[CSAudio Provider _didReceiveFinishStartAlertPlaybackAt:]-[CSAudio Provider _didReceiveFinishStartAlertPlaybackAt:]_block_invoke_2-[CSAudioProvider _didReceiveFinishStartAlertPlaybackAt:]_block_invoke-[CSAudioProvider audio RecorderBuiltInAudioStreamInvalidated: error:]_block_invoke-[CSAudioProvider audioRecorder Disconnected:]-[CSAudioProvider CSAudioServerCrash Monitor Did ReceiveServerCrash:]-[CSAudio Provider CSAudio ServerCrashMonitorDidReceiveServerRestart:]-[CSAudioProvider
_handleAudioSystemFailure]
StreamInitStreamPreparedStreamStartingStreamSteamingStreamStoppingStreamStoppingWithScheduledStartcom.apple.corespeech.recordingRecording transaction-[CSAudioProvider _releaseRecording TransactionIfNeeded]% @-% @-[CSAudioProvider _onAudioPacketWatchdogFire]-[CSAudioProvider _scheduleDidStart Recording DelegateWatchDog]-[CSAudioProvider _schduleDidStartRecording DelegateWatchDogWithToken:]-[CSAudioProvider _clearDidStartRecording DelegateWatchDog]-[CSAudioProvider _scheduleDidStopRecording DelegateWatchDog]-[CSAudio Provider _scheduleDidStopRecording DelegateWatchDog:]-[CSAudio Provider _clearDidStop Recording DelegateWatchDog]-[CSAudio Provider _updateRemote DeviceIdFromAVVCIfNeeded] speaker RecognitioncombinationWeight implicit Profile Threshold implicit ProfileDeltaThreshold implicitVTThreshold pruningExplicitSA TThresholdpruningExplicit PSR ThresholdpruningSATThresholdpruning PSRThresholdnum Pruning RetentionUttmaxEnrollment Utterances pruningCookie configFileNDAPI voiceTrigger Se condPassAOPimplicit_training_enabledmultiUser HighScore Threshold multiUserLowScore ThresholdmultiUser ConfidentScoreThresholdmultiUserDeltaScore ThresholduseSpeakerRec ognition Asset phrase-[CSAsset (Speaker Recognition) satScore ThresholdForPhId:] recognizer.json-[CSAsset (SpeakerRecognition)
contains MultiUserThresholds ] CSSAC InfoMonitor queue-[CSSACInfoMonitor _startMonitoringWithQueue:]-[CSSAC InfoMonitor _stop Monitoring]-[CSSAC InfoMonitor isDeviceRoleStereo] com.apple.corespeech.darkwake.powerassertion-[CSDarkWake Power AssertionMac initWithDescription: timeout:]-[CSDarkWake Power AssertionMac invalidate]-[CSSpeaker Recognition Asset Download Monitor _startMonitoringWithQueue:]-[CSSpeaker Recognition Asset DownloadMonitor _stopMonitoring]-[CSSpeaker Recognition AssetDownloadMonitor did Installed NewAsset]-[CSSpeaker RecognitionAssetDownloadMonitor trialAssetDownloadMonitorDelegate: did InstallNewAsset: assetType:]com.apple.Mobile Asset.Speaker RecognitionAssets.ma.new-asset-installed-[CSAVCallConnectedMonitor _systemControllerDied:] CSFallbackAudioSession ReleaseProvider-[CSFallbackAudioSessionReleaseProvider fallbackDeactivate AudioSession: error:]_block_invoke-[CSFallbackAudioSession Release Provider fallbackDeactivateAudioSession: error:]-[CSSpeaker Recognition Asset MetaUpdateMonitor _startMonitoringWithQueue:]-[CSSpeaker RecognitionAssetMetaUpdateMonitor _stopMonitoring]-[CSSpeaker RecognitionAssetMetaUpdateMonitor _didReceiveSpeaker RecognitionAssetMetaData] com.apple.MobileAsset.SpeakerRecognitionAssets.ma.cached-metadata- updatedAttSiriAttSiriJSAttSiriCCAttSiriHSmitigationModelConfigFiledefaultAFTMValuenldaConfigFile allowKeywordFile allowKeywordCountuseSpkrIdouresConfig.jsonnldaConfig.jsonallowList.txtHSCSPreMyriad Coordinator Queue-[CSPreMyriad Coordinator _clear PendingRemoraVoiceTrigger]-[CSPreMyriadCoordinator handlePendingRemora VoiceTrigger IfNeeded]-[CSPreMyriad Coordinator handlePendingRemora VoiceTrigger IfNeeded]_block_invoke -[CSPreMyriad Coordinator _clearPendingBuiltInVoice Trigger]-[CSPreMyriadCoordinator handlePending Built In Voice Trigger IfNeeded]-[CSPreMyriadCoordinator handlePending Built In Voice Trigger IfNeeded]_block_invokev32@?0@"NSString"8@"CSPreMyriad Voice TriggerMetaData"16^c24-[CSPreMyriad Coordinator secondPassDidStopForClient: deviceId:]N/A-[CSPreMyriad Coordinator secondPassDid StartForClient: deviceId: withFirstPass Estimate:] AttSiriController queue-[CSAttSiriController siriClientBehavior Monitor: willStartStreamWithContext: option:]-[CSAttSiriController
siriClientBehavior Monitor: didStartStreamWithContext: successfully: option: withEventUUID:]_block_invoke-[CSAttSiriController siriClientBehavior Monitor: didStopStream: withEventUUID:]_block_invoke-[CSAttSiriController
siriClientBehavior Monitor: fetchedSiriClientAudio Stream: successfully:]_block_invoke-[CSAttSiriController
siriClientBehavior Monitor: preparedSiriClientAudioStream: successfully:]_block_invoke-[CSAttSiriController CSSiriEnabled Monitor: didReceiveEnabled:]-[CSAttSiriController _reconfigure RequiredNodes: enforceAttending AudioNode:]-[CSAttSiriController forceBuildGraph:]-[CSAttSiriController
_fetchMitigationAssets]_block_invoke_2-[CSAttSiriController _fetchMitigationAssets]_block_invoke-[CSAttSiriController _fetchVoiceTriggerAssets]_block_invoke_2-[CSAttSiriController _fetchVoiceTriggerAssets]_block_invoke-[CSAttSiriController _setupAudioSrc NodeWithSiriClientStream:] CSAttSiriController-[CSAttSiriController _setupAudioSrc NodeWithSiriClientStream:]_block_invoke-[CSAttSiriController _handleStartProcessingWithRecordContext: completion:]-[CSAttSiriController _handleStartProcessingWithRecordContext: completion:]_block_invoke-[CSAttSiriController _handleStopProcessing]attSiri transaction-[CSAttSiriController _releaseAttSiriTransaction IfNeeded]-[CSAttSiriController handleAttendingAudioStopUnexpectly]_block_invoke-[CSAttSiriController
handleAudioStopUnexpectly]_block_invokekVTPreferences PhraseSpotterEnabled DidChangeDarwin Notification-[CSPhraseSpotterEnabledMonitor checkPhraseSpotterEnabled]- _phraseSpotterEnabledDidChange] CSEndpointMetrics::: totalAudioRecordedCSEndpointMetrics::: endpointBuffer HostTimeCSEndpointMetrics:::
[CSPhraseSpotterEnabledMonitor
featuresAtEndpoint CSEndpointMetrics::: endpointerTypeCSEndpointMetrics::: serverFeatureLatencyDistributionCSEndpointMetrics:::additionalMetricsCSEndpointMetrics:::
=
trailingSilence DurationAtEndpoint [totalAudioRecorded = %f][endpointBuffer HostTime = %llu][ trailingSilence DurationAtEndpoint %f][endpointerType = %lu][ featuresAtEndpoint = %@][additional Metrics = %@] com.apple.corespeech.corespeechd.activation.xpc-[CSActivationXPCClient dealloc]-[CSActivationXPCClient _handleListener Event:]-[CSActivationXPCClient handleListenerError:]-[CSActivationXPCClient notifyActivation Event: completion:]event-[CSAdBlockerAsset Download Monitor _startMonitoringWithQueue:]-[CSAdBlocker Asset Download Monitor _stopMonitoring]-[CSAdBlocker Asset DownloadMonitor _didInstalled NewAdBlocker Asset]-[CSAdBlockerAsset DownloadMonitor
trialAssetDownloadMonitor Delegate: did InstallNewAsset: assetType:] com.apple.Mobile Asset.AdBlocker Assets.ma.new-asset-installed VoiceTriggerAsset ChangeMonitorcom.apple.corespeech.voice trigger asset changevoice trigger xpc service connection client queue-[CSVoiceTriggerXPCConnection _handleClientEvent:]-[CSVoiceTriggerXPCConnection handleClientMessage:client:]-[CSVoiceTriggerXPCConnection _handleClientError:client:]-[CSVoiceTriggerXPCConnection _handleVoiceTriggerXPCServiceMessage:client:]phraseSpotter Bypass bypass Timeout-[CSVoiceTriggerXPCConnection _handlePhraseSpotterBypass Request:] raiseToSpeakBypass-[CSVoiceTriggerXPCConnection _handleVoiceTriggeredSiriSessionCancelled] enableassertiontimestamptriggerStatsCSAudioInjection Engine-[CSAudioInjectionEngine _createDeInterleaver IfNeeded]-[CSAudioInjectionEngine stop]_block_invoke-[CSAudioInjection Engine _readAudioBuffer AndFeed]-[CSAudioInjectionEngine injectAudio:withScaleFactor: outASBD: playbackStarted: completion:]-[CSAudioInjectionEngine stopAudioStream]_block_invoke-[CSAudioInjectionEngine _deinterleave Buffer IfNeeded:]-[CSAudioInjectionEngine
_compensateChannelDataIfNeeded: received NumChannels:] com.apple.siri.SiriDebug.SpeakerVoiceGradingTriggercom.apple.siri.SiriDebug.Remote NearMissGradingTriggercom.apple.siri.SiriDebug.Voice Profile Added Triggercom.apple.siri.SiriDebug.VoiceProfileSyncTriggercom.apple.siri.SiriDebug+ [CSSiriDebug Connection LaunchSiriDebugAppWith Message:]_block_invokev24@?0@"AFSiriResponse"8@"NSError"16com.apple.com.apple.private.+[CSUtils (LanguageCode) getSiriLanguageWithFallback:]+ [CSUtils (LanguageCode) getSiriLanguageWithEndpoint Id: fallbackLanguage:]-[CSHostPowerSource Monitor _startMonitoringWithQueue:]-[CSHost Power SourceMonitor _stopMonitoring]-[CSHostPowerSource Monitor _didReceiveHostSystemStateChangeNotification:]-[CSMyriadSelfTriggerCoordinator selfTriggerDetector: did DetectSelfTrigger:]-[CSContinuousAudioFingerprintEnabled Policy _addContinousAudioFingerprintEnabledConditions]_block_invoke-[CSAudioRouteChangeMonitorImplMac preferredExternalRoute DidChange]-[CSAudio Route ChangeMonitor ImplMac _startMonitoringWithQueue:]-[CSAudioRouteChangeMonitorImplMac _stopMonitoring]-[CSAudioRouteChangeMonitor ImplMac _fetchHearst RoutedStateWithDeviceID:]-[CSAudioRouteChangeMonitor ImplMac _notifyHearstConnectionState:]-[CSAudioRouteChangeMonitorImplMac _notify Hearst RoutedState:]-[CSAudioRouteChangeMonitorImplMac _fetchHearstRoutedState]-[CSActivation XPCConnection _handleClientEvent:]-[CSActivationXPCConnection _handleClientMessage:client:]-[CSActivationXPCConnection _handleClientError: client:]-[CSActivationXPCConnection _handleActivate EventMesssage:client:]injectionDevice IOGeneralInterest-[CSClamshellStateMonitor _startMonitoringWithQueue:]-[CSClamshellStateMonitor _stopMonitoring] IOPower:/IOPowerConnection/IOPMrootDomainAppleClamshellState_getClamshellStatecaptureFilePath-selfTriggerVoiceTrigger audio logging queue-[CSVoiceTriggerFileLogger _audioLogDirectory]-[CSVoiceTriggerFileLogger geckoLogDirectory]%@%@%@%@%@%@%@-[CSVoiceTriggerFileLogger _write Dictionary: toPath:]-[CSVoiceTriggerFileLogger logGeckoWithFilePrefix: WithResult:].*-[CSEndpointDelay Reporter initWithRequestMHUUID: turnIdentifier:]-[CSEndpointDelay Reporter reset] leadingSilence trailingSilence end Time-[CSEndpointDelay Reporter setSpeechRecognizedContext: withEndpointerMetrics:]-[CSEndpointDelay Reporter reportEndpoint Delay IfNeed]-[CSEndpointDelay Reporter _reportUEIUserSpeakingContext]cs.secondpass.retrainer.q-[CSVoiceProfile Retrain Manager init]-[CSVoiceProfile RetrainManager triggerVoiceProfileRetrainingWithAsset:]_block_invoke-[CSVoiceProfile RetrainManager CSVoiceTriggerEnabledMonitor: didReceiveEnabled:]_block_invoke-[CSVoice Profile RetrainManager CSVoiceTriggerEnabledMonitor: didReceiveEnabled:]_block_invoke_2-[CSVoiceProfile RetrainManager CSLanguageCodeUpdateMonitor: didReceive LanguageCodeChanged:]-[CSVoiceProfile Retrain Manager CSLanguageCodeUpdateMonitor: didReceive LanguageCodeChanged:]_block_invoke_2-[CSVoice Profile RetrainManager CSLanguageCodeUpdateMonitor: didReceive LanguageCodeChanged:]_block_invoke-[CSVoiceProfile RetrainManager
CSSpeakerRecognition Asset Download Monitor: did InstallNewAsset: assetProvider Type:]-[CSVoice Profile RetrainManager
CSSpeaker Recognition Asset Download Monitor: did InstallNewAsset: assetProvider Type:]_block_invoke_2-[CSVoice Profile RetrainManager
CSSpeaker Recognition Asset Download Monitor: did InstallNewAsset: assetProvider Type:]_block_invoke-[CSVoice Profile RetrainManager
_speaker RecognitionModelRetrainCallback]-[CSVoiceProfile Retrain Manager speaker Recognition ModelRetrainCallback]_block_invoke_2-[CSVoice Profile RetrainManager speaker RecognitionModelRetrainCallback]_block_invoke-[CSVoiceProfileRetrain Manager speakerRecognition Cleanup Duplicated ProfilesCallback]-[CSVoiceProfile RetrainManager speaker RecognitionCleanup Duplicated ProfilesCallback]_block_invoke_2-[CSVoiceProfileRetrain Manager _speaker RecognitionCleanup Duplicated ProfilesCallback]_block_invoke-[CSVoice ProfileRetrainManager
_runVoiceProfile RetrainerWithAsset: withLanguageCode:]_block_invokeVoiceProfile Migration-[CSVoiceProfileRetrainManager
_runVoiceProfileRetrainerWithAsset: with LanguageCode:]-[CSVoiceProfile Retrain Manager _retrainingVoice Profile: voiceProfile: asset:]-[CSVoice Profile RetrainManager _retrainingVoiceProfile: voiceProfile: asset:]_block_invoke-[CSConnectionListener
initWithMachService: withService Interface:with ServiceObject:with DelegateInterface: queue:] com.apple.CoreSpeech.Connection.Listener-[CSConnectionListener dealloc]-[CSConnectionListener listener:shouldAcceptNewConnection:]-[CSConnectionListener listener: shouldAcceptNewConnection:]_block_invoke-[CSConnectionListener notifyClientsWithBlock:]_block_invoke-[CSConnectionListener resumeConnection] CSVoiceTriggerAOPModeEnabled PolicyIOS RecordState queue-
[CSVoiceTrigger AOPModeEnabledPolicyIOS _addConditions For IOSBargeIn]_block_invoke-[CSVoiceTriggerAOPModeEnabled PolicyIOS _addConditions ForIOSAOP]_block_invoke-[CSVoiceTrigger AOPModeEnabledPolicy IOS isSpeech DetectionDevicePresent]-[CSVoiceTriggerAOPModeEnabled PolicyIOS siriClientBehavior Monitor: didChanged RecordState: withEventUUID: withContext:]_block_invoke-[CSVoiceTriggerXPCServiceProxy
enableVoiceTrigger: withAssertion: timestamp:]voicetrigger assertion queue-[CSVoiceTriggerXPCServiceProxy
enableVoiceTrigger: withAssertion: timestamp:]_block_invokephrasespotter assertion queue-[CSVoiceTriggerXPCServiceProxy
setPhraseSpotterBypassing: timeout:]_block_invoke_2bypassed NOT bypassed-[CSVoiceTriggerXPCServiceProxy setPhraseSpotter Bypassing: timeout:]_block_invokeraise-to- speak assertion queue-[CSVoiceTriggerXPCServiceProxy setRaiseToSpeakBypassing: timeout:]_block_invoke_2-[CSVoiceTriggerXPCServiceProxy
notifyServiceConnectionLost]-[CSVoiceTriggerAOPModeEnabled PolicyMac
setRaiseToSpeakBypassing: timeout:]_block_invoke-[CSVoiceTriggerXPCServiceProxy notifyVoiceTriggeredSiriSessionCancelled]-[CSVoiceTriggerXPCServiceProxy _addMacBargeInConditions]_block_invokeCSAtt SiriRequestSource KeySiriFollowup for IdleAndQuiet DictationLock ScreenNotificationSpeechDetection-[CSAdBlocker AssetMetaUpdateMonitor _startMonitoringWithQueue:]-[CSAdBlocker Asset MetaUpdateMonitor _stop Monitoring]-[CSAdBlockerAsset MetaUpdateMonitor _didReceiveNewAdBlocker Asset MetaData] com.apple.Mobile Asset.AdBlocker Assets.ma.cached-metadata-updatedCSVoiceTriggerHandlerMacQueue-[CSVoiceTriggerAssetHandlerMac _getVoiceTriggerAssetFromAsset ManagerWithLocale: completion:]_block_invoke-[CSVoiceTriggerAssetHandlerMac
_getVoiceTriggerAsset FromAsset ManagerWithLocale: completion:]_block_invoke_2v16@?0@"NSString"8-[CSVoiceTriggerAssetHandlerMac
_checkNewAsset Availablity]_block_invoke-[CSVoiceTriggerAssetHandlerMac _checkNewAsset AvailablityForEndpoint]_block_invoke_3-[CSVoiceTriggerAssetHandlerMac _checkNewAsset Availablity For Endpoint]_block_invoke-[CSVoiceTriggerAssetHandlerMac CSVoiceTriggerAssetDownload Monitor: did InstallNewAsset:]-
[CSVoiceTriggerAssetHandlerMac CSLanguageCodeUpdateMonitor: didReceive LanguageCodeChanged:]-[CSVoiceTriggerAssetHandlerMac CSFirstUnlockMonitor: didReceiveFirstUnlock:]-[CSVoiceTriggerAssetHandlerMac
trialAssetDownloadMonitorDelegate: did InstallNewAsset: assetType:] CSSiriClientBehaviorMonitor-[CSSiriClientBehavior Monitor
notifyFetchedSiriClientAudio Stream: successfully:]_block_invoke-[CSSiriClientBehavior Monitor notify PreparedSiriClientAudioStream: successfully:]_block_invoke-[CSSiriClient Behavior Monitor notifyWillStartStreamWithContext:option:]_block_invoke-[CSSiriClientBehavior Monitor notifyDidStartStreamWithContext: successfully: option: withEventUUID:]_block_invoke-[CSSiriClientBehaviorMonitor notifyWillStopStream: reason:]_block_invoke-[CSSiriClient Behavior Monitor notify DidStopStream: with Event UUID:]_block_invoke-[CSSiriClientBehavior Monitor notifyRelease Audio Session]_block_invoke-[CSAudioProcessWaitingBuffer initWithSiriSession UUID:]-[CSAudio ProcessWaitingBuffer dealloc]localSpeechRecognizerQueue Queue-[CSAttSiriAsr Node stopWithReason:]-[CSAttSiriAsr Node stopWithReason:]_block_invoke-[CSAttSiriAsrNode adjustEndpointStartTime With VoiceTriggerEvent:]-[CSAttSiriAsrNode preheatLocalSpeech RecognitionWithLanguage:source:]_block_invoke SRD ASR Result Delivery Transaction-[CSAttSiriAsrNode startDeliverLocalSpeech Recognition ResultsWithSettings:]_block_invoke-[CSAttSiriAsrNode _startDeliver LocalSpeech RecognitionResultsWithRequestId:]-[CSAttSiriAsrNode stopDeliverLocalSpeech RecognitionWithReason: requestId:]-[CSAttSiriAsrNode stop Deliver LocalSpeech RecognitionWithReason: requestId:]_block_invoke-[CSAttSiriAsrNode disableLocalSpeech RecognitionForRequestId:]-[CSAttSiriAsrNode disableLocalSpeech Recognition ForRequestId:]_block_invoke-[CSAttSiriAsrNode pauseLocalSpeech Recognition For RequestId:]-[CSAttSiriAsr Node resumeLocalRecognitionWithRequestId: prefixText: postfixText: selected Text:]-[CSAttSiriAsrNode attSiriAudioSrc NodeLPCMRecordBuffer Available: audio Chunk:]_block_invoke-[CSAttSiriAsrNode attSiriAudioSrcNode DidStop:]_block_invoke-[CSAttSiriAsrNode attSiriNode:did DetectHardEndpointAtTime: withMetrics:]_block_invoke-[CSAttSiriAsr Node enforceEndpointHintWithRequestId: rcId: shouldAccept: featuresToLog:]-[CSAttSiriAsr Node enforceEndpointHintWithRequestId:rcId:shouldAccept: featuresToLog:]_block_invoke-[CSAttSiriAsrNode start] ASRNode Recording Transaction-[CSAttSiriAsrNode start]_block_invoke-[CSAttSiriAsrNode preheatWithLanguage: preheatSource:] Siriunified_asset_namespace-[CSAttSiriAsrNode prepareToStartSpeechRequestWithStartStreamOption: audioRecordContext: voice Trigger Info:]_block_invoke-[CSAttSiriAsrNode _stopPrevious RecognitionTask IfNeededWithNewRequestId:]-[CSAttSiriAsr Node should DisableLocalSpeechRecognizerWithOption: audioRecordContext:]-[CSAttSiriAsrNode _startLocalSpeechRecognizerIfNeeded] localASR-[CSAttSiriAsr Node _startLocalSpeechRecognizerIfNeeded]_block_invokev24@?0@"CESRModelProperties"8@"NSError"16-[CSAttSiriAsrNode processAudioChunk:]-[CSAttSiriAsrNode _handleStop Speech RecognitionTaskIfNeeded:]-[CSAttSiriAsr Node _scheduleRecording TransactionReleaseTimer]-[CSAttSiriAsr Node release Recording TransactionIfNeededWithToken:]-[CSAttSiriAsrNode interactiveLocalSpeechRecognizer]-[CSAttSiriAsrNode LocalSpeechRecognizer: didRecognizeTokens:]_block_invoke-[CSAttSiriAsrNode LocalSpeechRecognizer: didRecognize Tokens: withMetadata:]_block_invoke-[CSAttSiriAsrNode LocalSpeechRecognizer: didProcessAudioDuration:]_block_invoke-[CSAttSiriAsrNode queryShouldAcceptEagerResultForDuration: requestId: rcId:]-[CSAttSiriAsrNode _handleShould AcceptEagerResultWithRequestId: rcId: duration: shouldAccept: featuresToLog:]_block_invoke-[CSAttSiriAsrNode LocalSpeechRecognizer: didRecognize FinalResultCandidate Package:]_block_invoke-[CSAttSiriAsrNode localSpeechRecognizer: didRecognize Package:]_block_invoke-[CSAttSiriAsr Node localSpeechRecognizer: didRecognize Package: withMetadata:]_block_invoke-[CSAttSiriAsrNode _handleDidRecognized FinalSpeechPackage:requestId: metadata:]-[CSAttSiriAsrNode
_handleDidRecognizedSpeech Package ForEagerRecognitionCandidate:requestId: rcId: metadata:]-[CSAttSiriAsrNode LocalSpeechRecognizer: did Completion RecognitionWithStatistics: error:]_block_invoke-[CSAttSiriAsrNode
LocalSpeechRecognizer: didProduceEndpoint FeaturesWithWordCount: trailingSilenceDuration: eosLikelihood: pauseCounts: silencePosterior:
processedAudioDurationInMilliseconds:]_block_invoke-[CSAttSiriAsr Node LocalSpeechRecognizer: didSelectRecognitionModelWithModelProperties:] HomeButton-[CSAttSiriAsr Node _fetchInputOriginWithRecordContext:]-[CSAttSiriAsrNode _setLocalSpeechRecognizerState:][Idle][Disabled ][ Delivering message][Waiting for start deliver message][Waiting for start deliver message after client stop][Unknown]-[CSAttSiriAsrNode _fetchRecognizerLanguageWithSiriLanguage: UILanguage:taskString:]-[CSAttSiriAsrNode _markTimeToFirstWordMetric]-[CSLanguageCodeUpdateMonitorImplDarwin _startMonitoringWithQueue:]-[CSLanguageCodeUpdateMonitorImplDarwin _stopMonitoring]-[CSLanguage Code Update Monitor ImplDarwin didReceive Language Code Update:] Languages Footprint Premium.%@CSOpportune SpeakEventMonitor-[CSOpportuneSpeakEventMonitor isStreaming] com.apple.corespeech.CSSystemUserActivityMonitor-[CSSystemUserActivityMonitor
_startMonitoringWithQueue:]_block_invokecom.apple.system.powermanagement.useractivity-[CSSystemUserActivityMonitor _fetchSystemUserActivityState] CSActivationEvent NotificationHandler Queue-[CSActivationEvent NotificationHandler setDelegate: forType:]_block_invoke-[CSActivationEvent NotificationHandler notifyActivationEvent: completion:]_block_invoke-[CSActivationEvent NotificationHandler _notifyActivationEvent: completion:]-[CSActivation Event NotificationHandler _notifyActivationEvent: completion:]_block_invoke-[CSActivationEvent NotificationHandler _startMonitoring]-[CSActivation Event NotificationHandler _stopMonitoring]-[CSAudio Converter _convertBuffered LPCM: allowPartial: timestamp:arrivalTimestamp To Audio Recorder:]-[CSAudioConverter convertBuffered LPCM: allowPartial: timestamp: arrival Timestamp To Audio Recorder:]_block_invoke-[CSAudioConverter reset]-[CSAudioConverter _configureAudio Converter:] CreateAudioConverterACOpusEncoderFactory/System/Library/Components/Audio Codecs.component/Contents/MacOS/Audio Codecs+ [CSAdBlockerAssetDecoderFactory adBlocker AssetDecoderWithVersion:] HOME EnterSandboxcom.apple.core speechdTMPDIRDARWIN_CACHE_DIRDARWIN_USER_DIR-[CSSelfTriggerDetectorEnabled Policy ASMac _addSelfTriggerDetectorEnabledConditions]_block_invokeCSHangUpEnabled Monitor queue-[CSHangUpEnabled Monitor _checkCanUseVoiceTriggerDuring CallEnabled]-[CSHang UpEnabled Monitor voice TriggerDuring CallEnabled DidChange]_block_invoke + [CSUtils (machXPC) machXPCConnection: hasEntitlement:]-[NSArray (XPCObject) _cs_initWithXPCObject:]-[NSArray (XPCObject) _cs_initWithXPCObject:]_block_invokeB24@? 0Q8@"NSObject<OS_xpc_object>"16-[NSArray (XPCObject) _cs_xpcObject]_block_invokev32@?
from asset
O@8Q16^c24RTModelDataRTModelHashRTModelLocaleRTModelDigestRTModelSignatureRTModelCertificateRT Model for Corealis RTModelCorealis RTModelVersiondataSize (%d), hash (%@), Locale (%@), digest (%@), cert (%@), signature (%@) -[CSPowerAssertionMac initWithTimeout:]-[CSPowerAssertionMac invalidate]-[CSCommandControlStreamEventMonitor isStreaming]+[CSPhone CallStateMonitor sharedInstance] CSPhoneCallStateMonitor.m-[CSPhoneCallStateMonitor phone CallState]-[CSPhoneCallStateMonitor firstPartyCall]-[CSVoiceTriggerAsset MetaUpdateMonitor _startMonitoringWithQueue:]-[CSVoiceTriggerAsset MetaUpdate Monitor _stop Monitoring]-[CSVoiceTriggerAsset MetaUpdateMonitor _didReceiveNewVoiceTriggerAssetMetaData] com.apple.MobileAsset.VoiceTriggerAssets.ma.cached-metadata-updatedcom.apple.Mobile Asset.VoiceTriggerAssets IPad.ma.cached- metadata-updatedcom.apple.MobileAsset.VoiceTrigger HSAssets IPad.ma.cached-metadata-updatedcom.apple.MobileAsset.VoiceTriggerAssetsWatch.ma.cached-metadata- updatedcom.apple.MobileAsset.VoiceTriggerHSAssetsWatch.ma.cached-metadata-updatedcom.apple.MobileAsset.VoiceTriggerAssets Marsh.ma.cached-metadata- updatedcom.apple.Mobile Asset.VoiceTriggerAssetsMac.ma.cached-metadata-updatedcom.apple.MobileAsset.VoiceTriggerAssetsTV.ma.cached-metadata- updatedcom.apple.Mobile Asset.VoiceTrigger HSAssets.ma.cached-metadata-updated-[CSSpeechDetection DevicePresentMonitor handleSpeech DetectionVADPresentChange:]-[CSSpeechDetection DevicePresentMonitor systemControllerDied:]-[CSAudioTandemStream attachToPrimaryStreamWithCompletion:]-[CSAudio TandemStream prepareAudioStreamSyncWithRequest: error:] CSAudio TandemStream.m-[CSAudio TandemStream prepareAudioStreamWithRequest: completion:]-[CSAudio TandemStream startAudioStreamWithOption: completion:]-[CSAudioTandemStream stopAudioStreamWithOption: completion:]-[CSPhraseNDEAPIScorer keywordAnalyzer NDEAPI: hasResultAvailable: forChannel:] CSActivation XPCListener-[CSActivationXPCListener listen]-[CSActivationXPCListener handleListenerEvent:]-[CSActivation XPCListener handleListener Error:]-[CSActivationXPCListener handleNewRemoteConnection:]corespeechd.activation-[CSActivationXPCListener CSActivationXPCConnectionReceivedClientError:clientError:client:]_block_invoke CSRemoteRecordClient Queue-[CSRemoteRecordClient initWithDeviceId: audioStreamHandleId:]-[CSRemoteRecordClient dealloc]-[CSRemoteRecordClient
didDeviceConnect:] com.apple.corespeech.xpc.remote.recordcom.apple.corespeech.xpc.remote.record.darwin-[CSRemoteRecordClient didDeviceConnect:]_block_invoke-[CSRemoteRecordClient did Device Disconnect:]-[CSRemoteRecordClient waiting ForConnection: error:]-[CSRemoteRecordClient handleServerEvent:]-[CSRemoteRecordClient _handleServerError:]-[CSRemote RecordClient handleServerMessage:] didStart RecordingdidStopRecording LPCMBuffer AvailablebuffertwoShot Detected-[CSRemoteRecordClient _handleDidStart RecordingMessage:] didStartRecording ErrorDevice Typeerrortime-[CSRemoteRecordClient _handleTwoShot DetectedMessage:]startRecordingstartRecordingOptions-[CSRemoteRecordClient startRecordingWithOptions: error:]_block_invokestopRecording-[CSRemoteRecordClient stopRecording:]_block_invoke-[CSRemote RecordClient didPlay Endpoint Beep] didPlayEndpoint Beep replyDidPlayEndpointBeep-[CSRemoteRecordClient didPlayEndpointBeep]_block_invokereplyVoice Trigger Event Info-[CSRemoteRecordClient voiceTriggerEvent Info]_block_invoke-[CSRemoteRecordClient voiceTriggerEventInfo] has Pending Two Shot Beep reply HasPending TwoShot Beep-[CSRemoteRecord Client has Pending Two ShotBeep]_block_invoke-[CSRemoteRecordClient hasPending Two Shot Beep] CSContinuousAudioFingerprint Provider-[CSContinuousAudioFingerprint Provider startWithUUID: with MaximumBufferSize:]-[CSContinuous AudioFingerprintProvider startWithUUID: withMaximumBufferSize:]_block_invoke-[CSContinuousAudioFingerprint Provider stopWithUUID:]-[CSContinuous Audio FingerprintProvider stopWithUUID:]_block_invoke-[CSContinuous AudioFingerprint Provider _startListen PollingWithInterval: completion:]-[CSContinuous Audio FingerprintProvider _startListen PollingWithInterval: completion:]_block_invoke-[CSContinuousAudioFingerprintProvider _startListenWithCompletion:]_block_invoke_2-[CSContinuousAudioFingerprintProvider _startListenWithCompletion:]_block_invoke-[CSContinuousAudioFingerprintProvider _startListenWithCompletion:]-[CSContinuousAudioFingerprintProvider _startListenPolling]-[CSContinuousAudioFingerprintProvider _stopListening]-[CSContinuous Audio FingerprintProvider _stop Listening]_block_invoke-[CSContinuous AudioFingerprintProvider _handleEnablePolicyEvent:]-[CSContinuous Audio FingerprintProvider audioStreamProvider: didStopStreamUnexpectly:]-[CSContinuousAudioFingerprintProvider CSAudioServerCrash MonitorDid ReceiveServerRestart:]isDarwinOSinitweakObjectsHashTabledefaultProtocolInfoenterdidDeviceConnect: did Device Disconnect:isEqual: classselfperformSelector: performSelector: withObject: performSelector: withObject: withObject:isProxyisKind Of Class: isMemberOfClass: conformsToProtocol: responds To Selector: retain releaseautorelease retainCountzonehashsuperclassdescription debug DescriptionTQ, RT#, RT@"NSString", R, CdidReceive Voice Triggered: disconnected: didReceiveSelfTriggerDetected: myriad Hash: didReceiveBootFromHibernate: didConnected: didReceiveConnectionInvalidated: didReceiveVoiceTriggerAssetsDownloadingRequest: withConfigVersion: LanguageCode: addObject:removeObject:_invalidate deallocinitWithUUIDBytes: UUIDStringleave_handleServer Event: countByEnumeratingWithState: objects: count:waitWithTimeout: errorWithDomain: code:userInfo:isConnectedstringstringWithUTF8String: append Format:_handleServerError:_handleServerMessage: stringWithFormat: isEqualToString:_getMyriad InfoFromServer Message: dictionaryWithObjects: forKeys: count:_cs_xpcObject_cs_initWithXPCObject: objectForKeyedSubscript: boolValueunsigned LongLongValuedefaultManagerfileExistsAtPath: UTF8StringnumberWithInt: sharedInstancemodelDirectoryPathForProfile: hashFromResourcePathURL By Appending PathComponent: stringBy Appending PathComponent: path_transferFile: at: completion:
localizedDescriptionconfigVersion stringByAppendingString:resourcePathenumeratorAtPath: fileExistsAtPath: isDirectory: numberWithInteger:
arraycountsharedPreferences interstitialRelativeDirForLevel: Last PathComponentunsignedIntegerValuesetObject: forKey: xpcObjectinitWithXPCObject:_transferAudioData: numSamples: remoteWavFilePath:completion: _fetchDataFromAudioFileUrl: aesKey: encryptedAudioSampleBypeDepth: completion: initWithFileUrl: aesKey: sampleByteDepth: LpcmInt16ASBD dataWithBytes: Length: readAudioChunksWithCallback: readVoiceTriggeredTokenWithCompletion: readAndClearVoiceTriggeredTokenWithCompletion: transferVoice Trigger SpeakerModel: forAsset: transferVoice TriggerAsset: for LanguageCode: completion: setVoice TriggerEnable: withCompletion:
voiceTriggerEnabledWithCompletion: invalidate InterstitialWithLevel: transfer InterstitialAudioFiles: interstitialLevel: completion: getTriggerCount:clearTriggerCount: getFirstPassRunningMode:notifyVoice TriggerAssetChangeWithSiriLanguageCode: exchange RemoteDevice ProtocolInfo:createRemoteVoiceProfileWithAudioFiles:aeskey:
encryptedAudioSampleBypeDepth: LanguageCode: completion: notifyBluetooth Wireless SplitterStateChanged: shouldDisableSpeaker VerificationInSplitter Mode: fetchAndClearCachedVoiceTriggerEventsWithCompletion: setSelfTriggerEnable: with Completion: initWithRemoteDevice: isConnectedDeviceGibraltarisConnected Device DarwinaddObserver: removeObserver: invalidatewaiting ForConnection: error: _dictionaryWithContentsOfXPCObject: deviceTypedevice deviceIddevice ProtocolInfo.cxx_destruct_queue_connection_deviceWaitingGroup_observers_device Type_device_deviceId_device ProtocolInfoTI,R,N,V_ deviceTypeT@"OS_remote_device",R,N,V_deviceT@"NSString",R,C,N,V_deviceIdT@"CSRemoteDeviceProtocolInfo",R,N,V_device Protocol InfosetXpcConnection: _ handleMetricProvidingRequestTypeAudioMetricMessage: message Body: client: audioMetrichandleXPCMessage: message Body: client: CSXPCConnectionReceivedClientError: clientError:client:initWithXPCConnection: audioMetricProvidersetAudioMetricProvider: xpcConnectionstreamClient TypesetStreamClientType:_audioMetricProvider_ xpcConnection_streamClientTypeT@"<CSAudio MetricProviding>",W,N,V_audioMetricProviderT@"CSXPCConnection",W,N,V_xpcConnectionTQ,N,V_ streamClientTypegetAssetTypeForNamespace: getTrialIdsForAssetType: withCompletion: iterateBitset: block: getNumElementInBitset: initializeTimerState_ startMonitoringWithQueue:_stop MonitoringtimerState_timerFiringStatesupportMphAssets_notificationKey_did Installed NewVoice TriggerAsset_notifyObserver: enumerateObservers: notifyObserver: CSVoiceTriggerAsset Download Monitor: didInstallNewAsset:_notifyTokeninitWithStreamHandleId: inputRecording NumberOfChannels inputRecording Sample RateconverterForAudioStreamId: initWithNumChannels: recording Duration: samplingRate: audioTimeConverter: UUIDsetConnected Device: enableAlwaysOnVoiceTriggeris AlwaysOnVoiceTriggerAvailable setAlwaysOnVoice TriggerEnabled:setDelegate: startdefaultFallBackAssetForVoice TriggerdecodeConfigFrom: configPathNDAPIinitWithConfigPath: resourcePath: setActiveChannel: noAlertOptionstartAudioStreamWithOption: stopAudioStreamstopresetinjectAudio: injectAudio: withScaleFactor: playbackStarted: completion: sampleCountaudioEngine DidStartRecord: audioStreamHandleId: successfully: error:audioStreamHandleIdaudioEngineDidStop Record: audioStreamHandleId: reason: LengthinputRecording SampleByteDepthbytesaddSamples: numSamples: initWithData: numChannels: numSamples: sampleByteDepth: startSample Count:hostTime: remoteVAD: getBestAnalyzed ResultsFromAudioChunk: bestScoregetThreshold bestStartsharedManagerForCoreSpeech Daemondevice IDremoteMicVoiceTriggerEvent: activationInfo:hostTime: notifyActivationEvent: completion: inputRecordingBufferDuration copybuffer From: to: audioEngineBuffer Available: audioStreamHandleId: buffer: remoteVAD: atTime: audioEngine AudioChunk ForTvAvailable: audioChunk: alwaysOnVoiceTriggerEnabled attachDevice: isRecordingqueuesetQueue: delegatekeywordAnalyzersetKeywordAnalyzer: circularBufferset CircularBuffer: LastDetectedVoiceTriggerBeginSampleCount setLastDetectedVoice TriggerBeginSampleCount:lastForwardedSampleCount setLastForwardedSampleCount: voiceTriggerEnabledsetVoice TriggerEnabled: connected DeviceuuidsetUuid:isForwardingsetIsForwarding:_voice TriggerEnabled_is Forwarding_delegate_keywordAnalyzer_ circularBuffer_lastDetectedVoice TriggerBeginSampleCount_lastForwardedSampleCount_connected Device_uuidT@"NSObject<OS_dispatch_queue>", &,N,V_queueT@"<CSAudioInjectionEngineDelegate>",W,N,V_delegate T@"CS Keyword Analyzer NDAPI", &,N,V_keywordAnalyzer T@"CSAudioCircular Buffer", &,N, V_circularBufferTQ,N,V_ lastDetectedVoiceTriggerBeginSampleCount TQ,N,V_LastForwardedSampleCountTc,N,V_voice TriggerEnabledT@"CSAudioInjectionDevice",W,N,V_connectedDevice T@"NSUUID", &,N,V_ UuidTc,N,V_is Forwarding smartSiriVolume EnablePolicy_fetchHearst RoutedState_fetchSiri InputSourceOutOfBand State_notify HearstRoutedState: _ notifySiriInputSourceOutOfBandState: _startObservingSystemControllerLifecycle_startObservingAudioRouteChangeCSAudioRouteChangeMonitor: didReceiveAudio RouteChangeEvent: enumerateObservers InQueue:activeAudioRouteDidChange: getHearst Connected: hearstConnectedgetHearstRouted: hearstRoutedgetJarvisConnected: jarvisConnectedcarPlay ConnectedsiriInputSourceOutOfBandgetSiriInputSourceOutOfBand:_systemController Died:_isHearstConnected_ isHearstRouted_isSiriInputSourceOutOfBandinitWithWordCount: trailingSilence Duration: eosLikelihood: pauseCounts: silencePosterior: task Name: processedAudioDurationInMilliseconds: componentsJoined By String: numberWithDouble: initWithWordCount: trailingSilenceFrames : endOfSilenceLikelihood: pauseCounts: silencePosterior:taskName: dictionarywordCountsetWordCount: trailingSilence Durationset TrailingSilence Duration: eosLikelihoodsetEosLikelihood: pauseCountssetPauseCounts: silence PosteriorsetSilencePosterior:processedAudioDurationInMilliseconds setProcessed Audio DurationInMilliseconds: taskNamesetTaskName: _ wordCount_trailingSilence Duration_eosLikelihood_pause Counts_silencePosterior_processedAudioDurationInMilliseconds_taskNameTq,N,V_wordCountTq,N,V_ trailingSilence DurationTd,N,V_eos LikelihoodT@"NSArray",C,N,V_pauseCountsTd,N,V_silencePosteriorTq,N,V_processedAudioDurationInMilliseconds T@"NSString",C,N,V_ taskNamedefaultContinousFingerprintBufferDurationsubdataWithRange: initWithData: encoding: numberWithBool: setValue: forKey: signatureWithDataRepresentation: error: mediaItemWithProperties: arrayWithObjects: count: addReferenceSignature: representingMediaItems: error: initWithData: decodeAssetmaxFingerprintBufferSize shouldResetAdsDictionaryassetVersionpayloadDataset PayloadData:_maxFingerprintBufferSize_shouldResetAdsDictionary_assetVersion_ payloadDataT@"NSData", &,N,V_payloadDataTf,R,N,V_maxFingerprintBufferSizeT@"NSMutableDictionary",R,N,V_shouldResetAdsDictionaryT@"NSString",R,N,V_assetVersion_ subscribeEventMonitorssubscribeEventMonitor:_addSmartSiriVolume Enabled Conditions shouldAudioMonitoringRecording add Conditions: utteranceFileASBD_closeAudioFile_ makeTimestamped AudioLog FilenameWithPrefix: suffix: fileURLWithPath: isDirectory: baseDir_audioLogDirectorycreateDirectoryAtPath: with Intermediate Directories: attributes :error:localeWithLocaleIdentifier: setLocale:setDateFormat: datestring FromDate: _getOrCreateAudioLogDirectory_nowStringstringByReplacing OccurrencesOfString: withString:startRecording appendAudioData: stopRecording_audioFile_asbd_url_audioLengthallowVoice TriggerAssetDownloadingsetAllowVoiceTriggerAsset Downloading: allowEndpoint Asset DownloadingsetAllowEndpoint Asset Downloading: allowLanguage Detector Asset DownloadingsetAllowLanguage Detector Asset Downloading: allowAdBlocker Asset DownloadingsetAllowAdBlocker AssetDownloading: allowSpeaker RecognitionAssetDownloadingsetAllowSpeaker RecognitionAssetDownloading: allowVoice TriggerAccessoryAsset DownloadingsetAllowVoice Trigger AccessoryAssetDownloading:_allowVoiceTriggerAssetDownloading_allowEndpointAssetDownloading_ allowLanguage DetectorAssetDownloading_allowAdBlockerAssetDownloading_allowSpeaker RecognitionAssetDownloading_allowVoice Trigger AccessoryAsset Downloading TC,N,V_ allowVoiceTriggerAsset Downloading Tc,N,V_allowEndpointAsset DownloadingTc,N,V_allowLanguage DetectorAssetDownloading Tc,N,V_allowAdBlocker Asset Downloading Tc,N,V_ allowSpeaker Recognition Asset DownloadingTc,N,V_allowVoiceTrigger AccessoryAssetDownloading getNumberForKey: category: default: floatValuegetString ForKey: category: default: keywordDetector Threshold keywordDetectorConfigPathRecognizerkeywordDetectorWait Time Since VTT@"NSString", R, NTf,R, NhorsemanDevice TypeSSVCAUserIntentValidForSeconds SSVCAUser IntentVolume Increase FactorSSVCAUser IntentVolume Decrease FactorSSVCAUser IntentPermanentOffsetFactorDeltaSS VCAUserIntentPermanentOffsetFactor LowerBoundSSVCAUser IntentPermanentOffsetFactor UpperBoundSSVCA DeviceSimpleMinTTSVolume SSVCADevice SimpleMaxTTSVolume SSVCA DeviceDef aultMinTTSVolumeSSVCADeviceDefaultMaxTTSVolumegetASVUserIntent: setUserIntentValidForSeconds: applyLower And UpperBounds ToVolume: setASVUserIntent: initWithStored Information And Asset:increaseSiriVolumeBasedOnUserIntentdecreaseSiriVolume BasedOnUserIntentstoreASVState Information apply Lower AndUpperBounds ToVolumeOffset:userIntentTypesetUserIntentType:userIntentValidForSecondsuserIntentTimesetUserIntentTime: latest Volume Time set LatestVolume Time: userIntentVolumesetUserIntentVolume: latestVolume setLatestVolume: permanentOffsetFactorset PermanentOffsetFactor: permanentOffsetIsEnabledsetPermanentOffsetIsEnabled:
KSSVCAUserIntentValidForSecondskSSVCAUserIntentVolume IncreaseFactorkSSVCAUserIntentVolume DecreaseFactorkSSVCAUserIntentPermanentOffsetFactorDeltakSSVCAUserIntentP
ermanentOffsetFactor Lower BoundkSSVCAUserIntentPermanentOffsetFactor
UpperBoundkSSVCA_DEVICE_SIMPLE_MIN_TTS_VOLUMEKSSVCA_DEVICE_SIMPLE_MAX_TTS_VOLUMEKSSVCA_DEVICE_ DEFAULT_MIN_TTS_VOLUMEKSSVCA_DEVICE_DEFAULT_MAX_TTS_VOLUME_permanentOffsetIsEnabled_userIntentVolume_latestVolume_permanentOffsetFactor_userIntentType_ userIntentValidForSeconds_userIntentTime_latestVolume Time TQ,N,V_userIntentTypeTQ,N,V_userIntentValidForSeconds Tq,N,V_userIntentTimeTq,N,V_LatestVolume TimeTf,N,V_ userIntentVolumeTf,N,V_latestVolume Tf,N,V_permanentOffsetFactorTc,N,V_permanentOffsetIsEnablednotifySiriLanguageCodeChanged:_notifyObserver: withEnabled: CSSiriEnabled Monitor: didReceiveEnabled:_didReceiveSiriSettingChanged: isEnabled fetch IsEnabled_isSiriEnabledsharedManagersetDeviceId: T@"NSString",C,N,V_ deviceIdRMSScoreinitWithRMSScore: lastSample Count: compareScores Desc: setRMS Score: Last SampleCountsetLastSampleCount: RMSScore_lastSample Count Td,N,V_RMS Score TQ,N,V_ LastSampleCountappendData: getBytes:range:_calculate RMSWith FrameData:_calculateSpeechVoicingLevelremoveAllObjects_ calculateNumberOfVoicingFrames numberOfVoicing Framessort Using Selector:addDataToBuffer: calculateShadowMicScorebestStartDetectSamplesetBestStartDetectSample: bestEarly DetectSamplesetBestEarly DetectSample: bestEnd DetectSamplesetBestEnd DetectSample: shadowMicScoreset ShadowMicScore: rmsSamplesForEntireAudiosetRms SamplesForEntireAudio: audioBuffersetAudioBuffer: speechVoice LevelsetSpeech Voice Level:setNumberOfVoicingFrames: numberOfTotalFramesETFTsetNumberOfTotalFramesETFT: _bestStartDetectSample_bestEarly DetectSample_bestEndDetectSample_shadowMicScore_rms Samples For EntireAudio_ audioBuffer_speechVoice Level_numberOfVoicingFrames_numberOfTotalFrames ETFTT@"NSMutableArray", &,N,V_rms SamplesForEntire Audio T@"NSMutableData", &,N,V_audioBufferTd, N ,V_speechVoice LevelTQ,N,V_numberOfVoicingFramesTq,N,V_numberOfTotalFrames ETFTTQ,N,V_bestStartDetectSample TQ,N,V_bestEarly DetectSample TQ,N,V_bestEndDetect SampleTd,N,V_shadowMic Score audioStreamHoldingsetAudioStreamHolding: audio ProvidersetAudioProvider:_audioStreamHolding_audioProviderT@"CSAudioStreamHolding", &,N,V_ audioStreamHolding T@"CSAudio Provider", &,N,V_audioProvidercsAudioProcessingQueue PrioritygetFixed High PrioritySerialQueueWithLabel: priority:getSerialQueue: qualityOfService:_secondPassState Queue_secondPassWorkQueue initWithPHSEnabled: speech Manager: stateQueue: secondPassQueue: setFirstPass Source:setSecondPassClient: setFirstPassDeviceId:setAsset: holdAudioStreamWithDescription: timeout:cancelCurrentRequestcancelAudioStreamHoldcancelAudioStreamHold: initWithDeviceID: holdAudioStreamWithTimeout: cancelRequestfirstPassDevice IDsetFirstPassDeviceID: voice Trigger SecondPasssetVoice Trigger SecondPass: isSecondPassRunningsetIsSecondPassRunning: current AssetsetCurrentAsset: timestamp setTimestamp:isCancelledsetIsCancelled: goodnessScoresetGoodnessScore: firstPassTriggerEnd Time setFirstPass TriggerEnd Time: secondChance ContextsetSecond ChanceContext:_isSecondPass Running_isCancelled_goodness Score_firstPass DeviceID_ voiceTriggerSecondPass_current Asset_timestamp_firstPassTriggerEnd Time_second ChanceContextT@"NSString", &,N,V_firstPassDeviceIDT@"CSVoiceTriggerSecondPass", &,N,V_ voiceTriggerSecondPassTc,N,V_isSecondPassRunning T@"CSAsset", &,N,V_current Asset TQ,N,V_timestampTC,N,V_isCancelledTf,N,V_goodnessScoreTd,N,V_ firstPassTriggerEnd Time T@"CSVoiceTrigger SecondChanceContext", &,N,V_second ChanceContextgetSerialQueue: withQualityOfService: and TargetQueue:registerObserver:_ resetobjectEnumerator_setDeviceIds: sharedHandlergetVoiceTriggerAssetWithEndpointId: completion: accessoryFirstPassGoodness ScoresobjectForKey: doubleValuesecondPassDidStartForClient: deviceId: withFirstPassEstimate: secondPassDidStop For Client: deviceId:typeinitWithUUIDString:voiceTriggerEnabledForEndpointId: _handleRemora TriggerEvent: secondPassRequest: completion: removeObjectForKey: numberWithFloat:_createSecondPassRequestIfNecessary For ActivationEvent: completion: activationInfohosttimeallKeyshost TimeToTime Interval:_cancelAudioStreamHolding For AccessoryWithId: CSVoiceTriggerFirstPassMetricsWithFirstPassInfoGeneratedTime: firstPassInfo ProcessedTime:contextForRemora Voice TriggerWithDeviceId: _requestStartAudioStreamProviderWithContext: secondPassRequest: startStreamOption: completion:_ setIsSecondPassing: forDeviceId: shouldRunAsSecond ChanceinitWithFirstPassSource: deviceId: audioProvider UUID: firstPassInfo:rejectionMHUUID: isSecond ChanceRun: firstpassMetrics: _handleSecondPassResult: secondPassRequest: deviceId: error: completion: sharedAggregatorresult voice Trigger Event InfologSecondPass Result: event Info: triggerAPWake Up: handleVoice TriggerSecondPassFrom: completion: mutableCopyvoice Trigger DidDetectKeyword: deviceId: completion: voice TriggerDid DetectKeyword: deviceId: voice TriggerDid Rejected: deviceId: voice Trigger Did DetectNearMiss: deviceId:isSecond ChanceCandidate initWithWindowStartTime: triggeredAudioStreamHoldingByAccessoryIdaudio ProviderWithContext: error: activationEvent NotificationHandler: event: completion: accessorySiriClientBehavior Monitor: willStartStreamWithContext: option: for Accessory: accessorySiriClientBehavior Monitor: didStartStreamWithContext: successfully: option: withEventUUID: for Accessory: accessorySiriClientBehavior Monitor: willStopStream: reason: for Accessory: accessorySiriClientBehavior Monitor: didStopStream: reason: with Event UUID: for Accessory: cancelSecondPassRunningpending SecondPassTriggerWas ClearedForClient: deviceId: initWithTargetQueue:setConnected DeviceIds: _ cancelAllAudioStreamHoldings secondPass ProgressDelegatesetSecondPassProgressDelegate: remoraSecondPassRequestssetRemoraSecondPassRequests:
set AccessoryFirstPass GoodnessScores: setTriggered AudioStreamHoldingByAccessoryId: triggeredAudio Providerset TriggeredAudioProvider: _secondPassProgressDelegate_ remoraSecondPassRequests_accessoryFirstPass GoodnessScores_triggeredAudioStreamHolding ByAccessoryId_triggeredAudio ProviderT@"NSMutableDictionary", &,N,V_ remoraSecondPassRequests T@"NSMutableDictionary", &,N,V_accessoryFirstPassGoodness Scores T@"NSMutableDictionary", &,N,V_triggeredAudioStreamHolding ByAccessoryIdT@"CSAudioProvider", &,N,V_triggeredAudioProvider T@"<CSVoiceTriggerDelegate>",W,N,V_delegate T@"<CSSecondPassProgressDelegate>",W,N,V_ secondPassProgress Delegateordered SetgetUUIDBytes: setObject: forKeyedSubscript:voiceTriggerEnabled Devices deviceUIDMapTablecontainsString: firstObject_ isRemoteDarwinConnectedWithUUID: currentInputDeviceUIDArraydeviceConnectedWithUUID: notify VoiceTriggerEnabledWithDeviceUUID: notifyVoice Trigger DisabledWithDeviceUUID : deviceDisconnectedWithUUID: allDeviceDisconnectedhasDarwin DeviceConnectedhasDarwin DeviceHandleVoiceTriggerfetchDeviceUUIDStringFromUID: isPrimaryVoice TriggerDeviceWithUUID: fetchRich DeviceUIDString FromUUID: isRemote Darwin ConnectedWithUUID: addDevice IDPairToMap Table:withDeviceUID: setDeviceUIDMapTable: setVoice TriggerEnabled Devices: _deviceUIDMapTable_voiceTriggerEnabled Devices T@"NSMutableDictionary", &,N,V_deviceUIDMapTableT@"NSMutableOrderedSet", &,N,V_ voiceTriggerEnabledDevicesis VoiceTriggerAsset OverridingEnabled voiceTriggerAssetHandler: endpointId: didChangeCachedAsset:defaultFallbackModelIfNil:
unregisterObserver:notifyObservers: endpointId: observersset Observers: T@"NSHashTable", &,N,V_observersinitWithRemoteDevice: voice TriggerEvents Coordinator: delegate: testContext:supportRemote DarwinVoice TriggerpreventSystemSleepManagerisUserActive_registerPowerNotification_
registerUserSession NotificationremoteDarwinVoice TriggerEnabled Policy_switchVoice TriggerStatus: setCallback:_connectRemoteCoreSpeechIfNeeded_ handleRemoteCoreSpeechFirstTimeConnectedsplitterState: forced Power AssertionTimeoutinitWithTimeout:_startMonitoring SystemUserActivity_release PMConnectionsharedWorkspacenotificationCenter removeObserver: name: object:_stopMonitoringSystemUserActivity_disconnect RemoteCoreSpeech_ stopRetryTimerremoteDeviceIdretryVoice TriggerEnable: onUserSession Active: addObserver:selector: name: object: onUserSession Resign: _disable RemoteVoiceTrigger_ wakeSiriIfNeeded FromFullWake: completion: _getPowerAssertion IfNeeded For RemoteClient: forceUserSessionActiveshared LaunchernotifyDarwinVoice Trigger PrewarmWithCompletion: _handleDevice Disconnection_
invalidateRemoteControlClientsetRemote Darwin EverConnectedWithNotifyKey: code local Device ProtocolInfogetSiriLanguageWithFallback: _enable Remote VoiceTrigger_ retryVoice TriggerEnable: _startRetryTimer didReceiveDarwin Device Disconnected: setRawVoice Trigger Event Info: fromDevice UUID: anchorHostMachTime: anchor DarwinMachTime: getMachTimeAdjustedVoiceTriggerEvent InfoForDeviceUUID: override PHash: withMachTime: _wakeSiriWith VoiceTrigger Info: myriad PHash: deviceId:isTriggered FromFullWake:__ writeMyriad HashFile:_send SELFMetricsForCachedVoice TriggerEvents: secondPassRejectEvents: secondPassCancelledEvents:_
releaseFullWake Assertionvoice TriggerDidDetect Keyword: myriad Hash: remote TriggerType: remoteDeviceId:isTriggeredFromFullWake: completion: myriad HashFilePathwriteToFile: atomically:removeItemAtPath: error: shared LoggerlogStartEventWithFirstPassStarted Info:with MHUUID:Log RejectEvent With VTEI: withMHUUID: with SecondPass Result: LogCancelledEventWithMHUUID: setTriggerNotified MachTime: _handleSelfTrigger Detected: myriad Hash: parse Compatibility FromConfigVersion:isLeftConfigVersion: newerThanRightConfig Version: _transferDarwinVoiceTriggerAsset: LanguageCode: assetOfType: Language: compatibilityVersion: completion: forceAcquirePowerAssertion_ stopPreventSleepAssertionTimerisUserSession Active_updateSystemSleepPowerAssertionState_release PreventSystemSleepPowerAssertionsystemUserActivityState_
currentSystemUserActiveState_startPreventSleepAssertionTimer acquireAssertionForActiveUseracquireAssertionForIdleUseracquireAssertionrelease PreventSystemSleepAsser tion_handleVoice TriggerEnabled:_markRemote Voice TriggerEnabled_remote Voice TriggerEnabled: disallowSuddenTermiation remoteControlClient_ getSpeakerProfileForCurrent Languageget Voice Trigger Profiles AESKeyexplicitSpIdTypeForSpId:getEnrollment UtterancesForModelType: EncryptionAudioSampleByteDepthallowSudden Terminationprovisioned Voice ProfilesForAppDomain: with Locale: objectAtIndexedSubscript:handleAssetChangeisScreenLocked_ safeAssetChangeHandlerCSLanguageCodeUpdateMonitor: didReceive Language CodeChanged: CSScreen LockMonitor: didReceive Screen LockStateChanged: CSBluetoothWirelessSplitterMonitor: didReceive SplitterStateChange: should Disable Speaker VerificationInSplitterMode: CSSystem UserActivityMonitor: activeStateChanged: initWithRemoteDevice: voiceTriggerEventsCoordinator: delegate: onFullWakeonDarkWake on EarlyWakeonSleeponDaemonExitsetRemoteControlClient: remoteDevice setRemoteDevice: setRemoteDeviceId: retryTimersetRetryTimer:setIsUserSession Active: power Stateset PowerState: voiceTriggerStartPolicysetVoice TriggerStartPolicy: shouldHandleAssetChangeAfterUnlocksetShould HandleAssetChangeAfter Unlock: voiceTriggerEvents CoordinatorsetVoiceTriggerEventsCoordinator: setPreventSystemSleepManager :preventSleepAssertionTimerset PreventSleepAssertionTimer: testContextsetTestContext: pmConnectionsetPmConnection: assertion IDsetAssertionID: _isUserSessionActive_ shouldHandleAssetChangeAfter Unlock_assertionID_remoteControlClient_remoteDevice_remoteDeviceId_retryTimer_powerState_voiceTriggerStartPolicy_ voiceTriggerEvents Coordinator_preventSystemSleepManager_preventSleepAssertionTimer_testContext_pmConnectionT@"CSRemoteControlClient", &,N,V_remote ControlClientT@"OS_remote_device", &,N,V_remoteDeviceT@"NSString", &,N,V_remoteDeviceIdT@"NSObject<OS_dispatch_source>", &,N,V_retryTimerTc,N,V_isUserSession Active TQ,N,V_powerStateT @"CSPolicy", &,N,V_voice TriggerStart PolicyTC,N,V_shouldHandle AssetChangeAfterUnlockT@"CSVoiceTriggerEventsCoordinator",W,N,V_voiceTriggerEventsCoordinatorT@"<CSDarwinVoiceTriggerHandler Delegate>",W,N,V_delegateT@"CSDarwin PreventSystemSleepManager", &,N,V_preventSystemSleep ManagerT@"NSObject<OS_dispatch_source>", &,N,V_ preventSleepAssertionTimerT@"CSVoiceTrigger DarwinHandlerTestContext", &,N,V_testContextT^{__IOPMConnection=},N,V_pmConnectionTI,N,V_assertion IDengineWithDevice Type :streamHandleId: sharedVoice TriggerClient_fetchSpeaker State Muted Info_fetchSpeaker State Active Info_didReceiveSpeaker MuteStateChangeNotification: speakerStateMutedCompletionBlock: _didReceiveBuiltin Speaker StateChangeNotification: speakerStateActiveCompletionBlock:setSpeakerStateChanged Block: setSpeakerMuteStateChangedBlock: enable Speaker State Listening: completionBlock:_notifyObserver: withBuiltin Speaker State: CSBuiltin SpeakerStateMonitor: didReceiveBuiltinSpeakerStateChange:_notifyObserver:isSpeakerMuted: CSAudioServerCrash MonitorDidReceiveServerCrash: CSAudioServerCrashMonitorDidReceiveServerRestart : currentBuiltin SpeakerStateisBuiltinSpeakerMutedsetBuiltInSpeaker State: alwaysOnProcessorController setAlwaysOnProcessor Controller: builtInSpeakerStateisSpeaker MutedsetIsSpeaker Muted:_isSpeakerMuted_alwaysOnProcessorController_builtInSpeakerStateT@"AVVoiceTriggerClient", &,N, V_ alwaysOnProcessorControllerTQ,N,V_builtInSpeaker State Tc,N,V_isSpeakerMutedinitWithType:
defaultFactoryclientForAudio Providing clientForAudioSession InfoProviding clientForSmartSiriVolume ProvidingclientForMacOSDuckAudioDevice clientForFallbackAudioSession ReleaseProvidinginteger Valuedid Transit From: to: by: did IgnoreEvent: from: initWithInitialState: add Transition From: to: for: add Transition FromAnyStateTo: for: performTransitionForEvent: currentStateinitialStatesetInitialState:transitionssetTransitions:eventToStateTransitionssetEventToStateTransitions:_currentState_ initialState_transitions_eventToStateTransitions Tq,N,V_initialStateT@"NSMutableDictionary", &,N,V_transitions T@"NSMutableDictionary", &,N,V_eventToStateTransitionsT @"<CSStateMachineDelegate>",W,N,V_delegateTq,R,N,V_currentState languageCode_notifyObserver: with LanguageCode:_didReceiveLanguageCode Update logMitigationFeatures: forTask:withModelOutput: forMHRequestId:getCategoryKeyForRecordCtx:activationModeactivation DeviceUIDannounceCallsEnabledstreamIDstartHostTimestartAlertstopAlertsto pOnErrorAlertskipAlertremote Voice ActivityAvailableremote VoiceActivityVADremote Voice ActivityVADBuffer_voiceControllerWithError: initWithBackingStoreCapacity: minimalNumberOfBackingStores: maximumNumberOfBackingStores: backingStoreIdleTimeout: initWithConfiguration: _destroyVoiceController_ audio Recorder DidStart Recording Successfully: streamHandle ID: error: audioRecorderWillBe Destroyed: setRecordDelegate: initWithError: setSynchronousCallbackEnabled: avvcContextSettingssetContext: streamType: error: has RemoteCoreSpeechhasRemote BuiltInMic_isDarwinDeviceId: avvcContext_shouldUseRemote RecordForContext: timeIntervalSinceDate:setContextForStream: forStream: error:_getRecordSettingsWithRequest: shouldUseRemote RecorderstreamHandleId_fetchRemoteRecordClientWithDeviceId: streamHandleId: initWithStreamID: settings: bufferDuration: setMeteringEnabled: prepareRecordForStream: error:_trackRemote AccessoryStreamIdIfNeeded:_ LogResourceNotAvailableError IfNeeded: audioInjectionEnabled_should InjectAudio_needResetAudio Injection Index: audio InjectionFilePathobjectAtIndex:URLWithString: initWithURL:setRecordBufferDuration: requestForLpcmRecordSettingsWithContext: prepare Recording: recordContexthasPending TwoShotBeep_ hasLocalPending Two ShotplayAlertSoundForType: override Mode: startAlertBehaviorisRecordContextVoice Trigger: contextForBuilt In Voice TriggerstartRecordingWithOptions: error:_startAudioStreamForAudio InjectionWithAVVCContext: avvcStartRecordSettingsWithAudioStreamHandleId: startRecordForStream: error: stopRecording: stopRecordForStream: error: getCurrentSessionStategetCurrentStreamState:isRemoteDeviceGibraltaris RemoteDeviceDarwingetRecordDevice InfoForStream: recordRouteinitWithAVVCRecordDevice Info: remoteDeviceProductIdentifierremoteDeviceUIDStringinitWithRoute:isRemoteDevice: remoteDeviceUID: remoteDeviceProductIdentifier: remoteDeviceUIDString: recordDeviceInfoWithStreamHandleId: recordDevice Indicator: playbackRouteinitWithRecordDeviceInfo: playbackRoute: playbackDeviceTypeList: recordSettingsWithStreamHandleId:getRecordSettingsForStream:isUpsamplingSourceAudiodomain_ shouldLogResource Not AvailableErrorsubmitAudio Issue Report: initWithDuckOthers: duckToLevel: mixWithOthers: setIsBlur:setDuckOverride: setDuckOthersForStream: withSettings: error: initWithStreamID: setStartAlert: setStopAlert: setStopOnErrorAlert: configureAlertBehavior ForStream: error: _updateLanguageCode For RemoteVTEIResult: voice Trigger Infois RecordContextBuiltInVoice Trigger:isRecordContextHome Button Press: _shouldUseRemote Built In Mic: IsDeviceAvailableInLocalRoute: error: audio Recorder Buffer Available: audioStreamHandleId: buffer: remoteVAD: atTime: arrival TimestampToAudioRecorder: numberOfChannels: _audioIsFromRemote Accessory: channelspacketDescriptionCountbytes DataSize initWithCapacity: datapacketDescriptionsinitWithBytes: length: setPackets: updateMeterForStream:getPeak PowerForStream: forChannel:getAverage PowerForStream: forChannel: setPeak Power: setAvg Power: setTimeStamp: setNumChannels: streamDescriptionset Audio Format: setStreamHandleID: audioRecorder Buffer Available: audioStreamHandleId: buffer:_compensateChannelDataIfNeeded: received NumChannels: timeStamp_processAudioChain: audioStreamHandleId: remoteVAD: atTime: arrivalTimestamp To Audio Recorder: numberOfChannels: numberWithUnsignedInteger: opusASBD initWithInASBD: outASBD: addPackets: audioStreamHandleId: remoteVAD: timestamp: arrivalTimestampToAudio Recorder: was Buffered: received NumChannels: initWithLength: replaceBytesInRange: withBytes: recordRouteWithRecordDevice Indicator: supportHearst Voice Triggercontains Object:setAlertSoundFromURL: forType:
playRecordStartingAlertAndResetEndpointerdidPlayEndpointBeepmetricsaudio Recorder DidStart Record: audioStreamHandleId: successfully: error:_ stopTracking Remote AccessoryStreamId: audioRecorderDidStopRecord: audioStreamHandleId: reason: _processAudioBuffer: audioStreamHandleId: arrivalTimestampTo Audio Recorder: _audioRecorder DidStopRecording For Reason: streamHandleID: audio RecorderStreamHandleIdInvalidated: audioRecorder RecordHardwareConfigurationDidChange: toConfiguration: audioRecorder DidFinishAlertPlayback:ofType: error: audioRecorderBuiltInAudioStreamInvalidated: error: audio Recorder LostMediaserverd: audioServerCrashEvent Providing LostMediaserverdinputRecordingIsFloatconvertToFloatLPCMBufFromShort LPCMBuf: remoteRecorder Did Detected Two ShotAtTime: triggerNotified MachTime audio Recorder Disconnected:useCustomizedRecordSettingsdefaultRequestWithContext: audioFormatnumberOfChannelsnumberWithUnsignedInt: sampleRatelpcmBitDepthlpcmIsFloat encoderBitRateinitWithDeviceId: audioStreamHandleId: createSharedAudioSession reset DuckSettings voiceController DidStartRecording: successfully: voiceControllerDidStartRecording: successfully: error: voiceController DidStopRecording: for Reason: voiceControllerDid DetectStartpoint: voiceController Did DetectEndpoint: of Type: voiceController Did DetectEndpoint: ofType: atTime: voiceControllerEncoderErrorDidOccur: error: voiceController Did FinishAlertPlayback: of Type: error: voiceController Did FinishAlertPlayback: withSettings: error: voiceController RecordBuffer Available: buffer: voiceController LPCMRecordBuffer Available: buffer: voiceControllerWirelessSplitter RouteAvailable: devices: voiceControllerDidStart Recording: forStream: successfully: error:voiceControllerDidStop Recording: forStream: for Reason: voiceController AudioCallback: forStream:buffer: voiceController LPCMAudioCallback: forStream:buffer: voiceControllerStreamInvalidated: forStream: audio Decoder Did DecodePackets: audioStreamHandleId: buffer: remote VAD: timestamp: arrivalTimestamp ToAudioRecorder: wasBuffered :receivedNumChannels: audioFileReaderBuffer Available: buffer: atTime: audioFileReaderDidStartRecording: successfully: error: audioFileReaderDidStop Recording: for Reason: remoteRecordDidStart RecordingWithStreamHandleId: error: remoteRecordDidStop RecordingWithWithStreamHandleId: error: remoteRecordLPCMBuffer Available: streamHandleId: remoteRecordTwo Shot DetectedAtTime: remoteRecordConnectionDisconnected:userSession Activate Monitor: didReceivedUserSession ActiveHasChanged: setAudioServerCrashEventDelegate: setAudioSessionEventDelegate: initWithQueue: error: willDestroysetAnnounceCallsEnabled: withStreamHandle ID: setContext:completion: setCurrentContext: streamHandleId: error: prepareAudioStreamRecord: recordDevice Indicator: error: startAudioStreamWithOption: recordDevice Indicator: error: stopAudioStreamWithRecordDevice Indicator: error:isSessionCurrentlyActivatedisRecordingWithRecordDevice Indicator: audioDeviceInfoWithStreamHandleId: recordDevice Indicator: recording SampleRateWithStreamHandleId:isNarrowBandWithStreamHandleId: prewarmAudioSessionWithStreamHandleId: error: setRecord Mode: streamHandleId: error:activateAudioSessionWithReason: streamHandleId: error: deactivateAudioSession: error: deactivateAudioSession: streamHandleId: error: enableSmartRoutingConsiderationForStream: enable: setDuckMixWithOthersForStream: duckOthers: duckToLevelInDB: mixWithOthers: enable MiniDucking: configureAlertBehavior: audioStreamHandleId: voiceTriggerInfoWith RecordDevice Indicator: isDuckingSupportedOnCurrentRouteWithStreamHandleID: error:setAlertSoundFromURL: for Type: force: playRecordStartingAlertAndResetEndpointerFromStream: playAlertSoundForType: recordDevideIndicator: alertStartTime updateMeterspeakPowerForChannel: averagePowerForChannel: voiceController RecordHardwareConfiguration DidChange: toConfiguration: voiceControllerMediaServicesWere Lost: voiceController MediaServicesWereReset:voiceControllerCreationQueuesetVoiceControllerCreationQueue: crashEventDelegatesetCrashEventDelegate: sessionEventDelegatesetSessionEventDelegate: remote AccessoryStreamIdSetset Remote AccessoryStreamIdSet: _voiceController_interleavedABL_pNonInterleavedABL_ remoteRecordClient_opus Decoders_audioFileReader_audioFilePathIndex_waitingForDidStart_pending TwoShot VTToken_audioBuffer Pool_hasSetAlertDictionary_ voiceControllerCreationQueue_crashEventDelegate_sessionEventDelegate_remote AccessoryStreamIdSetT@"NSObject<OS_dispatch_queue>", &,N, V_voiceController CreationQueueT @"<CSAudioServerCrashEvent Providing Delegate>",W,N,V_crashEventDelegate T@"<CSAudioSessionEvent ProvidingDelegate>",W,N,V_sessionEventDelegateT@"NSMutableSet", &,N,V_ remoteAccessoryStreamIdSet_defaultInputDeviceDidChange_defaultOutputDeviceDidChange_fetchIsDefaultInputBultInMic_fetchIsDefaultOutput BuiltInSpeaker_ getAudioDeviceDataSourceID: propertyScope: to:_getAudio DeviceName:_getAudio DeviceTransport Type: to: _getInputAudioDeviceDataSourceID: to:_ getOutputAudioDeviceDataSourceID: to: default Audio RouteChangeMonitorMac: didReceived InputAudioRouteChangeEvent: default Audio RouteChangeMonitorMac: didReceivedOutputAudioRouteChangeEvent: isDefaultInputBuiltInMicisDefaultOutputBultInSpeakerdefaultOutputAudioDeviceID_defaultInputDeviceChangedBlock_ defaultOutputDeviceChangedBlocknotify InEarMyriad Trigger secondsToHostTime: secondChance Hot TillMachTimesetSecond Chance Hot TillMachTime:_second ChanceHotTillMachTimeTQ,N,V_secondChance HotTillMach Time opportune Speak Listening TypesetOpportune Speak ListeningType:_opportuneSpeakListening TypeT@"NSString", &,N,V_deviceIdTQ,N,V_ opportuneSpeakListeningTypeprogrammable Audio InjectionEnableddefaultInjectionProvideraudioRecorderWithQueue: error: setSkip Alert Behavior: requestHistoricalAudioDataSampleCountsetRequestHistoricalAudioDataSampleCount:requestHistoricalAudioDataWith HostTimesetRequestHistoricalAudioDataWithHostTime: startRecordingHostTimesetStartRecordingHostTime: startRecording SampleCountsetStartRecording SampleCount: use OpportunisticZLLsetUseOpportunisticZLL: requireSingle ChannelLookupsetRequireSingleChannelLookup: selectedChannelsetSelectedChannel: disableBoostForDoAPsetDisableBoostForDoAP:setStartAlertBehavior: setStopAlertBehavior: setErrorAlertBehavior: setDisable Endpointer:setDisableLocalSpeechRecognizer:setDisable Prewarm LocalAsrAtStartRecording: setRequestMHUUID: setSiriSessionUUID: copyWithZone:initTandemWithOption: stopAlert Behavior error Alert BehaviorskipAlertBehaviorestimatedStartHostTimesetEstimatedStartHostTime:disableEndpointerdisableLocalSpeechRecognizerdisable PrewarmLocalAsrAtStartRecording requestMHUUIDsiriSessionUUID_requestHistoricalAudioDataWithHostTime_
requestHistoricalAudioDataSampleCount_useOpportunisticZLL_skipAlertBehavior_requireSingleChannelLookup_disableEndpointer_disableLocalSpeechRecognizer_
disable PrewarmLocalAsrAtStartRecording_disableBoostForDoAP_selectedChannel_startRecordingHostTime_startRecording
SampleCount_startAlertBehavior_stopAlertBehavior_
errorAlertBehavior_estimatedStartHostTime_requestMHUUID_siriSessionUUIDTC,N,V_requestHistoricalAudioDataWith HostTimeTc,N,V_requestHistoricalAudioDataSampleCountTQ ,N, V_startRecordingHostTime TQ,N,V_startRecording SampleCountTc,N,V_useOpportunisticZLLTq,N,V_startAlert BehaviorTq,N,V_stopAlertBehaviorTq,N,V_errorAlert BehaviorTc,N,V_skipAlert Behavior T@"NSObject<OS_xpc_object>", R, NTC,N,V_requireSingleChannelLookupTI,N,V_selectedChannelTQ,N,V_estimatedStartHostTimeTc,N,V_disableEndpointerTc ,N, V_disableLocalSpeechRecognizerTc,N,V_disable PrewarmLocalAsrAtStartRecording Tc,N,V_disableBoostForDoAPT@"NSString", &,N,V_requestMHUUIDT@"NSString", &,N,V_ siriSessionUUIDinitWithAttSiriController: addReceiver: removeReceiver: pauseattSiriControllersetAttSiriController: requiredNodessetRequired Nodes: mhIdset MhId: prefetchedAssetsetPrefetchedAsset:isReadysetIsReady: T@"CSAttSiriController", W, NTQ, R, NT@"NSArray", &, NT@"NSString", &, NT@"CSAsset", &, NTC, NstartRequestWithContext: withVtei:taskType: withVTAsset: completion: startRequestWithContext: withVtei:taskType: completion: addAudio: endAudio_isReady_type_requiredNodes_attSiriControllerT@"CSAttSiriController",W,N,V_attSiriControllerTQ,R,N,V_typeT@"NSArray", &,N,V_required Nodes Tc,N,V_isReadydistantPast_
getVoiceTriggerAssetselfTrigger DetectorEnabledPolicy_switchSelf Trigger Status:_wakeSiriIfNeededFromFullWake:_enableRemote Voice TriggerWithAsset:_ transfer Asset For RemoteContinuousVoiceTrigger: defaultCenter_transferSpeakerModel_sendSelfTriggerEnabledToRemote: force:_getPower AssertionIfNeeded_ getPower Assertion IfWakenByVoiceTriggerNotFromS3Sleep_invalidate RemoteCoreSpeech_isWakeReasonVoice Trigger_isWakeFromS3Sleep_wakeSiriWith TriggerEventInfo: myriadPHash:isTriggered FromFullWake: setPerceptualAudioHash: newWithBuilder:error_handleSelfTriggerDetected: trigger Voice ProfileMigrationWithCompletion: initWith Voice RetrainingContext: error: profileIDlocale_enableRemote Voice TriggerWithAsset: withSpeaker Profile: trigger RetrainingVoice Profile: with Context: withCompletion :_transferVoice TriggerAsset: with Completion: assetForCurrent LanguageOfType:registerVoiceTrigger EventsCoordinator: _wakeSiriWithMyriad PHash: setDelay InterstitialSounds :level:completion: voice Trigger Assetset VoiceTriggerAsset: LastSATUpdateTimestamp setLastSATUpdateTimestamp:
got Power AssertionFromEarlyWakesetGotPower Assertion FromEarlyWake: voiceProfileManagersetVoiceProfileManager: selfTriggerStartPolicysetSelfTriggerStartPolicy: selfTriggerEnabledsetSelfTriggerEnabled:_gotPowerAssertionFromEarlyWake_selfTriggerEnabled_voiceTrigger Asset_lastSATUpdateTimestamp_voiceProfileManager_ selfTriggerStartPolicy T@"CSAsset", &,N,V_voice TriggerAsset T@"NSDate", &,N,V_LastSATUpdateTimestampTc,N,V_gotPower AssertionFromEarlyWake T@"SSRVoiceProfileManager", &,N,V_voiceProfileManager T@"CSPolicy", &,N,V_selfTriggerStartPolicyTC,N,V_
selfTriggerEnabledis AttentiveSiriEnabledsupports Speech RecognitionOnDeviceinitWithAttSiriController: supportsAttentiveSiri: supportsSpeech RecognitionOnDevice: supportsSSR:_setupAttSiriServiceListener_setupEndpointListener_setup LocalSpeechRecognitionListener_setupSSRListener_ setupRCProcessing Listener setupConnection processServer FeaturesWithWordCount: trailingSilence Duration: eosLikelihood: pause Counts: silencePosterior: taskName: processedAudioDurationInMilliseconds: getEndpointerModelVersionWithReply:updateEndpointer Threshold: updateEndpointerDelayed Trigger: shouldAcceptEagerResultForDuration: results CompletionHandler:setStart Wait Time: setEndWait Time:setAutomatic EndpointingSuspensionEndTime:
getElapsed Time NoSpeechWithReply:getEndPoint AnalyzerTypeWithReply: resetForVoice Trigger Two ShotWithSampleRate:setEndpointerOperationMode: interfaceWithProtocol: didDetectStartpointAtTime: didDetectHardEndpointAtTime: with Metrics: getNodeOfType: initWithMachService: withServiceInterface:with ServiceObject: with DelegateInterface: queue: setEndpointerListener: resumeConnectionpreheatLocalSpeechRecognitionWithLanguage:source: startDeliver LocalSpeech Recognition ResultsWithSettings: stopDeliverLocalSpeechRecognitionWithReason:requestId: disableLocalSpeechRecognition ForRequestId: pauseLocalSpeechRecognition ForRequestId: resumeLocalRecognitionWithRequestId: prefixText: postfixText:selectedText: resetCacheAndCompile AllAssetssendSpeechCorrection Info: interactionIdentifier: LocalSpeechServiceDidReceived PartialResultWithRequestId: language: tokens: localSpeechService Did Received FinalResultWithRequestId: speechPackage: LocalSpeechServiceDidReceived EagerRecognition CandidateWithRequestId: rcId: speechPackage: duration:localSpeechServiceDidReceived Eager ResultWithRequestId: rcId: shouldAccept: mitigation Signal: featuresToLog: LocalSpeechServiceDidCompletion RecognitionWithStatistics: requestId: endpointMode: error: LocalSpeechServiceDidReceived VoiceIdScoreCard: LocalSpeechServiceDidReceived PartialResultWithRequestId: language: tokens: metadata:
LocalSpeechService DidReceivedEagerRecognitionCandidateWithRequestId: rcId: speechPackage: duration: metadata:localSpeechService DidReceivedFinalResultWithRequestId: speechPackage: metadata:localSpeechServiceDidReceived FinalResultCandidateWithRequestId: speechPackage:targetQueuesetLocalSRBridgeListener:startAttendingWithContext: stopAttendingWithContext: siriRequestProcessing CompletedattSiriDid DetectAttending Trigger: attSiriAttendingTimeoutTriggeredattSiriAttending Failed initWithMachService: withServiceInterface: with ServiceObject: with DelegateInterface:setAttSiriSvcListener:startXPCConnectiondidReceiveSpeaker RecognitionScoreCard: didFinishSpeaker Recognition: setSsrListener: processRCWithId: duration: lrnnScore: lrnnThreshold:taskId: forceAccept: completionHandler: getMitigation DecisionForRCIdWithCompletion: completion: rcHandler setupListenersendpointerListenerlocalSpeech RecognitionListenersetLocalSpeechRecognitionListener: attSiriSvc ListenerssrListenerrcProcessing ListenersetRcProcessingListener:setSupportsSpeech RecognitionOnDevice: supports SSRsetSupportsSSR:_ supportsSpeechRecognitionOnDevice_supportsSSR_endpointerListener_localSpeech RecognitionListener_attSiriSvcListener_ssrListener_rcProcessing ListenerT@"CSAttSiriController", &,N,V_attSiriControllerT@"CSConnectionListener", &,N,V_endpointerListenerT@"CSConnectionListener", &,N,V_LocalSpeech RecognitionListenerT@"CSConnectionListener", &,N,V_attSiriSvcListenerT@"CSConnectionListener", &,N,V_ssrListener T@"CSConnectionListener", &,N,V_rcProcessing ListenerTc,N,V_ supportsSpeechRecognitionOnDevice Tc,N,V_supports SSR_didReceiveDaemonStateChanged:_notifyObserver: withDaemonState: coreSpeech DaemonStateMonitor: didReceiveStateChanged: notifyDaemonStateChanged: startWithRecordContext: processSpeechPackage: processSpeech PackageSync:updateCachedScoresForLogging: LogMHOdldFTMScores: _mhIdT@"NSString", &,N,V_mhIdinitializeMediaPlayingStatemediaPlayingStatemediaPlayingStateWithCompletion: _mediaIsPlaying initWithDeviceID: speechManager: remoteMicVADScoresetRemote MicVADScore: speech Managerset SpeechManager:_remoteMicVADScore_speech ManagerTf,N,V_remoteMicVADScore T@"CSSpeechManager", &,N,V_speechManager phone CallStateMonitorphoneCallStateinitWithSpeechManager: voiceTriggerEnabledMonitor: siriClientBehavior Monitor: phone CallStateMonitor: other AppRecordingStateMonitor: _setAsset: decodeConfigFrom: forFirstPassSource: wearerDetectionConfigthreshold myriad Threshold minimumPhrase LengthphrasesToSkipBoronDecision MakingphraseSpotterEnabledsupportRingtone A2DPisOtherNon EligibleAppRecord ingisStreaming_handleRemoteMicVoice TriggerEvent: secondPassRequest:completion: vadScore_handleRemoteMicVADEventWithSecondPass Request: setPhoneCallState:shouldOverwrite RemoteVADScoreoverwriting RemoteVADScorecontextForHearst Voice TriggerWithDeviceId: _requestStartAudioStreamWitContext:secondPassRequest: startStreamOption: completion: voiceTrigger Did Detect Speaker Reject:setRequires HistoricalBuffer: audioStreamWithRequest: stream Name: error: siriClientBehavior Monitor: willStartStreamWithContext: option: siriClientBehaviorMonitor: didStartStreamWithContext: successfully: option: withEvent UUID: siriClientBehavior Monitor: willStopStream: reason: siriClientBehavior Monitor: didStopStream: withEventUUID: siriClientBehaviorMonitor: didChanged RecordState:with Event UUID: withContext: siriClient Behavior Monitor: fetchedSiriClientAudioStream: successfully: siriClientBehavior Monitor: preparedSiriClientAudioStream: successfully: siriClientBehavior Monitor ReleasedAudioSession: CSPhoneCallStateMonitor: didRecieve PhoneCallStateChange: hearst SecondPassRequestssetHearst SecondPass Requests: airpodWearerConfigsetAirpodWearerConfig: remoteMicVADThresholdsetRemote MicVADThreshold: remoteMicVADMyriad ThresholdsetRemoteMicVADMyriad Threshold: minimumPhrase Length ForVADGatingsetMinimum PhraseLength ForVADGating: setPhrasesToSkipBoron Decision Making: triggeredAudioStreamHoldingsetTriggeredAudioStreamHolding: setPhoneCallStateMonitor: other AppRecordingStateMonitorsetOtherAppRecordingStateMonitor: siriClientBehavior Monitorset SiriClientBehavior Monitor: voiceTriggerEnabledMonitorsetVoiceTriggerEnabled Monitor: _remoteMicVADThreshold_remoteMicVADMyriad Threshold_minimumPhrase Length ForVADGating_ hearstSecondPassRequests_airpodWearerConfig_phrasesToSkipBoron Decision Making_triggeredAudioStreamHolding_phoneCallStateMonitor_phoneCallState_ other AppRecordingStateMonitor_siriClientBehavior Monitor_voiceTriggerEnabled MonitorT@"NSMutableDictionary", &,N,V_hearst SecondPassRequestsT@"CSVoiceTriggerAirPodWearerDetectionConfig", &,N,V_airpodWearerConfigTf,N,V_remoteMicVADThreshold Tf,N,V_remoteMicVADMyriad Threshold Tf,N, V_ minimumPhrase Length ForVADGatingT@"NSArray", &,N,V_phrasesToSkipBoron Decision MakingT@"CSAudioStreamHolding", &,N,V_triggeredAudioStreamHolding T@"CSPhoneCallStateMonitor", &,N,V_phoneCallStateMonitorTQ,N,V_phoneCallState T@"CSOtherAppRecordingStateMonitor", &,N,V_other App RecordingState MonitorT@"CSSiriClientBehavior Monitor", &,N,V_siriClientBehavior MonitorT@"CSVoiceTriggerEnabledMonitor", &,N,V_voiceTriggerEnabled Monitor built InVoice TriggerEnabled Policy_ addContinousAudioFingerprintEnabledConditionsaudioStreamstreamProvidernamesetAudioStream: setRecordContext:_isHubRequest_setAllow Mixable AudioWhile Recording: notifyWillStopStream: reason: notifyWillStopStream: reason: forAccessory: notifyWillStopStream: notifyDidStopStream: withEventUUID: notifyDidStopStream: reason: withEventUUID: forAccessory: notifyDidStopStream: stopAudioStreamWithOption: completion: _handleSetCurrentConextMessage: messageBody:client:_ handleAudioStreamRequestMessage:messageBody: client:_handleAudioStream PrepareMessage:message Body: client: _handleStartAudioStreamMessage: message Body: client:_ handleStopAudioStreamMessage: messageBody: client: _handle Voice Trigger InfoMessage: messageBody: client: _handle IsRecording Message: messageBody: client:_ handleRecordRouteMessage: message Body: client: _handleRecordDevice Info:message Body: client:_handleAudioDevice Info:messageBody: client: _handleRecordSettings:message Body :client:_handle IsNarrowband: message Body: client:_handlePlaybackRoute Message:messageBody: client:_handleSupportsDuckingWithStreamHandleID: messageBody:client: audioStreamProviding_sendReply: client: result: error: supportsDuckingOnCurrentRouteWithError: setCurrentContext: error: notifyFetched SiriClientAudioStream: successfully: streamRequestprepareAudioStreamSyncWithRequest: error: notify PreparedSiriClientAudioStream: successfully:notifyWillStartStreamWithContext:option: notifyWillStartStreamWithContext: option: for Accessory: copynotifyWillStartStreamWithContext: audio Provider UUID: option:notifyDidStartStreamWithContext: successfully: option:withEventUUID:notifyDidStartStreamWithContext: successfully: option: withEventUUID: for Accessory: notifyDidStartStreamWithContext: successfully: option: notifyDidStartStreamWithContext: audioProvider UUID: successfully: option: startAudio StreamWithOption: completion: fetchVoice Trigger InfoWithAudioContext: triggerInfoProviding: resultVoiceTrigger Info: resultRTSTrigger Info: recordDeviceInfoaudioDeviceInfo recordSettingsisNarrow Band_sendDelegateMessageToClient: sendMessageToClient: audioStreamProvider: didStopStreamUnexpectly: audioStream Provider: audioBuffer Available: audioStreamProvider: audioChunk For TVAvailable: audioStreamProvider: did HardwareConfigurationChange: audioStreamProvider: remoteRecorder Did Detected TwoShotAtTime: setAudioStreamProvidingForProxy: setInitialContext: triggerInfoProvidingset Trigger InfoProviding: recordEventUUIDsetRecordEventUUID: accessoryIdset AccessoryId:_audioStreamProviding_trigger InfoProviding_audioStream_ recordContext_recordEvent UUID_accessoryIdT@"CSAudioStream", &,N,V_audioStreamT@"CSAudioRecordContext", &,N,V_recordContextT@"NSString", &,N,V_recordEventUUIDT@"NSString", &,N,V_accessory IdT@"<CSAudioStreamProviding>", W, N, SsetAudioStream ProvidingForProxy:,V_audioStreamProviding T@"<CSTriggerInfoProviding>",W,N,V_ triggerInfoProviding numberWith Unsigned LongLong:_initWithFirstPass InfoGeneratedTime: firstPass InfoProcessed Time: firstPass InfoGenerated Time firstPass InfoProcessedTime _firstPassInfoGeneratedTime_firstPass InfoProcessed TimeT@"NSNumber",R,N,V_firstPassInfoGeneratedTimeT@"NSNumber",R,N, V_ firstPassInfoProcessedTime is Mitigation Asset OverridingEnabled fakeMitigationAssetPathinitWithAsset Manager: with TrialAsset Manager: with TrialDownloadMonitor: withAssetOverrideFlag: withOverrideAssetPath: setCachedAsset:stringByDeleting LastPathComponentassetForAssetType:resource Path: configVersion: assetProvider: cachedAssetinitWithDomain: code: userInfo:getInstalledAssetofType: forLocale: completion: assetProvider_received NewAssetUpdate: trialAssetDownloadMonitorDelegate: did InstallNewAsset: assetType:getMitigationAssetWithEndpointId: completion: asset Manager setAsset Manager: trialAsset Manager setTrialAsset Manager: trialDownloadMonitorset TrialDownloadMonitor: overrideEnabledsetOverrideEnabled: override PathsetOverridePath:_overrideEnabled_cachedAsset_assetManager_ trialAssetManager_trialDownloadMonitor_override Path T@"CSAsset", &, V_cachedAsset T@"CSAsset Manager", &,N,V_asset Manager T@"CSTrialAsset Manager", &,N,V_ trialAsset ManagerT@"CSTrialAsset Download Monitor", &,N,V_trialDownloadMonitor Tc,N,V_override Enabled T@"NSString", &,N,V_overridePathinitWithMode: deviceUID: supportHandsFreeisRequestDuringActiveCallsetActivationMode:setAnnounceCallsEnabled: deviceProductTypeintValuesystemUpTimesharedPowerLoggerpowerWithNumFalseWakeup: withDuration: withPhraseDict: numberWithLongLong: reportDigitalZerosWithAudioZeroRun: LogAOPFirstPassTriggerWakeup Latency: LogFalseWake Up: withPhrase: LogTriggerLengthSampleCountStatistics: withFirstPassDeterministic TriggerLengthSampleCount: numFalseWakeUpsetNumFalseWakeUp: lastAggTimeFalseWakeUpsetLastAggTimeFalseWake Up: falseWakePhraseDictionary setFalseWake PhraseDictionary:_numFalseWakeUp_lastAggTimeFalseWakeUp_ falseWakePhraseDictionaryTQ,N,V_numFalse WakeUpTQ,N,V_lastAggTimeFalse WakeUpT@"NSMutableDictionary", &,N,V_falseWakePhraseDictionary initWithSpeechManager: audioStreamProvider: streamName:streamRequest: initWithAudioStreamProvider: streamName:streamRequest: _handleDidAudioStartWithResult: error:_ handleDidStopattSiriAudioSrc Node DidStart Recording: successfully: error: attSiriAudioSrc NodeLPCMRecordBuffer Available: audioChunk: attSiriAudioSrcNodeDidStop:_ handleDidStopStreamUnexpectlyhandleAttendingAudioStop Unexpectly receiverssetReceivers: _receivers T@"NSHashTable", &,N,V_receiversinitWithResult: voiceTriggerEventInfo :isSecondChanceCandidate: _isSecond Chance Candidate_result_voiceTriggerEventInfoTQ,R,N,V_resultT@"NSDictionary",R,N,V_voiceTrigger Event InfoTc,R,N,V_ isSecond ChanceCandidate_clearTriggerCandidate_initializeMediaPlayingState audio StreamIdgetSiriLanguageWithEndpoint Id: fallbackLanguage:_
resetStartAnalyze TimeresetWithContext: preTrigger Audio Time prependingAudioTimetrailingAudioTime_voiceTriggerSecondPassLatencyMetrics setSecondPassAssetLoadStartTime:setConfig:setSecondPassAsset LoadComplete Time: supportSATcontains Speaker RecognitionCategory_
fetchSiriLocale triggerInvalidSiriProfile CleanupFromPersonalDevicesForLanguage: appDomain: useSpeaker RecognitionAssetinstalledAssetOfType: Language: initWith Voice RecognitionContext: error: initWithContext: with Delegate: error: phraseConfigsspeaker Reject Logging ThresholdmusicVolumeWithCompletion: setSecondPass AudioStreamReadyTime:setSecondPassAudioStreamStartTime: audio ProviderWithUUID: setAudio Provider UUID: _prepareStartAudioStream_didStartAudioStream:_ shouldRequestSingleChannelFromAudio Provider inputRecordingDurationInSecs_requestStartAudioStreamWitContext: audioProviderUUID: startStream Option: completion: setResultCompletion: initWithAsset: assetConfig: firstPass Source:activeChannel: siriLanguage: shouldEnableShadowMicScore: unsignedIntValuecontextForJarvisWithDeviceId:_ voiceTriggerFirstPassDidDetect KeywordFrom: completion: _didStopAudioStream_handleResultCompletion: voiceTrigger Info:isSecondChanceCandidate: error:_ getFirstPassTriggerSourceAsString:_resetVoice TriggerLatencyMetricsfirstPassSourceaudioProviderUUIDfirstPassTrigger Infois SecondChanceRunrejectionMHUUIDfirstpassMet rics_isBuiltInFirstPass Source:useSiriActivationSPIFor Home Podis Local Voice TriggerAvailable notifyBuiltInVoice Trigger Prewarm: completion: notifyBluetooth Device Voice Trigger Prewarm: deviceId: completion: notify Remora Voice Trigger Prewarm: deviceId:completion:_ clearSecondPass CompletionWatch DogupdateVTEstimationStatistics:_scheduleSecondPassCompletionWatchDog_getDidWake AP: setRunAsSecondChance: _ handleVoiceTriggerFirstPassFromAP: audioProviderUUID: completion: _handle Voice TriggerFirstPassFromHearst: deviceId: audioProviderUUID: firstPass Info: completion:_ handleVoiceTriggerFirstPassFromHearstAP: deviceId: audioProviderUUID: firstPass Info: completion: _handleVoiceTriggerFirstPassFromRemora: deviceId: audioProviderUUID: firstPassInfo: completion: _handleVoiceTriggerFirstPassFromJarvis: deviceId: audio Provider UUID: firstPass Info: completion: _handle Voice TriggerFirstPassFromAOP: audioProviderUUID: completion: incrementFirstPassTriggerCount_addDeviceStatus InfoToDict:_logRejectionEventToSELF: result: sharedAnalytics logEventWithType:context: secondPassAudio LoggingEnabledsecondPassAudioLoggingFilePathWithDeviceId:_handleAudioChunk: setSecondPass FirstAudio PacketReception Time: startSampleCount_ setStartAnalyze Time: numSamples subChunk From: numSamples: _runRecognizersWithChunk: getAnalyzed ResultFromFlushedAudio_setKeywordDetectorStartMachTime: detectorEndMach Time: LastAudioPacket Analyzed MachTime:_analyzeForChannel: keywordDetectorResult:getAnalyzedResultFromAudioChunk: processAudioChunk:activeChannel: dataForChannel: convertToShort LPCMBufFromFloat LPCMBuf: processAudio: with NumberOfSamples: phIdphraseDetectorInfoFromPhId: phraseConfigndapiResultcombinedScoresamples FedbestEndsamplesAtFire_getAudioTimeConverterhostTimeFromSampleCount:batteryState_logUptimeWith VTSwitchChanged: VTEnabled: pre Trigger SilenceOffsetdevice BuildVersionis SecondChance effectiveKeywordThresholdis RunningQuasar recognizer Scorerecognizer Score OffsetrecognizerScoreScaleF actorsupportJarvis Voice Trigger_shouldLogMediaplayState: secondPassAssetQueryStartTimehost TimeToNs: secondPassAssetQueryCompleteTime secondPassAssetLoadStartTime secondPassAsset LoadCompleteTime secondPassAudioStreamStartTime secondPassAudioStreamReadyTime secondPassF irstAudioPacketReception Time secondPass LastAudioPacket Reception Time secondPassCheckerModelKeyword DetectionStartTime secondPassCheckerModelKeywordDetectionEndTimesetS econdPassCheckerModelKeyword DetectionStartTime: setSecondPassCheckerModelKeywordDetection End Time: setSecondPassLastAudio PacketReception Time: decisionsupportMph_ getVoiceTrigger InfoWithKeyword DetectorResult:getLatestSpeaker Info_handleSecondPassSuccess: _handlePHSResults: voice Trigger Event Info: forPhId: reset PHSRejectCountaddVTRejectEntry: truncateData:_notifySecondPassReject: result:isSecond ChanceCandidate: _markSecondPassTriggerMachAbsolute Time: config_ support Two Shot FeedbackDelay two Shot FeedbackDelayremora Two Shot Feedback Delay current ShadowMicScoreshadow MicScore Threshold ForVAD_resetUpTime addVTAcceptEntryAndSubmit: unsigned LongValueis IOSDevice Supporting Barge InsupportRemora Voice Triggerprune NumberOfLogFiles To: channelForProcessed Input hostTimeToSeconds: initWithBlob: isEarlyDetected:getLastPHSRejectTimegetPHSRejectCountlongLongValuegetBiometricMatch ResultForTriggerTimeStamp:is Trigger HandheldallValuessat Score ThresholdForPhId:_ isReduced PHSThresholdEnabled keyword Reject Logging Threshold incrementPHSRejectCountsecondPass Audio LogDirectorytimeStampStringvoiceTriggerAudioLogDirectorystring For Se condPassResult: stringBy Appending Format: _LogSecondPass Result: withVTEI:_scheduleDidStartSecondPassCompletionWatchDogWithToken: submit Voice TriggerIssueReport: voiceTrigger PhraseNDEAPIScorer Did DetectedKeyword: bestStartSampleCount:bestEndSampleCount: CSVoiceTriggerEnabledMonitor: didReceiveEnabled: CSMediaPlaying Monitor: didReceiveMediaPlayingChanged: CSVolumeMonitor: didReceiveMusicVolumeChanged: CSVolumeMonitor: didReceiveAlarm VolumeChanged: speakerRecognitionController: hasSpeaker Info: speakerRecognition Finished Processing: withFinalSpeaker Info: selfTriggerDetector: didDetectSelfTrigger: initWithPHSEnabled: secondPassTriggerMachAbsTime secondPass CompleteWatchDogTimeoutSecsetSecondPassCompleteWatch DogTimeout Sec: phrase Detector setPhraseDetector: phraseNDEAPIScorersetPhraseNDEAPIScorer: speakerRecognition ControllersetSpeaker RecognitionController: ssrContextsetSsrContext: resultCompletionsecondPassTimeoutsetSecondPassTimeout: numProcessedSamplessetNumProcessedSamples: numAnalyzed SamplessetNumAnalyzed Samples: secondPassPrependingSecsetSecondPassPrependingSec: phs Reject Logging Thresholdset PhsReject Logging Threshold: extraSamplesAtStartsetExtraSamplesAtStart: analyzer Prepending Samplesset Analyzer Prepending Samples: analyzer Trailing Samplesset Analyzer Trailing Samples: shouldUse PHSsetShouldUsePHS: early DetectFired Mach TimesetEarly DetectFired MachTime: active Channel selectedChannelFromFirstPasssetSelectedChannelFromFirstPass: processedSample Counts In PendingsetProcessed SampleCountsInPending: firstPassTriggerStartSampleCountsetFirstPass Trigger StartSampleCount: firstPassTriggerFireSampleCountsetFirstPass TriggerFireSampleCount:firstPassChannelSelectionScoressetFirstPassChannelSelectionScores: firstPassChannelSelection Delay SecondssetFirstPassChannelSelection Delay Seconds: firstPassMasterChannelScoreBoostsetFirstPassMasterChannelScoreBoost: firstPassOnsetScoresetFirstPassOnsetScore: firstPassOnsetChannel setFirstPassOnsetChannel: didWake APsetDid WakeAP: has TriggerCandidatesetHas TriggerCandidate: isStartSampleCountMarkedsetIsStartSampleCountMarked: secondPassAnalyzer StartSampleCountsetSecondPassAnalyzerStartSampleCount:setSecondPassTriggerMachAbsTime: stateSerialQueuesetStateSerialQueue:lastAggTimesetLastAggTime: cumulativeUptime setCumulativeUptime: cumulative Downtime setCumulativeDowntime: firstPassDeviceIdsecondPassClientcurrentLocalesetCurrentLocale: audioFileWritersetAudioFileWriter: secondPassHas Made DecisionsetSecondPassHas Made Decision: setMediaPlayingState: mediaVolumeset Media Volume: secondPassComplete Watch DogTokensetSecondPassCompleteWatchDogToken:
addPHSInfoToVTEI: from Speaker Info: with Threshold:_addRejectStatsToDict:
firstTimeAssetConfiguredsetFirstTimeAssetConfigured: assetConfigWaitingBuffersetAssetConfigWaitingBuffer: audioTime ConvertersetAudio TimeConverter: storedFirstPass InfosetStored FirstPass Info:secondPassRejectionMHUUIDsetSecondPass RejectionMHUUID: hasLogged SecondPassset Has Logged SecondPass: setFirstpassMetrics: secondPassLatencyMetricssetSecondPassLatencyMetrics:_shouldUsePHS_didWake AP_hasTriggerCandidate_isStartSampleCountMarked_secondPassHas Made Decision_ firstTimeAssetConfigured_has Logged SecondPass_secondPassComplete Watch DogTimeoutSec_secondPassPrependingSec_phsReject LoggingThreshold_firstPassChannelSelection Delay Seconds_firstPassMasterChannelScoreBoost_firstPassOnset Score_mediaVolume_UUID_config_audio Provider UUID_phraseDetector_ phraseNDEAPIScorer_speaker RecognitionController_ssrContext_resultCompletion_secondPassTimeout_numProcessedSamples_numAnalyzed Samples_extraSamplesAtStart_ analyzer Prepending Samples_analyzer Trailing Samples_early DetectFired MachTime_activeChannel_selectedChannelFromFirstPass_processed Sample CountsInPending_ firstPassTriggerStartSampleCount_firstPassTriggerFire SampleCount_firstPassChannelSelectionScores_firstPassOnsetChannel_secondPassAnalyzerStartSampleCount_
secondPassTriggerMachAbsTime_stateSerialQueue_lastAggTime_cumulativeUptime_cumulative Downtime_firstPass Source_firstPassDeviceId_secondPassClient_currentLocale_ audioFileWriter_mediaPlayingState_secondPassCompleteWatchDogToken_assetConfigWaitingBuffer_audioTimeConverter_storedFirstPass Info_secondPass RejectionMHUUID_ firstpassMetrics_secondPassLatencyMetricsT@"CSVoiceTrigger SecondPassConfig", &,N,V_config T@"NSString", &,N,V_audioProvider UUIDT@"CSPhrase Detector", &,N,V_ phraseDetectorT@"CSPhraseNDEAPIScorer", &,N,V_phraseNDEAPIScorer T@"SSRSpeaker RecognitionController", &,N,V_speakerRecognitionControllerT@"SSRSpeaker RecognitionContext", &,N,V_ssrContextT@?,C,N,V_resultCompletion TQ,N,V_secondPassTimeout TQ,N,V_num Processed SamplesTQ,N,V_numAnalyzed SamplesTf,N,V_ secondPassPrependingSecTf,N,V_phs Reject Logging Threshold TQ,N,V_extraSamplesAtStartTQ,N,V_analyzer PrependingSamples TQ,N,V_analyzer Trailing SamplesTc,N,V_ shouldUsePHSTQ,N,V_earlyDetectFired MachTime TQ,N,V_activeChannelTQ,N,V_selectedChannelFromFirstPass TQ,N,V_processedSample Counts In PendingTQ,N,V_ firstPassTriggerStartSampleCountTQ,N,V_firstPassTriggerFireSampleCountT@"NSDictionary", &,N,V_firstPassChannelSelectionScoresTf,N,V_ firstPassChannelSelection Delay SecondsTf,N,V_firstPassMasterChannelScoreBoostTf,N,V_firstPassOnsetScore TQ,N,V_firstPassOnsetChannelTc,N,V_didWakeAPTC,N,V_ hasTriggerCandidateTc,N,V_isStartSampleCountMarked TQ,N,V_secondPassAnalyzer StartSampleCountTQ,N,V_secondPassTrigger MachAbsTimeT@"NSObject<OS_dispatch_queue>", &,N,V_stateSerialQueueTd,N,V_lastAggTimeTd,N,V_cumulativeUptimeTd,N,V_cumulative Downtime T@"CSAudioCircularBuffer",W,N,V_audioBufferTQ,N,V_firstPassSourceT@"NSString", &,N,V_firstPass DeviceIdTQ,N,V_secondPassClientT@"NSString", &,N,V_currentLocaleT@"CSPlain AudioFileWriter", &,N,V_audioFileWriterTc,N,V_secondPass Has Made DecisionTq, N ,V_mediaPlayingStateTf,N,V_mediaVolume T@"NSUUID", &,N,V_secondPass CompleteWatch DogTokenTc,N,V_firstTimeAssetConfiguredT@"NSMutableArray", &,N,V_ assetConfigWaitingBufferT@"CSAudioTime Converter", &,N,V_audioTimeConverter T@"NSMutableDictionary", &,N,V_storedFirstPass InfoT@"NSUUID", &,N,V_ secondPassRejectionMHUUIDTC,N,V_has Logged SecondPassT@"CSVoiceTriggerFirstPassMetrics", &,N,V_firstpassMetrics T@"CSVT SecondPass LatencyMetrics", &,N,V_ secondPassLatencyMetricsT@"NSString",R,N,V_UUIDTf,N,V_secondPassCompleteWatch DogTimeoutSecsupportZeroFilter: supportBeepCanceller: resetWithSampleRate: contains Voice Trigger: voiceTrigger Info: resetWithSample Rate: initWithToken: sample Rate: numChannels: setSampleRate:_isNarrowBand: upsamplersetUpsampler: zeroFilterbeepCancellergetZeroStatisticsFromBuffer: entireSamples: convertSampleRateOfBuffer: processBuffer: atTime:cancelBeepFromSamples: timestamp:audioPreprocessor: hasAvailableBuffer:atTime: arrival TimestampToAudioRecorder: numberOfChannels: flushstopCountingZeroStatisticsWithReporter:_ reportMetricsis HeadphoneDeviceWithRecord Route: playbackRoute: willBeep_fetchCurrentMetricslogCoreSpeech Preprocessor CompletedWithMHUUID: with Metrics Dictionary: inputRecording Sample RateNarrowBandzeroFilter:zeroFilteredBuffer Available: atHostTime: beepCancellerDidCancelSamples: buffer: timestamp: initWithSample Rate: withNumberOfChannels: processBuffer: atTime: arrivalTimestamp To Audio Recorder: willBeepWith RecordRoute: playbackRoute: reportMetricsForSiriRequestWithUUID: setZeroFilter: setBeepCanceller:zeroCountersetZeroCounter: numChannels_sampleRate_numChannels_upsampler_zeroFilter_beepCanceller_zeroCounterTf,N,V_sampleRateT@"CSAudioSample RateConverter", &,N,V_upsampler T@"CSVoiceTrigger AwareZeroFilter", &,N,V_zeroFilterT@"CSBeepCanceller", &,N,V_beepCancellerT@"CSAudioZeroCounter", &,N,V_ zeroCounterTi,N,V_numChannelsT@"<CSAudioPreprocessorDelegate>",W,N,V_delegatestartObservinggetLastBiometricMatchEvent: atTime: T@"<CSBiometric Match MonitorDelegate>",W,N, V_delegate audioSessionProvidersetAudio SessionDelegate: audioAlertProvidersetAudioAlertDelegate:setAudioSessionProvider: setAudioAlertProvider: setAudioMeter Provider: _handleClientEvent: connection_handleClientMessage: client: _handleClientError: client: _handleAudio ProvidingMessage: messageBody: client:_ handlePingPongMessage:client:handleXPCMessage: message Body: client: audioStreamHandleId:_handleSet XPCClientTypeMessage: message Body: client:_ handleAudioProviding RequestTypeSwitchMessage: messageBody: client:_getAudio ProvideWithContext: streamClientType:_notifyXPCDisconnectionToProxiesclientType_ notifyXPCDisconnectionToProxy: initWithConnection: activateConnectionsetConnection: audioSession Providing ProxysetAudio Session ProvidingProxy: fallbackAudio Session Providing ProxysetFallbackAudioSession Providing Proxy: audioStream ProvidingProxysetAudioStreamProviding Proxy: audioAlertProvidingProxysetAudioAlertProviding Proxy: audioMeterProviding ProxysetAudioMeter Providing Proxy: audioMetricProviding ProxysetAudioMetricProviding Proxy: setClientType:_audioSessionProvidingProxy_fallback AudioSessionProvidingProxy_audioStream Providing Proxy_audioAlert Providing Proxy_audioMeter ProvidingProxy_ audioMetricProviding Proxy_clientTypeT@"NSObject<OS_xpc_object>", &,N,V_connection T@"CSAudio Session ProvidingProxy", &,N,V_audioSession Providing Proxy T@"CSFallbackAudio Session ReleaseProviding Proxy", &,N,V_fallbackAudioSession Providing Proxy T@"CSAudio StreamProviding Proxy", &,N,V_audioStreamProvidingProxyT@"CSAudioAlertProviding Proxy", &,N,V_audioAlertProviding Proxy T@"CSAudioMeter ProvidingProxy", &,N,V_audioMeter ProvidingProxyT@"CSAudioMetricProvidingProxy", &,N,V_ audioMetricProviding Proxy TQ,N,V_clientTypeT@"<CSXPCConnectionDelegate>",W,N,V_delegateis RecordContextHearstVoiceTrigger:isRecordContext Jarvis VoiceTrigger: isRecordContextDarwinVoiceTrigger:isRecordContextHearst DoubleTap:isRecordContextRaise To Speak: is RecordContextAutoPrompt: isRecordContextSpeakerIdTrainingTrigger: isRecordContext JarvisButtonPress: isValid RecordContext: recordContextString:_addVoice TriggerEnabledConditionsisClamshellClosedisSiriRestrictedOnLockScreen_cs_ isHashTableEmptysplitterStatewakeHostForVoice Triggershould Voice Trigger Run_notify TriggerEvent: deviceId: completion:_notify Remote TriggerEvent: myriad Hash: remoteTriggerType: remoteDeviceId: isTriggeredFromFullWake: completion: _notifyNearMissEvent: deviceId:_notifySpeakerReject:_notifyKeyword Reject: deviceId:_ notifySuperVector:_notifyKeywordDetect_notify RaiseToSpeakTriggerEvent: appendString: notifyWake KeywordSpokenBluetoothDevice: deviceId: notifyWakeKeyword SpokenCarPlay: deviceId:notifyWakeKeywordSpokenRemora: deviceId: notifyWake KeywordSpokenInBuiltInMic: _notifyWake KeywordSpokenEvent: deviceId:_shouldIgnoreVoiceTriggerEvent: setVoice Trigger Info: deviceId:_createVoice Trigger Event InfoString:_print Voice TriggerMetricsString:_isVoiceTriggerFromRemora: _myriad PhashFromVoice Trigger Info: notifyBuiltInVoice Trigger: myriad PHash: completion: supportHomeKit Accessorynotify Remora VoiceTrigger: myriad PHash: deviceId: completion: generateEmptyPHash:writeFile: notifyCarPlayVoice Trigger: deviceId: myriad PHash: completion:_isVoice Trigger FromHearst:notifyBluetoothDevice Voice Trigger: deviceId: completion: generatePHashFromVoice TriggerInfo:writeFile:decodeWithMyriad PHash:absTimenotifyDarwinVoice Trigger: deviceId: myriad PHash: myriad LateActivationExpirationTime: completion: keywordDetectorDidDetect KeywordvoiceTriggerGotSuperVector: raiseToSpeak Detected: setTargetQueue:_targetQueue_ splitterState supportRelay CallinitWithEndpoint Threshold: initWithAnalyze ModeaddAudio: numSamples: getFrame Duration MST@"<CSSPGEndpointAnalyzerDelegate>",W,N,V_ delegateinitWithType: deviceId: activation Info: vadScore:hosttime: initWithType: deviceId: activation Info:hosttime: _activationTypeStringremoteMicVADEvent: vadScore: hostTime: builtInMicVoiceTriggerEvent:hostTime: jarvisVoiceTriggerEvent: activation Info: hostTime: remoraVoice TriggerEvent: hostTime: remora VoiceTriggerEvent: activationInfo: hostTime:mediaserverd Launched Event: _vadScore_activation Info_hosttime T@"NSString",R,N,V_deviceIdT@"NSDictionary",R,N,V_activation InfoTQ,R,N,V_ hosttimeTf,R,N,V_vadScoreRTModelWithFallbackLanguage:built InRTModelDictionarymodelDatainitWithBlob: _setBuiltInRTModelDictionary: enableVoiceTriggerListening: completionBlock:updateVoice TriggerConfiguration: completion Block: enable Voice TriggerOnAlwaysOnProcessorWithAsset: completion: disableVoiceTriggerOnAlwaysOnProcessorWithCompletion: _aopSwitchGroupsupportAttentionLostAndGainset Name: _name T@"NSString", &,N,V_namesetForceAcquirePower Assertion: setForced Power AssertionTimeout: setForceUser Session Active:_force Acquire Power Assertion_forceUserSessionActive_forced Power AssertionTimeoutTc,N,V_ forceAcquirePowerAssertionTd,N,V_forced PowerAssertionTimeoutTc,N,V_forceUserSession Active_readAudioBufferAndFeeddataWith Length: closereadSamplesFromChannelIdx:_ fFile_audioFeedTimer_bufferDuration_outASBDT@"<CSAudioFileReaderDelegate>",W,N,V_delegate_createHandlerWithDevice: initWithVoice TriggerEvents Coordinator: device Browser setDeviceBrowser:handlerssetHandlers: _device Browser_handlers T@"OS_remote_device_browser", &,N,V_device BrowserT@"NSMutableArray", &,N,V_ handlersisPluginContextinitWithDeviceType: device Name: deviceID:productID: _createSpeech DetectionVADIfNeededisPlugin Device_connectPlugin Device:_ tearDownSpeechDetection VADIfNeededsetInjectionEngine: injectionEngine deviceName deviceUIDproductIdentifierinitWithRoute:is RemoteDevice: remoteDeviceUID: remoteDeviceProductIdentifier: use SpeexForAudio Injection streamHandleIDprimary Input DeviceconnectDevice: disconnectDevice: setDuckOthersOption: duckOthersOptiondidStart DelayInSecondssetDidStartDelay InSeconds: connected Devices setConnected Devices: built InDevicesetBuilt In Device: bundle Tv RemotesetBundle TvRemote: builtInAudio InjectionEnginesetBuiltInAudio InjectionEngine: audio InjectionEnginessetAudioInjectionEngines: Latest PluginStreamIdsetLatest PluginStreamId: activateStartTimesetActivateStartTime: activateEndTimesetActivateEndTime: deactivateStartTimesetDeactivateStartTime: deactivateEnd TimesetDeactivateEndTime: atvRemoteDevice IDsetAtv RemoteDeviceID: _didStartDelay InSeconds_connected Devices_builtInDevice_bundleTvRemote_builtInAudio InjectionEngine_audioInjection Engines_ latestPluginStreamId_activateStartTime_activate End Time_deactivateStartTime_deactivate End Time_atvRemoteDeviceIDT@"NSMutableArray", &,N,V_connected DevicesT@"CSAudioInjectionDevice", &,N,V_builtInDevice T@"CSAudioInjection Device", &,N,V_bundleTvRemoteT@"CSAudioInjectionEngine", &,N,V_builtInAudio InjectionEngineT@"NSMutableDictionary", &,N,V_audioInjectionEngines TQ,N,V_latestPluginStreamIdTQ,N,V_activateStartTime TQ,N,V_activate EndTime TQ,N,V_deactivateStartTimeTQ,N,V_ deactivateEnd Time T@"NSString", &,N,V_atvRemoteDeviceIDTf,N,V_didStart Delay InSecondsbeginAnnounceMessageException: reason: endAnnounce MessageException: reason: _ addAsset ManagerEnabledConditions_shouldCheckNetworkAvailabilityisFirst Unlocked is Available_handleListenerEvent: _handleListenerError:_handleNewRemoteConnection: machXPCConnection: hasEntitlement: CSVoiceTriggerXPCConnectionReceivedClientError:clientError:client:listenlistenersetListener:connectionssetConnections: _listener_ connectionsT@"NSObject<OS_xpc_object>", &,N,V_listener T@"NSMutableArray", &,N,V_connectionssetToken: setIs Voice TriggerEnabled: isVoice TriggerAvailable_ checkVoiceTriggerEnabled_notifyVoice Trigger StateToObserversvoiceTriggerEnabledWithDevice Type: endpointId: tokenis Voice TriggerEnabled_is Voice TriggerEnabled_tokenTi, N ,V_tokenTc,N,V_isVoiceTriggerEnabledclearFalseFirstPass Triggers PerHoursubmitSiriPower Issue Report:_convertToFirstPassSource: increase TriggerCountincrementVTRejectCountincrease False FirstPassTriggersPer Hour clearTriggerCounttriggerCountgetVTRejectCountclearFirstPass TriggerCountfirstPassTriggerCountresetVTEstimationStatisticsgetVoiceTriggerStatisticsgetVoice TriggerDailyMetadata_triggerCount_consecutive PHSRejects_lastPHSReject_consecutive VTRejects_ firstPassTriggerCount_consecutive False FirstPassTriggers Per Hour_hourPowerTimer_vtEstimationStatistics_vtDailyMetadata_vtEstimationStatisticsAreStale_ vtDailyMetadataIsStalegetTestResponse:getCurrentVoice Trigger LocaleWithEndpointId: completion: requestUpdatedSATAudio: setWithArray: setClasses: forSelector: argumentIndex: ofReply: lpcmNarrowBandASBDLpcmASBD_createSampleRate ConverterWithInASBD: outASBD: mutableBytesset Length: downsampler_sampleRateConverter_ outBufferScaleFactor_inASBD_checkSoftwareUpdateCheckingState_didReceiveSoftwareUpdateCheckingStateChanged:_softwareUpdateCheckingState_notifyObserver: withSoftwareUpdateChecking Running: CSSoftwareUpdateCheckingMonitor: didReceiveStateChanged: isSoftware UpdateChecking Running_
didReceiveSoftwareUpdateCheckingStateChangedInQueue:_isSoftware UpdateCheckingRunninginitWithBool: initWith Double: initWithLongLong: initWithUnsigned LongLong: objCType _gibraltarHasBuilt In Micis RemoteDarwinWithDeviceId:_queryIsScreenLocked_notifyObserver:isScreenLocked: screenLockStateChanged_ isScreen LockedfetchVolume FromAVSystemControllerForAudioCategory: startObserving System VolumesmusicVolume alarmVolumesystemVolume DidChange: systemControllerDied:_ supportAVSystem VolumeFetch_musicVolume Level_alarmVolume Level_initsharedUser DefaultsController_didReceiveSRFUserSettingChanged:is LockscreenEnabled_notifyObserver: withSRFUserSetting: CSSRFUserSetting Monitor: didReceive SRFUserSettingChanged: triggerModeStringDescription: setTriggerMode: getTriggerMode_ didReceiveWireless SplitterStateChange_notifyObserver: splitterState: should Disable SpeakerVerificationInSplitterMode: updateSplitterState: should Disable Speaker VerificationInSplitterMode:_should DisableSpeaker Verification InSplitter ModesetInputOriginWithAudioRecordContext: boronScore: processResultCandidate: for RCId: forTask: completion: getLatestUresFeaturesWithCompletion:getMitigation DecisionForRCId: osdNoderegisterOSDNode: nldaClassifierNoderegister NLDAClassifier Node: ssrNoderegister SSRNode:_osdNode_nldaClassifier Node_ssrNode T@"CSAttSiriOSDNode", W, N, SregisterOSDNode:, V_osdNode T@"CSAttSiriNLDAClassifier Node", W, N, Sregister NLDAClassifier Node:, V_nldaClassifier Node T@"CSAttSiriSSRNode", W, N, SregisterSSRNode:, V_ssrNode_ didReceiveVoiceTriggerSettingChanged:_didReceiveVoice Trigger Setting Changed InQueue: initWithSampling Rate: withAsset: support SmartVolumeinitWithSamplingRate: asset: startSmartSiriVolumegetVolumeForTTSType: withOverride MediaVolume: WithRequestTime: setSmartSiriVolume Percentage:setSmartSiriVolumeDirection: setPermanent Volume OffsetWith Direction: didReceiveAlarmChanged: notifyClientsWithBlock: didTTSVolumeChangeFor Reason: didReceiveTimerChanged: didReceiveMusicVolumeChanged: didReceiveAlarmVolume Changed: did DetectKeywordWithResult: CSAlarmMonitor: didReceive AlarmChanged: CSTimer Monitor: didReceive Timer Changed: CSAutomaticVolumeEnabledMonitor: didReceiveEnabled: smartSiriVolume setSmartSiriVolume:_smartSiriVolume T@"<CSSmartSiriVolume Processor>", &,N,V_smartSiriVolumeT@"<CSConnection ServiceDelegate>",W,N,V_delegateinitWithMachServiceName: resumesetExported Interface: xpcConnection: hasEntitlement: setExportedObject: setInterruptionHandler: setInvalidationHandler:_services Listener Should AcceptNewConnection: listener: shouldAcceptNewConnection: gibraltarVoiceTriggerHandler setGibraltarVoice TriggerHandler: servicesListenersetServicesListener:_gibraltarVoiceTriggerHandler_servicesListenerT@"NSXPCListener", &,N,V_servicesListener T@"CSGibraltarVoiceTriggerHandler", &,N,V_gibraltarVoice TriggerHandlers peexConverteropusConverteraddSamples:timestamp: arrivalTimestamp To Audio Recorder: audioConverter DidConvertPackets: packets: duration InSec: timestamp: arrival TimestampToAudioRecorder: encodersetEncoder: _encoderT@"CSAudioConverter", &,N,V_encoderstartDetection TimesetStartDetectionTime: _prefetchedAsset_startDetectionTime TQ,N,V_startDetectionTimeT@"CSAsset", &,N,V_ prefetchedAsset initializeAlarmStatealarmState_alarmFiringStateinitWithAudioURL: withScaleFactor: outASBD: audioURLoutASBD setOutASBD: fFilesetFFile: scaleFactor_scaleFactor_audioURLT@"NSURL",R,N,V_audioURLT{AudioStreamBasic Description=dIIIIIIII},N,V_outASBDT^{Opaque ExtAudioFile=},N,V_fFileTf,R,N,V_scaleFactor_ addDisabledConditions_createXPCClientConnection_notifyActivationEvent: completion: connectsharedNotifiernotifyActivationEventSynchronously: completion: notifyActivationEvent: deviceId: activation Info:completion: initWithProtocolVersion: buildVersion: device ProductVersion: deviceProductType: deviceCategory: deviceProduct Version protocol Version build VersiondeviceCategory_protocolVersion_buildVersion_deviceProductVersion_device ProductType_deviceCategoryTQ,R,N, V_ protocolVersionT@"NSString",R,N,V_buildVersionT@"NSString",R,N,V_deviceProductVersionT@"NSString",R,N,V_deviceProductTypeTQ,R,N,V_deviceCategoryinitWithFormat: encodeObject: forKey: decodeObjectOfClass: forKey:isRemote Device remoteDeviceUI DremoteProductIdentifiersupportsSecureCodingencodeWithCoder: initWithCoder: Tc, Rroute_ isRemoteDevice_route_remoteDeviceUID_remoteDeviceProductIdentifier_remoteDeviceUIDStringT@"NSString",R,C,N,V_remoteDeviceUIDStringT@"NSString",R,C,N,V_routeTc, R, N ,V_isRemoteDeviceT@"NSUUID",R,C,N,V_remoteDeviceUIDT@"NSString",R,C,N,V_remoteDeviceProductIdentifier_isBuilt In DeviceFromDeviceId: isVoiceTrigger InfoAvailable Locally: isDarwin Voice Triggeredtrigger InfoForContext: completion:
isHearstVoice TriggeredisJarvis Voice Triggeredis Remora VoiceTriggeredrtsTrigger InfosetRtsTrigger Info:_accessoryVoice Trigger Events_builtInVoiceTriggerEvent_ rtsTriggerInfo_triggerNotified MachTime T@"NSDictionary",C,N,V_rtsTrigger InfoTQ,N,V_triggerNotified MachTime_ addListeningEnabledConditionsisPresentis SpringboardStartedisBuiltInVoiceTriggeredinitWithRecordContext: deviceId: shouldUseRemoteRecorder: streamHandleId: updateWithLatestRecordContext:updateDeviceId:_shouldUse RemoteRecorder_streamHandleIdT@"CSAudioRecordContext",R,N,V_recordContextTc,R,N,V_shouldUse RemoteRecorder TQ ,R,N, V_streamHandleId_daemon Did Launch_daemonWillShutdown_registerKillSignalsetAsset DownloadingOption: sharedMonitornotifyVoiceTriggerAssetChangedonHangupSignalonTerminationSignalshutdownsharedDaemondid Launch_hangupSignalSource_terminationSignalSource_xpcListener_ activationXPCListener_voice TriggerXPCListener_audio Injection XPCListener_darwinVoice Trigger Handler Pool_corespeechServicesListener_ attSiriConnectionManagerinitWithNSUUID: setEventMetadata:getMHStatisticDistribution InfoFromDictionary: withScaleFactor: setNum: millisecondsToNs: setAvg: setMax:setMin: setP95:setMedian:setStd:setWarmup: setAccessibleEndpointerLevel:getMHClientEventByMhUUID: setEndpointer AccessibleContext: sharedStreamemitMessage: setEndpointerType: setEndpointDetected:getMHStatisticDistribution InfoFromDictionary: reportMHEndpointer AccessibleContextEventWithThreshold Type: MhId: reportServerEndpointWithMhId: arrayWithCapacity: setObject: atIndexedSubscript:distributionDictionary: _emitMHEndpoint Latency Info: withRequestMHUUID: currentContextinitWithInstanceContext: setFirstPacketLatencyInNs:setTrailing PacketLatency: setCoreSpeechTrailingPacketLatency: setEndpointLatency InfoReported: initWithRequestMHUUID: addPkt InfoWithTimestamp :arrivalTimestamp: currentMachTime: reportfirstPkt LatencysetFirstPktLatency: trailingPkt SpeechLatenciesset TrailingPktSpeech Latencies: trailingPktLatenciesset TrailingPktLatencies: numOfAudio PacketssetNumOfAudioPackets: numOfValidTrailing PacketssetNumOfValid Trailing Packets: numOfValidTrailing SpeechPacketssetNumOfValid TrailingSpeech Packets:_firstPkt Latency_trailing PktSpeech Latencies_trailing PktLatencies_numOfAudioPackets_ numOfValidTrailing Packets_numOfValidTrailingSpeech PacketsT@"NSMutableArray", &,N,V_trailingPktSpeechLatencies T@"NSMutableArray", &,N,V_trailing PktLatencies TQ,N,V_ numOf AudioPackets TQ,N,V_numOfValidTrailing Packets TQ,N,V_numOfValidTrailingSpeech PacketsTd,N,V_firstPktLatencyrunMitigation For RCId: withScore: threshold: task: completion: initWithEndpointerNode:ures Node: endpointer NodesetEndpointer Node:uresNodesetUres Node: _lastEndpointHintFeatures_lastEndpoint HintCompletion_endpointerNode _uresNodeT@"CSAttSiriEndpointerNode",W,N,V_endpointer NodeT@"CSAttSiriUresNode",W,N,V_uresNodefileSystem RepresentationmakeRootlessDirectoryAtPath: error: convertToRootlessDirectoryAtPath: error: mapTableWithStrongToStrongObjectssetEnableAlwaysOnVoiceTrigger: speakAudio: withScaleFactor: playbackStarted: completion:_ outASBDWithNumChannels: speakAudio: with Scale Factor: out ASBD: playbackStarted: completion: lpcmInterleaved ASBDWith SampleRate: numberOfChannels: pingpong: completion: createAudioInjection DeviceWithType: deviceName: deviceID:productID: completion: injectAudio: toDeviceWithUUID: withScaleFactor: completion: injectAudio: toDeviceWithUUID: withScaleFactor: with NumChannels: completion: connectDeviceWithUUID: completion: disconnectDeviceWithUUID: completion: primary InputDeviceUUIDWithCompletion:_ deviceMapTabledictionaryWithDictionary: expressionForConstantValue: expressionForFunction: arguments: expression ValueWithObject:context: sortUsingComparator: rootQueueWithFixedPriority: set_sendXPCClientType_disconnect_sendMessageAsync: completion: sendMessageAndReplySync: error: sendMessageAsync: completion: setAudioSession ProvidingDelegate:setAudioAlertProviding Delegate:_decodeError:createPrepare AudioStreamMessageWithRequest: createStartAudioStreamMessageWithOption: createStopAudio StreamMessage is Voice TriggeredisRTSTriggered_handleListenerMessage:_handle Session Providing DelegateMessageBody:_ handleStreamProvidingDelegateMessageBody:_handleAlert ProvidingDelegate MessageBody:_handleSessionInfoProvidingDelegateMessage Body:_handleListenerDisconnectedError: CSXPCClient:did Disconnect:_handleAlert Providing Delegate Did FinishAlertPlayback: audioAlert ProvidingDelegateaudioAlert ProvidingDidFinishAlertPlayback: ofType: error: _ handleSession ProvidingDelegateBeginInterruption: _handleSessionProviding DelegateBeginInterruptionWithContext: _handleSessionProvidingDelegateEndInterruption: _ handleSession Providing Delegate WillSetAudioSession: _handleSessionProviding DelegateDidSetAudioSession: _handleSessionProviding DelegateStreamHandleIdInvalidation: _ handleSession ProvidingDelegate DidChangeContext: audioSession Providing DelegateaudioSession ProviderBegin Interruption: audioSessionProviderBeginInterruption: withContext: audioSessionProviderEndInterruption: audioSessionProvider: willSetAudioSession Active: audioSessionProvider: didSetAudioSessionActive: audioSessionProvider: provider Invalidated: audioSessionProvider: didChangeContext:_handleSessionInfoProviding DelegateInterruption Notification:_ handleSessionInfoProviding Delegate RouteChangeNotification: _handleSessionInfoProviding DelegateMediaServicesWere LostNotification:_ handleSessionInfoProviding DelegateMediaServicesWere Reset Notification: audioSession Info Provider: didReceiveAudioSession Interruption NotificationWithUserInfo: audioSessionInfoProvider: didReceive Audio SessionRouteChangeNotificationWithUserInfo: audio Session InfoProvider: didReceive AudioSessionMediaServicesWere LostNotificationWithUserInfo: audioSessionInfoProvider: didReceive Audio SessionMediaServicesWereResetNotificationWithUserInfo: _handleStreamProviding Delegate DidStop Unexpectly: _handleStreamProviding Delegate ChunkAvailable:_handleStreamProviding Delegate Chunk ForTVAvailable:_ handleStreamProviding Delegate HardwareConfigChange:_handleStream Providing Delegate Two Shot Detected: createAudioStreamMessageWithRequest: prewarmAudioSessionWithError: activate Audio SessionWithReason: dynamicAttribute: bundleID: error: enableSmartRoutingConsideration: duckAudioDevice: duckedLevel: rampDuration: duckDefaultOutputAudioDeviceWithDucked Level: ramp Duration: reportsDynamic ActivityAttribute: bundleId: fallbackDeactivateAudioSession: error: audioStreamWithRequest: streamName:completion: attach TandemStream: to PrimaryStream: completion: prepare Audio StreamSync: request: error: prepareAudioStream: request: completion: startAudioStream: option: completion: stopAudioStream: option: completion: audioChunkFrom: to: audioChunk From: to: channelIdx: audioChunkToEndFrom: audioChunkToEndFrom: channelIdx: saveRecordingBuffer From: to: toURL:saveRecordingBufferToEndFrom: toURL: playAlertSoundForType: configureAlertBehavior: audioSessionIdForDeviceId:sampleCount FromHostTime: disconnectprepare Audio ProviderWithContext: clientType: error: pingpong: acousticSLResultForContext: completion:
audioStreamProviding Delegate setAudioStreamProviding Delegate: xpc ReplyQueue setXpcReplyQueue: xpcClientQueues etXpcClientQueue:
activationAssertionssetActivationAssertions: audioSessionInfoObserverssetAudioSessionInfoObservers: xpcClientTypesetXpcClient Type:_audioSessionProviding Delegate_ audioStreamProviding Delegate_audioAlertProviding Delegate_xpc Reply Queue_xpcClientQueue_activationAssertions_audioSessionInfoObservers_xpcClientTypeT@"NSObject<OS_ xpc_object>", &,N,V_xpcConnectionT@"NSObject<OS_dispatch_queue>", &,N,V_targetQueueT@"NSObject<OS_dispatch_queue>", &,N,V_xpcReplyQueueT@"NSObject<OS_dispatch_queue>", &,N, V_xpcClientQueueT@"NSMutableSet", &,N,V_activationAssertions T@"NSHashTable", &,N,V_audioSessionInfoObservers TQ,N,V_xpcClientTypeT@"<CSAudioSessionProvidingDelegate>",W,N,V_audioSession ProvidingDelegate T@"<CSAudioStreamProviding Delegate>",W,N,V_audioStreamProviding DelegateT@"<CSAudioAlert ProvidingDelegate>",W,N,V_audioAlertProviding DelegateT@"<CSXPCClientDelegate>",W,N,V_delegate opportune SpeakBehavior Monitor: willStartStreamWithContext : audioProvider UUID: option: opportune SpeakBehavior Monitor: didStartStreamWithContext: audioProvider UUID: successfully: option: opportuneSpeakBehaviorMonitor: willStopStream: opportuneSpeakBehavior Monitor: didStopStream: opportune SpeakingFileLoggingIsEnabledlpcmNonInterleavedWithRemoteVADASBDlpcm InterleavedWithRemoteVADASB DcreateAudioFileWriter For OpportuneSpeakListenerWithInputFormat: outputFormat: contextForOpportune SpeakerListenercontextForOpportuneSpeakerListenerWithCall_ resetAlignBuffer_startRequestWithCompletion: remote VADDurationsupports UnderstandingOnDeviceinitWithDelegate: stopListenWithStateReset: completion: opportuneSpeakListener: didStop Unexpectly: host TimeprocessSampleCount:hostTime: remote VADopportuneSpeakListener BypassEnabled_addRemoteVADSignal: dataWithRemoteVADWithScaleFactor: numAudioSamplesPerRemoteVAD: removeObjectAtIndex: _shouldReportBoron_popRemoteVADSignalopportuneSpeakListener: hasRemote VADAvailable : opportuneSpeakListener: hasVADAvailable: withHostTime: opportuneSpeakListener: hasVADAvailable: startListenWithOption: completion: stopListenWithCompletion: spgEndpointAnalyzer: hasSilenceScore Estimate: clientProcessedAudio TimeMS: spgEndpointAnalyzerset SpgEndpointAnalyzer: remoteVADSPGRatioset RemoteVADSPGRatio: audioStreamProvidersetAudioStreamProvider:latestContextsetLatestContext:isMediaPlayingNowsetIsMediaPlaying Now: remoteVADAlignBufferset RemoteVADAlignBuffer: remoteVADAlignCountsetRemote VADAlignCount:alignBufferQueuesetAlignBufferQueue: running SampleCountsetRunningSampleCount:_isMediaPlaying Now_remote VADSPGRatio_ spgEndpointAnalyzer_audioStreamProvider_audio Session Provider_latestContext_remoteVADAlignBuffer_remoteVADAlignCount_alignBufferQueue_running SampleCountT@"CSSPGEndpoint Analyzer", &,N,V_spgEndpointAnalyzer Ti,N,V_remoteVADSPGRatio T@"<CSAudio StreamProviding>", &,N,V_audioStream Provider T@"<CSAudioSessionProviding>", &,N,V_ audioSessionProvider T@"CSAudio RecordContext", &,N,V_latestContextTc, V_isMediaPlaying NowT@"NSMutableArray", &,N,V_remoteVADAlignBufferTQ,N,V_remoteVADAlignCountT@"NSObject<OS_dispatch_queue>", &,N,V_alignBufferQueueTQ,N,V_running SampleCountT@"<CSOpportuneSpeakListenerDelegate>",W,N,V_delegate_ handleMeterProvidingRequestTypeSetMeteringEnabledMessage:message Body: client: _handleMeter ProvidingRequestTypeUpdateMeters Message: messageBody: client:_ handleMeterProviding RequestTypePowerMessage: messageBody: client: powerType:_sendReplyMessageWithResult: event:client: audioMeterProvider_audio MeterProviderT@"<CSAudioMeter Providing>",W,N,V_audioMeterProviderinitWithDownloadOption: defaultControlleraddObserver: forAssetType:_ createPeriodicalDownload TimerassetManagerEnabled Policy_startPeriodicalDownload_stopPeriodicalDownload_fetchRemoteMetaData_canFetchRemoteAsset: assetOfType: Language :allInstalledAssetsOfType: Language: assetOfType: Language: completion: installedAssetOfType: Language: completion: fetchRemoteMetaOfType: supportHybrid EndpointersupportLanguage DetectorsupportAdBlockersupports SpeakerRecognitionAssetsassetForCurrentLanguageOfType: completion: CSAsset Manager Did Download NewAsset: CSVoiceTriggerAsset MetaUpdate Monitor: didReceive NewVoiceTriggerAssetMetaData: CSSpeechEndpointAssetMetaUpdateMonitor: didReceiveNewSpeechEndpointAssetMetaData: CSAdBlockerMetaUpdateMonitor: didReceive NewAdBlockerAssetMetaData: CSAssetController: didDownload NewAsset ForType: CSSpeakerRecognitionAssetMetaUpdateMonitor: didReceive NewSpeaker RecognitionAssetMetaData:installedAssetForCurrentLanguageOfType: installedAssetForCurrentLanguageOfType: completion: assetOfType: provider Type: Language: completion: currentLanguageCoderemoveObserver: forAssetType:_enablePolicy_ currentLanguage Code_downloadingOption_download Timer_download Timer Count fetchVoice Trigger HeartBeatMetrics initWithTimeOut:_
acquirePreventSystemSleepAssertionWithTimeout: setIdleUserPreventSleepAssertionAcquitionDate:
getIdleUserPreventSleepAssertionAcquitionDatetimeIntervalSinceReferenceDateassertionTimeout IntervalpreventSystemSleepPowerAssertionsetPreventSystemSleepPowerAsser
tion: setCurrentState: _assertionTimeout Interval_preventSystemSleep Power AssertionT@"CSPreventSystemSleepPowerAssertion", &,N,V_preventSystemSleepPower AssertionTq, N, V _currentStateTd,R,N,V_assertionTimeout IntervalpreheatendpointStylesetEndpointStyle: delaysetDelay: startWaitTimeautomatic Endpointing Suspension EndTimeminimumDuration ForEndpointersetMinimumDurationForEndpointer:
lastEndOfVoiceActivityTimelastStartOfVoiceActivityTimebypass Samplesset Bypass Samples: endpointModesetEndpointMode:interspeech Wait TimesetInterspeechWaitTime: endWaitTimesave SamplesSeen In ResetsetSaveSamplesSeen In Reset: Tq, NTd, NTd, R, Nreset For NewRequestWithSampleRate: recordContext: processAudioSamplesAsynchronously: stopEndpointer recordingStopped For Reason: implDelegatesetImplDelegate: canProcessCurrentRequestprocessServerEndpoint Features: logFeaturesWithEvent: Locale: handleVoiceTriggerWithActivationInfo: processOSDFeatures: with Frame DurationMs: processFirstAudioPacketTimestamp: firstAudioSample Sensor Timestamp: fetchCurrentEndpointerOperation ModelogAnchor MachAbsTime: numSamplesProcessed Before Anchor Time: isAnchor TimeBuffered: processASRFeatures: fromServer: processTaskString: endpointerModelVersione lapsedTimeWithNoSpeech T@"<CSEndpointAnalyzerDelegate>", W, NT@"<CSEndpointAnalyzer ImplDelegate>", W, NTC, R, NTQ, NsetEndpointerModelVersion:_ canProcessCurrentRequest_endpointerModelVersionT@"NSString", &,N,V_endpointerModelVersionTc,R,N,V_canProcessCurrentRequestT@"<CSEndpointAnalyzer Delegate>", W, N, VdelegateT@"<CSEndpointAnalyzer ImplDelegate>", W, N, VimplDelegate TQ, N, VactiveChannelTq, N, VendpointStyleTd, N, VdelayTd, N, VstartWaitTimeTd, N, VautomaticEndpointingSuspensionEndTimeTd, N, VminimumDurationForEndpointerTd, R, N, VlastEndOfVoice Activity TimeTd, R, N, VlastStartOfVoice Activity Time T@"NSString", &, N, Vmh IdhandleConsoleEnabled: startManager_createClear LoggingFileTimersharedServiceregisterPostBuildInstallService_startAllClients_setupVoiceTriggerWithCompletion:_ setupSpeakerRecognitionWithVTAsset:_startClearLogging Files Timerset Delegate: forType: supportBluetoothDevice Voice Trigger_voice TriggerEvent NotifierCreateIfNeeded: triggerVoiceProfile RetrainingWithAsset: initWithTargetQueue: with SpeechManager:_preMyriad CoordinatorCreateIfNeeded: setBuiltInSeconPassProgress Provider:_ startVoice Triggersupports Voice TriggerFides_voice TriggerFileLoggerCreateIfNeeded: channelForOutputReferencesupportSelfTrigger Suppression: ref ChannelIdx:_ myriadSelfTriggerCoordinator IfNeeded: _getVoiceTriggerAssetIfNeeded: enumerateKeys And Objects Using Block:_getAudio RecorderWithError: audioProviderssetLatest RecordContext:streamType: initWithAudioStreamHandleId: audioStreamType: audioRecordContext: audioRecorder: setAudio ProviderDelegate: initWithAudio Recorder: setAudio Recorder: _reinitialize VoiceTrigger IfNeeded_reinitialize Voice TriggerWithAsset: _reinitialize SmartSiriVolumeWithAsset:daysBeforeRemoving LogFiles removeLogFilesOlder ThanNDays: removeOpportunistic AudioLoggingOlderThan NDays: removeRemote P2PLogFilesOlderThanNDays:_ handleClearLogging FileTimer_setupForJarvis IfNeededWithPrepareCompletion: completion: _setupForRemoraIfNeededWithCompletion:_ setupForHearstIfNeededWithPrepareCompletion: completion: _setupForBluetooth DeviceIfNeededWithDeviceType: prepareCompletion: completion:_ prepareForBluetoothDeviceWithDevice Type:_startForBluetooth DeviceWithDevice Type: asset: setRemoraSecondPassProgress Provider: opportune SpeakEvent Monitor: didStreamStateChanged: audioRecorder BeginRecordInterruption: audioRecorderBeginRecordInterruption: with Context: audio RecorderEndRecordInterruption: audio Recorder: willSetAudioSessionActive: audioRecorder: didSetAudioSession Active: voiceTriggerDetectedOnAOP: audioProviderInvalidated: streamHandleId: audioFingerprintProviderregisterSpeech Controller: registerSiriClientProxy: audio ProviderWithStreamID: fetchFallbackAudioSession ReleaseProvider_ updateBuiltInTriggerForPreMyriad IfNeeded: _prepareRemora DeviceWithConnectedDeviceIds: _teardown ForBluetooth DeviceassetQueryQueuesetAssetQueryQueue: audioRecordersetAudioProviders: fallbackAudioSessionReleaseProvidersetFallbackAudioSessionReleaseProvider: clientControllersetClientController: voiceTriggerQueuesetVoice TriggerQueue: remoraTargetQueueset RemoraTargetQueue: voiceTriggersetVoiceTrigger: preMyriad CoordinatorsetPreMyriad Coordinator: voice TriggerFileLoggerset Voice TriggerFileLogger: selfTriggerDetectorset SelfTrigger Detector: keywordDetectorset KeywordDetector: myriadset Myriad: myriadSelfTriggerCoordinatorset MyriadSelfTriggerCoordinator: voice TriggerFidesClientsetVoiceTriggerFidesClient: voice TriggerFirstPassJarvissetVoice TriggerFirstPassJarvis: voice TriggerFirstPassHearst setVoice TriggerFirstPassHearst: voice TriggerFirstPassHearstAPsetVoiceTriggerFirstPassHearstAP:voiceTriggerFirstPass RemorasetVoiceTriggerFirstPass Remora:
voice Trigger RetrainersetVoiceTriggerRetrainer: clearLoggingFileTimerset Clear LoggingFileTimer: clearLoggingFileTimerCount setClearLogging FileTimerCount: opportuneSpeakListnerTest ServicesetOpportuneSpeakListnerTestService: postBuildInstallServicesetPostBuildInstallService:ssvManager setSsvManager:_assetQueryQueue_ audioRecorder_audio Providers_fallbackAudioSession ReleaseProvider_clientController_voice TriggerQueue_remoraTargetQueue_voice Trigger_preMyriad Coordinator_ voiceTriggerFileLogger_selfTriggerDetector_keywordDetector_myriad_myriad Self Trigger Coordinator_voice TriggerFidesClient_voiceTriggerFirstPass Jarvis_ voiceTriggerFirstPassHearst_voice TriggerFirstPass Hearst AP_voice TriggerFirstPass Remora_voiceTrigger Retrainer_clearLogging FileTimer_clearLoggingFileTimerCount_ opportuneSpeakListnerTestService_postBuildInstallService_ssvManagerT@"NSObject<OS_dispatch_queue>", &,N,V_assetQueryQueue T@"CSAudioRecorder", &,N,V_audioRecorderT@"NSMutableDictionary", &,N,V_audioProviders T@"CSFallbackAudioSession Release Provider", &,N,V_fallbackAudioSessionReleaseProvider T@"<CSSpeechManagerDelegate>",W,N,V_ clientControllerT@"NSObject<OS_dispatch_queue>", &,N,V_voiceTriggerQueueT@"NSObject<OS_dispatch_queue>", &,N,V_remora TargetQueueT@"CSBuiltInVoiceTrigger", &,N, V_ voiceTriggerT@"CSVoiceTriggerEvents Coordinator", &,N,V_voiceTriggerEventsCoordinator T@"CS PreMyriadCoordinator", &,N,V_preMyriad CoordinatorT@"CSVoiceTriggerFileLogger", &,N,V_voiceTriggerFileLoggerT@"CSSelf Trigger Detector", &,N,V_selfTriggerDetectorT@"CSKeywordDetector", &,N,V_keywordDetectorT@"CSMyriadPHash", &,N,V_myriad T@"CSMyriad SelfTriggerCoordinator", &,N,V_myriadSelfTriggerCoordinatorT@"CSVoiceTriggerFidesClient", &,N,V_voiceTriggerFidesClientT@"CSVoiceTriggerFirstPass Jarvis", &,N,V_voiceTriggerFirstPass Jarvis T@"CSVoiceTriggerFirstPass Hearst", &,N,V_voiceTriggerFirstPass HearstT@"CSVoiceTriggerFirstPass HearstAP", &,N,V_voiceTriggerFirstPass HearstAPT@"CSVoiceTriggerFirstPass Remora", &,N, V_voice TriggerFirstPassRemoraT@"CSVoiceProfileRetrainManager", &,N,V_voice Trigger RetrainerT@"NSObject<OS_dispatch_source>", &,N,V_clearLoggingFileTimerTq,N,V_clearLoggingFileTimer CountT@"CSOpportuneSpeakListner TestService", &,N,V_opportune SpeakListner TestService T@"CSPostBuildInstallService", &,N,V_postBuildInstallService T@"CSSmartSiriVolumeManager", &,N,V_ssvManager firstPartyCall_acquire AssertionForType: withTimeout: assertionId: details:_releaseAssertionForAssertionId : details:_timeout Interval_ preventUserIdleSystemSleepAssertionId_preventSystemSleepAssertionIdflexKwdConfigFile flexKwdThreshold FileinitWithDictionary: zeroFilterWindowSizeInMsgetHostClockFrequencyzeroFilterApproxAbsSpeech ThresholdinitWithZeroWindowSize: approxAbsSpeechThreshold: num HostTicksPerAudioSample: filterZerosInAudio Packet: atBufferHostTime: filteredPacket: endAudio And FetchAnyTrailingZerosPacket:vtEndInSampleCountsetVtEndInSampleCount: numSamplesProcessedsetNumSamples Processed:_vtEndInSampleCount_numSamplesProcessedTQ,N,V_vtEndInSampleCountTQ,N,V_numSamples ProcessedT@"CSAudioZeroFilter", &,N,V_ zeroFilterT@"<CSVoiceTrigger AwareZeroFilterDelegate>",W,N,V_delegatecopySamplesFrom: to: initWithRecording Duration: audio SamplesPer Remote VAD: audio SampleRate: remoteVADSample Countcopy Samples From Audio SampleCount:toAudioSampleCount: capacitysize beginSampleCount.cxx_construct_remote VADCircular BufferImpl_ audioSamplesPer Remote VAD_capacity_size_beginSampleCount TQ,R,N,V_capacityTQ,R,N,V_size TQ,R,N,V_beginSample Count_getAuditToken: attributionWithAuditToken: setWithObject:setAudioRecording Attributions: updateVolatile DataWithBlock: completion: _reportsDynamic ActivityAttribute: bundleId: setCurrentAttributionKey: andApp: reportMicUsage: reportsDynamic ActivityAttributeAsync: bundleId: reports Dynamic ActivityAttributeSync: bundleId:micUsage Publisher setMicUsagePublisher: micUsageAttributesetMicUsage Attribute: _micUsage Publisher_micUsage AttributeT@"STMediaStatus DomainPublisher", &,N,V_micUsagePublisher T@"NSSet", &,N,V_ micUsageAttribute_availabilityChanged_didReceived NetworkAvailability Changed Notification:_notifyObserver: with NetworkAvailability: CSNetworkAvailabilityMonitor: didReceiveNetworkAvailabilityChanged:_performPostBuildInstallWith Completion: numberWithLong: trigger Voice Profile CleanupWithCompletion: initWithSpeechManager: other AppRecording State Monitor: jarvisAudioLoggingEnabledjarvisAudioLogging FilePath_notifyJarvis Voice TriggerRejectprocessAudioChunk: _reportJarvis Voice TriggerFire_ didDetectKeywordFromDeviceId: activationInfo: triggerHostTime: completion: _holdAudioStreamWithTimeout:_requestStartAudioStreamWitContext: startStreamOption: completion :_didStartAudioStreamnotifyCarPlayVoiceTrigger Prewarm: deviceId: completion: _handleJarvis VoiceTriggerFromDeviceId: activationInfo: triggerHostTime: completion: _ cancelAudioStreamHold_createSecondPass IfNeeded_handleSecondPass Result: deviceId: error:_teardownSecondPassjarvis AudioLogDirectorykeywordAnalyzerNDEAPI: hasResultAvailable: forChannel: spgEndpointAnalyzerDidDetectEndpoint: keywordAnalyzerNDEAPIsetKeyword AnalyzerNDEAPI: hasReceivedNDEAPIResultsetHasReceived NDEAPIResult :jarvisVoiceTriggerTimeoutsetJarvis Voice TriggerTimeout: jarvis Trigger ResultsetJarvis Trigger Result:latest Trigger ModesetLatest TriggerMode: endpointAnalyzersetEndpointAnalyzer:rtModelsetRtModel:isSiriClientListeningsetIsSiriClientListening: _hasReceivedNDEAPIResult_isSiriClientListening_ keywordAnalyzer NDEAPI_jarvis Voice TriggerTimeout_jarvis TriggerResult_latestTriggerMode_endpointAnalyzer_rt ModelT@"CSKeywordAnalyzer NDEAPI", &,N,V_ keywordAnalyzer NDEAPITC,N,V_hasReceivedNDEAPIResultTQ,N,V_jarvis Voice TriggerTimeout T@"CSKeyword Analyzer NDEAPIResult", &,N,V_jarvis TriggerResultTq,N,V_ latestTrigger ModeT@"CSSPGEndpoint Analyzer", &,N,V_endpointAnalyzer T@"CSVoiceTrigger RTModel", &,N,V_rtModelTc,N,V_isSiriClientListening_ setDefaultParametersgetSSVDeviceType_convertDB2Mag: fetchInitSystemVolumes_resume SSVProcessing_pauseSSVProcessingsmartSiriVolume Run PolicysetEnablePolicy: enablePolicy_startListenPolling_stopListening_startListen PollingWithInterval:completion: _startListenWithCompletion: _getDevice dBFSForInputLinear Volume:
SSVNoise LevelChannelBitsetSSVLKFSChannelBitsetSSVEnergyBufferSize SSV Noise Lower Percentile SSVNoiseUpperPercentileSSVLKFSLower Percentile SSVLKFSUpper Percentile SSVNois eTimeConstant SSVNoiseMicSensitivityOffsetSSVNoiseMicSensitivityOffsetDeviceSimpleSSVLKFSTimeConstant SSVLKFSMicSensitivityOffsetSSVNoise TTSMapping InputRangeLowSSVN oiseTTSMappingInputRange High SSVNoiseTTSMappingOutputRangeLowSSV Noise TTSMappingOutputRangeHighSSVLKFSTTSMapping InputRange LowSSVLKFSTTS Mapping InputRange HighSSVLKFST TSMappingOutputRange LowSSVLKFSTTSMappingOutputRange High SSVUserOffsetInputRange LowSSVUserOffsetInputRangeHighSSVUserOffsetOutputRange LowSSVUserOffsetOutputRangeHig hSSVTTSVolume Lower Limit DBSSVTT SVolume Upper LimitDBSSVNoiseWeight SSVParameter Directionary_getFloatBufferData:_processAudio Chunk: soundType:_estimatedTTSVolume: Lower Limit:upper Limit: TTSmappingInputRange Low: TTSmappingInputRange High: TTSmappingOutputRangeLow: TTSmappingOutputRangeHigh:_getUserOffsetFromMusicVolumeDB:_ combineResultsWithOptimalFromNoise: and OptimalFromLkfs: withUserOffset: _getDeviceSimpleOutputLinearVolume FordBFSValue:_scaleInputWithInRangeOutRange: minIn:maxIn: minOut:maxOut: smartSiriVolumeSoftVolumeEnabled_getMusicVolume DBCSSSV DeviceSimple: _getMusicVolume DBCSSSV DeviceDefault:_ deviceSpecific Linear VolumeToDB MappingCSSSVDevice Simple: _deviceSpecific DBToLinear VolumeMapping CSSSVDeviceSimple:_getDeviceSimpled BFSForOutputLinearVolume: estimate Sound Levelby SoundType: estimatedTTSVolume For Noise LevelAndLKFS: LKFS: initWith Volume Estimate: debugLog File:_prepare Sound LevelBuffer From Samples: soundType: prepareSound LevelBuffer From Samples: sound Type: fired Voice TriggerEvent: triggerStartTimeSampleOffset: triggerEndTimeSampleOffset: listenPolling Timerset Listen PollingTimer: listenPolling Timer CountsetListen Polling TimerCount:_smartSiriVolume Noise Level_smartSiriVolume LKFS_floatBuffer_defaults_ ssvEnablePolicy_startAnalyze SampleCount_samples Fed_processed SampleCount_isListen PollingStarting_shouldPauseSSVProcess_shouldPauseLKFSProcess_alarmSoundIsFiring_ timerSoundIsFiring_musicVolume DB_alarm Volume_noise LevelChannelBitset_LKFSChannelBitset_energyBufferSize_noise Lower Percentile_noise Upper Percentile_ LKFSLower Percentile_LKFSUpper Percentile_noise Time Constant_noise MicSensitivityOffset_noise MicSensitivityOffsetDeviceSimple_LKFSTimeConstant_ LKFSMicSensitivityOffset_noise TTSMapping InputRange Low_noiseTTSMappingInputRangeHigh_noise TTSMappingOutputRange Low_noise TTSMappingOutputRangeHigh_ LKFSTTSMappingInputRangeLow_LKFSTTSMappingInputRange High LKFSTTSMappingOutputRangeLow_LKFSTTSMappingOutputRangeHigh_userOffsetInputRangeLow_ userOffsetInputRange High_userOffsetOutputRange Low_userOffsetOutputRangeHigh_TTSVolume Lower LimitDB_TTSVolume Upper LimitDB_noiseWeight_listen Polling Timer_ listenPolling Timer CountT@"NSObject<OS_dispatch_source>", &,N,V_listen Polling TimerTq,N,V_listen Polling Timer CountT@"CSPolicy", &,N,V_enablePolicyis HFPWith RecordRoute: isBluetoothAudioDeviceConnectedis BluetoothVehicleOutputaudioPortSubtypeAsString: volume EstimatedebugLogPath_volume Estimate_debugLogPathT@"NSString",R,N, V_ debugLogPathTf,R,N,V_volume Estimate isSudden TerminationEnabledsetIsSudden TerminationEnabled: process Infoenable Sudden Termination disable Sudden Termination_ isSudden TerminationEnabledTc, V_isSuddenTerminationEnabledsupportCSTwoShot DecisioninitWithCommon Format: sample Rate: channels: interleaved: initWithRequestType: addRequest:withObserver: error: initWithPCMFormat: frame Capacity:setFrameLength: mutableAudioBufferListsampleByteDepthwasBuffered_pcmBufferForAudioChunk: analyzeAudioBuffer: atAudio Frame Position: frame Lengthskip SamplesAtStartSuch ThatNumSamplesReceived SoFar: reaches ACountOf: completionHandler:timeRange_ effectiveAudioTime InSecsForSNObservation: detected_reportStartpointAtTsInSecs:_shouldEnterTwoShotAtAudio TimeInSecs:_reportTwoShotAtTsInSecs:_ reportEndpointAtTsInSecs:_checkSNObservationForStartpoint: _checkSNObservationForEndpoint:hostTimeFromSampleCount: anchorHostTime: anchor SampleCount: sampleRate: _ trailingSilence DurationAtEndpoint initWithTotalAudioRecorded: endpointBufferHostTime: featuresAtEndpoint: endpointerType: server FeatureLatencyDistribution: additionalMetrics: trailingSilence DurationAtEndpoint: endpointer: didDetectHardEndpointAtTime: with Metrics: endpointer: reportEndpointBufferHostTime: firstBufferHostTime :_emitEndpoint DetectedEventWithEndpoint Time: endpointBuffer HostTime: secondsToNs: setEndpointAudio DurationInNs: setFirstBufferTime InNs: setEndpointedBufferTimeInNs: setDerivedBufferTimeFromHistoricalAudio: setIsTimeout: setTimeoutMetadata: endpointer: didDetectStartpointAtTime: endpointer: detected TwoShot AtTime: decision Delay request :didProduceResult: request:didFailWithError: requestDidComplete:snAudioStreamAnalyzersetSnAudioStreamAnalyzer: frame PositionsetFrame Position: nnvadStatesetNnvadState: numSamplesReceived setNumSamplesReceived: numSamples ProcessedBefore AnchorTimesetNumSamples ProcessedBefore Anchor Time: anchor MachAbs TimesetAnchor MachAbsTime: isAnchor TimeBuffered setIsAnchor TimeBuffered: isRequestTimeoutset IsRequestTimeout: currentRequestSampleRatesetCurrentRequestSampleRate: currentRequestAudioFormatsetCurrentRequestAudioFormat: vtEndInSecssetVtEndInSecs:vtExtraAudioAtStartInMssetVtExtraAudioAtStartInMs: nnvadAudioOriginInMssetNnvad Audio OriginInMs: should Detect TwoShotsetShould Detect TwoShot: didEnterTwoshotsetDidEnterTwoshot: firstAudioSampleSensor TimestampsetFirstAudioSample SensorTimestamp: first Sample IdsetFirstSample Id: numSamplesSkipped ForVTsetNumSamplesSkipped ForVT: finished SkippingSamples For VTsetFinished SkippingSamples ForVT:_saveSamplesSeen In Reset_isAnchor TimeBuffered_isRequestTimeout_should DetectTwoShot_didEnterTwoshot_ finishedSkippingSamples ForVT_implDelegate_startWaitTime_endWait Time_automatic Endpointing Suspension EndTime_endpointStyle_endpointMode_inter speechWait Time_delay_ minimumDurationForEndpointer_lastEndOfVoice ActivityTime_lastStartOfVoice Activity Time_snAudioStreamAnalyzer_frame Position_nnvadState_numSamplesReceived_ numSamplesProcessedBefore Anchor Time_anchor MachAbsTime_currentRequest Sample Rate_currentRequestAudio Format_vtEndInSecs_vtExtraAudioAtStartInMs_nnvadAudioOriginInMs_ firstAudioSampleSensor Timestamp_firstSample Id_numSamplesSkipped ForVTT@"SNAudioStreamAnalyzer", &,N,V_snAudioStreamAnalyzer TQ,N,V_frame PositionTQ,N,V_nnvadStateTQ, N ,V_numSamples ReceivedTQ,N,V_numSamples ProcessedBefore AnchorTime TQ,N,V_anchor MachAbs TimeTc,N,V_isAnchorTimeBufferedTc,N,V_isRequestTimeoutTQ,N,V_ currentRequestSample Rate T@"AVAudioFormat", &,N,V_currentRequestAudioFormat Td,N,V_vtEnd InSecsTd,N,V_vtExtra AudioAtStartInMsTd,N,V_nnvadAudio OriginInMs Tc,N,V_ shouldDetect Two ShotTc,N,V_didEnterTwoshotT@"<CSAudioFileWriter>", &,N,V_audioFileWriterTd,N,V_firstAudio SampleSensor TimestampTq,N,V_firstSample IdTQ,N,V_ numSamplesSkipped For VTTC,N,V_finishedSkipping Samples For VTT@"<CSEndpointAnalyzerDelegate>",W,N,V_delegateT@"<CSEndpointAnalyzer ImplDelegate>",W,N,V_implDelegateTq,N,V_endpointStyleTd,N,V_delayTd,N,V_startWait TimeTd,N,V_automatic EndpointingSuspensionEndTimeTd,N,V_minimumDurationForEndpointerTd,R,N,V_ lastEndOfVoiceActivityTimeTd,R,N,V_lastStartOfVoiceActivityTimeTq,N,V_endpointModeTd,N,V_interspeechWait TimeTd,N,V_endWait TimeTc,N,V_ saveSamplesSeen InResetstartKeywordSpottingWithCompletion: setCtx: bestTokensetDetectedToken: endSampleIdsetTriggerAbsStartSampleId: setTrigger MachTime: dictionaryRepresentationattSiriNode: trigger ReportedFromFlxKwdSpotter: trigger ReportedFromFlxKwdSpotter: startWithContext: audioStreamId: kwdSpottersetKwdSpotter: contextsetContext: didTriggersetDidTrigger: setAudioStreamId:_did Trigger_kwdSpotter_context_audioStreamIdT@"CSFLexKeywordSpotter", &,N,V_kwdSpotter T@"CSAttSiriRequestContext", &,N,V_contextTc,N,V_did Trigger TQ,N,V_audioStreamIdwakeGesture Timestamp setWakeGestureTimestamp: dismissal Timestamps et DismissalTimestamp: _ wakeGestureTimestamp_dismissalTimestampTQ,N,V_wakeGestureTimestampTQ,N,V_dismissalTimestampaudioFeedTimerset AudioFeedTimer: fpsetFp:_fpT@"NSObject<OS_dispatch_ source>",&,N,V_audioFeedTimerT^{__SFILE=xiiss{__sbuf=xi}i^v^!^?^^?{__sbuf=xi}^{__sFILEX}i[3C][1c]{__sbuf=xi}
iq},N,V_fpgetVoice TriggerAssetTypeString getEndpointAssetTypeStringgetLanguageDetector AssetTypeString getAdBlocker AssetTypeStringget Speaker Recognition AssetTypeStringcompletion:_assetQueryForAssetType: returnTypes:
g_cleanUpMobileAssetV1Directory_isReadyToUseinstalledAssetOfType:withLanguage:_fetchRemoteAssetOfType:withLanguage: queryMetaDataSyncresultsfilteredAssets For Assets: assetType: Language:queryParamsis LatestCompare To: sortedArrayUsingComparator: stategetCSAssetOfType: enumerateObjectsUsing Block: installedAssetOfType: with Language: completion: addKeyValuePair: with: addKeyValuePair ForQuery: assetType:_installedAssetOfType:query: withLanguage: completion: _fetchRemoteAssetOfType: with Language: query: completion: _installedAssetOfType: withLanguage:_installedAssetOfType: with Language: completion:_ findLatest InstalledAsset: query MetaData:attributesfetchRemoteMetaOfType: allowRetry: _runAssetQuery: completion: _downloadAssetCatalogForAssetType:complete:_ updateFromRemoteToLocalAssets: for AssetType: completion: _defaultDownload Options_isRetry RecommendedWithResult:startCatalogDownload: options: then: isCSAssetInstalledis DownloadingcancelDownloadSynccanBePurgedpurgeSync_downloadAsset: with Complete:setAllows CellularAccess:setCanUseLocalCache Server: setDiscretionary: assetServerUrl_startDownloadingAsset: progress: completion: expectedTime RemainingtotalWrittentotalExpectedattachProgressCallBack: spaceCheck: startDownload: then: sharedControllergetAssetTypeStringForType: CSEventMonitorDid ReceiveEvent: assetsMigrationQueuesetAssetsMigrationQueue: csAssetsDictionarysetCsAssets Dictionary:_assetsMigrationQueue_csAssets Dictionary T@"NSObject<OS_dispatch_queue>", &,N,V_assetsMigrationQueue T@"NSDictionary", &,N,V_ csAssetsDictionaryT@"NSMutableDictionary", &,N,V_observersvalueForKey: supportPremiumAssetsgetVoiceTriggerAssetCurrentCompatibilityVersiongetEndpointAssetCurrentCompatibilityVersiongetLanguageDetectorCurrentCompatibilityVersiongetAdB LockerCurrentCompatibilityVersion getSpeaker RecognitionCurrentCompatibilityVersiongetVoice TriggerCurrentCompatibilityVersion filteredAssetsForFetchRemoteMetaDataFor Assets:assetType: getBlobWithConfigFilename: rootDirectory: assetHashInResourcePath: getDefaultBlobinitWithData: hash: Locale: createRTModelWithLocale: hearstRTModelWithMajorVersion: minorVersion: Locale: dataWithContentsOfFile:_sha1: substringWithRange:_sha256: initWithData: hash:locale: digest: signature: certificate: rtModelWithAccessory RTModelType: majorVersion: minorVersion: Locale:localeMapWith Name: remoraRTModelLocaleMaphearstRTModelLocaleMapstringWithCapacity: latestHearstRTModelForLocale: remora RTModelWithMajorVersion: minorVersion:locale: jarvis RTModelLocaleMaprtModel LocaleMapWith ModelType: resetDucking_ handleSession ProvidingRequestTypePrewarm Message: client: _handleSessionProvidingRequestTypeActivateMessage: messageBody: client:_ handleSessionProvidingRequestTypeDeactivateMessage:message Body: client: _handleSessionProvidingRequestTypeSetDuckOthersOption: messageBody: client:_ handleSessionProvidingRequestTypeEnable MiniDucking: message Body: client:_handleSessionProvidingRequestTypeDuckAudio Device:messageBody:client:_ handleSessionProvidingRequestTypeDuckDefaultOutput Audio Device: message Body: client:_handle Session ProvidingRequestTypeEnableSmartRoutingConsideration: messageBody: client:_handleSession ProvidingRequestTypeReportDynamic ActivityAttribute:messageBody: client:_sendReplyMessageWithResult: error: event:client: notifyRelease Audio SessionduckAudioDeviceWithDeviceID: duckedLevel: rampDuration: audioSessionProvider: didReceiveAudioSessionInterruption NotificationWithUserInfo: audioSessionProvider: didReceiveAudioSession RouteChangeNotificationWithUserInfo: audioSessionProvider: didReceive AudioSessionMediaServicesWere LostNotificationWithUserInfo: audioSessionProvider: didReceiveAudioSessionMediaServicesWere Reset NotificationWithUserInfo: manualDuckingHandler setManualDuckingHandler:_manualDuckingHandlerT@"CSManualDuckingHandler", &,N,V_manualDuckingHandleraudio ConverterBitratesetEncoderBitRate: setNumberOfChannels: inputRecordingSampleBitDepthsetLpcmBitDepth: setLpcmIsFloat:setUseCustomized RecordSettings: requires HistoricalBuffersetIsSiri: requestForOpus RecordSettingsWithContext: requestForSpeexRecordSettingsWithContext: init TandemWithRequest:isSiri_requires HistoricalBuffer_useCustomized RecordSettings lpcmIsFloat_isSiri_lpcmBitDepth_numberOfChannels_encoderBitRate_audioFormatTc,N,V_requires HistoricalBufferTc,N,V_useCustomized RecordSettingsTq,N,V_audioFormatTd,N,V_sampleRateTI,N, V_lpcmBitDepthTc,N,V_lpcmIsFloatTI,N,V_numberOfChannelsTI,N,V_encoderBitRate TC,N,V_isSiri_checkSpringBoardStarted_didReceiveSpringboardStarted: _notifyObserver: withStarted: CSSpringboardStartMonitor: didReceiveStarted:_didReceive SpringboardStarted InQueue:_ isSpringBoardStartedisHeadlessDeviceDataCollection ModeEnabled_process Remote HeySiriCommandWithRequest: fromSenderID: withReply:_
processParallelRecording CommandWithRequest: fromSenderID: with Reply:_receiveParallelRecordingFromPeerId: recording Info: with Reply:_receiveVoiceProfileFromPeerId: voiceProfileInfo: withReply:_processGradingDataFetchCommandWithRequest: fromSenderID: withReply:_processVoiceProfileDeleteCommandWithRequest: fromSenderID: withReply:_ receiveVoiceGradingDataFromPeerId:requestInfo: with Reply:_processVoiceProfileListQueryCommandFromPeerId: request Info: withReply:_ processFetchVoiceProfileCommandFromPeerId:requestInfo: with Reply:_processReverseTransferVoiceProfileCommandFromPeerId:requestInfo: withReply:_ processVoiceProfileUpdate TriggerFromPeerId: request Info: with Reply:_sendCoreSpeechGradingDataToPeerId:_send Voice TriggerGradingDataToPeerId:_ sendVoiceProfile Update TriggerToPeerId: forLocale:_sendAcousticGrading DataToPeerId:_sendGeckoSpeech Logs To PeerId:_compressFilesInDirectory: matching Predicate: sortedByCreationDate: compressedFile Available: contentsOfDirectoryAtURL: including PropertiesForKeys: options: error: filteredArrayUsingPredicate:getResourceValue: forKey : error: compare: companionSync Voice TriggerUtterancesEnabledpathExtensionisInternalWithout ProfilepredicateWithBlock:_sendGradingData:withFile Name: to PeerId: withCompressedFlag: with UncompressedDataSize: withBatchId: with RetainFileFlag: withFilePrefix: _compressFilesInDirectory: matching Predicate:compressedFileAvailable: URLByDeleting PathExtension assistantAudioFileLogDirectorygeckoAudioLogDirectory_sendGradingData: withFile Name: to PeerId: withCompressedFlag: with UncompressedDataSize: withBatchId:with RetainFileFlag: withFilePrefix: with Completion: initWithPattern: options: error: rangeOfFirstMatchInString:options: range: mh LogDirectory initWithString: dataUsingEncoding: replace MatchesInString:options:range: with Template: numberWith Unsigned Long: stringByDeletingPathExtension stringBy Appending PathExtension: moveItemAtPath: toPath: error: sendMessageWithPayload: toPeer: withReply:_spIdSiriDebugVoiceProfile Root DirectoryForProfile: locale:writeToFile: options: error: _ spIdSiriDebug Grading DataRoot Directory launchSiriDebugAppWith Message: dictionaryWithObject: forKey: setAttributes: ofItemAtPath: error: temporary Directory_ createDirectory IfDoesNotExist: writeToURL: atomically: newVoiceProfileWithLocale: withAppDomain:_getContentsOfDirectory: addUtterances: toProfile: withContext: withCompletion: updateVoiceProfile: withUserName: provisioned Voice ProfilesForLocale: appDomainprofileIdvoiceProfileForId:deleteUserVoiceProfile: _ sendCoreSpeechMagusGradingDataToPeerId: sharedSiriIddate Added homeId_getHomeUserIdForSharedSiriId: with Completion: userNameinitWithObjectsAndKeys: getHomeUserIdForSharedUserId: completion:_sendVoiceProfile: to PeerId: siriProfileIdcontentsOfDirectoryAtPath: error: fileURLWithPath:_ spIdSiriDebug Voice ProfileCacheDirectoryForProfile: locale: URLsForDirectory: inDomains: lastObject remote P2pLogDirectory remote Grading Data Directory_ spIdSiriDebugVTDataDirectory_spIdSiriDebugVoiceProfileStoreRootDirectory_spIdSiriDebugVoiceProfileStoreRootDirectoryForLocale: isP2PTransfer Enabled process RemoteCommandWithPayload: from Peer: with Reply:
sendCoreSpeechGradingDataToNearby Peersend VTNearMissGradingDataToCompanionsend VoiceProfileUpdatedMessageToNearby PeerForLocale:
sendAcousticGradingDataToNearby PeersendGeckoSpeech Logs To Companion_speaker RecognitionAudioLogs GradingDir_spIdSiriDebugTrainedUsersFilePathForLocale: adCompanionServiceProvidersetAdCompanionServiceProvider: lastCommunicatedPeersetLastCommunicated Peer: voice TriggerBatchIdsetVoiceTriggerBatchId: voice IdentificationBatchIdsetVoice IdentificationBatchId:_adCompanionServiceProvider_last Communicated Peer_voice TriggerBatchId_voice IdentificationBatchIdT@"NSString", &,N, V_LastCommunicatedPeer T@"NSString", &,N,V_voiceTriggerBatchIdT@"NSString", &,N,V_voice IdentificationBatchIdT@"<CSADCompanionServiceProvider>",W,N,V_ adCompanionServiceProviderwillSleephas PoweredOnCSMacWakeSleepMonitor: deviceWillSleep: isEqualTo: CSMacWakeSleepMonitor: deviceTurnedOn: deviceIsInSleepsetDeviceIsInSleep: stateQueuesetStateQueue:_device IsInSleep_stateQueue Tc,N,V_device IsInSleepT@"NSObject<OS_dispatch_queue>", &,N,V_stateQueueT@"NSUUID", &,N,V_token_refreshSpeaker RecognitionAssets_setupSSRControllerWithAudioContext: with VoiceTrigger Event Info:_stopProcessingattSiriNode: didUpdateWithSpeaker Info:attSiriNode: ssrFinished ProcessingWithSpeaker Info:valueForKeyPath: keysSortedByValueUsingComparator: filteredVoiceProfileArray: arrayByAdding ObjectsFromArray:_setupSpeaker RecognitionForProfiles: With VTEventInfo:WithLocale:deleteAllVoiceProfilesForAppDomain: getCacheDirectory For AppDomain: initWithURL:inputFormat:outputFormat: addObjectsFromArray:_processSpeaker Recognition Result: stringFromClassificationCategory: initWithDictionaryRepresentation:_ mapScoresToSharedSiriId: pickTopScoringProfileIdFromScores: classifyUserIdentityFor: withScores: withAsset: multiUserLowScore ThresholddictionaryWithCapacity: readSpeakerIdScoreOverrrideConfig_logSpeakerFalseTriggerMitigationScore: with Speaker MatchScore: with Speaker Score Threshold: withAudioDuration: withSuccess: setModelVersion: setSpeakerMatchScore: set ThresholdScore: setProcessedAudioDurationInNs: setErrorCode: setSpeakerFalse TriggerMitigated: CSSpeaker Recognition Asset Download Monitor: did InstallNewAsset: assetProvider Type: resetForNewRequestWithRecordContext:voiceTrigger Info: cacheSharedUserInfos: getSharedUserIdWithHighestVoiceIdScore:_setup LeadingUtteranceLoggerlogSpeakerFalseTriggerMitigationScore: getLeadingUtteranceLoggerlocalSRBridgeListenershouldCleanup VoiceProfilesetShould CleanupVoiceProfile: ssrControllersetSsrController:ccProfilesetCcProfile: LeadingUtteranceAudioFilesetLeadingUtteranceAudioFile: leadingUtteranceLoggersetLeadingUtteranceLogger: assetssrAssetssetSsrAssets: sharedUserIdsSetsetSharedUserIdsSet: audioRecordContextsetAudio RecordContext: setVoice TriggerEvent Info: speaker RecognitionScores setSpeaker RecognitionScores: cachedScoresForLoggingsetCachedScoresForLogging:_shouldCleanupVoiceProfile_localSRBridgeListener_ssrController_ccProfile_leadingUtteranceAudioFile_ LeadingUtteranceLogger_asset_ssrAssets_sharedUserIdsSet_audioRecordContext_speakerRecognitionScores_cachedScoresForLogging T@"SSRSpeaker RecognitionController", &,N,V_ssrController T@"SSRVoiceProfile", &,N,V_cc Profile T@"NSString", &,N,V_LeadingUtterance AudioFileT@"<CSAudio FileWriter>", &,N,V_leadingUtterance LoggerT@"CSAsset", &,N,V_assetT@"NSArray", &,N,V_ssrAssetsT@"NSSet", &,N,V_sharedUserIds SetT@"CSAudioRecordContext", &,N,V_audioRecordContextT@"NSDictionary", &,N,V_voice Trigger Event InfoT@"NSDictionary", &,N,V_speaker Recognition ScoresT@"NSMutableDictionary", &,N,V_cachedScoresForLogging T@"CSConnectionListener", &,N,V_localSRBridgeListener Tc,N,V_ shouldCleanup Voice ProfileinitWithHash: goodness: confidence: absTime: frac: hashValuegoodnessconfidence frac_goodness_confidence_frac_hashValue_absTimeTS, R, N, V hashValueTC,R,N,V_goodnessTC,R,N,V_confidence TQ,R,N,V_absTimeTC,R,N,V_frac_copyPsd DataInBuffer: copyLength: from Audio Data:_signalEstimate: length:_ copyAudioDataInBuffer: bufferSize: copyLength: from Audio Data: pHash: length: signalEstimate signalFractional_surfacePsdWithAudioChunk: createHashResult:goodness: confidence:absTime: frac:writeHashResultIntoFile:notifyAudioHashNotification notifyAudioHashlessNotificationcreateRemora HashResult: goodness: confidence: firstPassTriggerEndTime: frac: dataWithCapacity: appendBytes: Length: myriad File LoggingEnabled_generateMyriad Info:hsStart: triggerEnd: writeFile: score: triggerSource: channel: audio Provider UUID: absolute Time: createRemoraHashResultFromPHash: firstPassTriggerEndTime: setLastHash:notifyHashless Trigger:writeHashless Result: lastHashT@"NSData", CcachedHashsetSignalEstimate:setSignalFractional:_hammingWindow_setup_snrWindow_snrSetup_signalFractional_signalEstimate Ts,N,V_signalEstimateTC, N,V_ signalFractionalsignalEstimateWithBuilder: _updateAssetWithCurrent LanguageForAssetType:_isOSD Included InAsset: _getCurrentHEPAsset_updateAssetWithLanguage: assetType: _fetchEndpoint Mobile AssetWithLanguage:_notifyAssetsUpdate_updateOEPAssetsWithLanguage: isEndpointAssetOverridingEnabled_getFakeEndpointAssetsetCurrentOEPAsset: asrDatapack InstallationStatus_getModelPathFromInstallationStatusString:_getOEP Version FromPath: currentOEPAssetcurrentHEPAssetendpointerAsset Manager DidUpdateAsset: endpointer Asset ManagerDidUpdate OSDAsset: components SeparatedByString: JSONObjectWithData:options: error: fake Endpoint AssetPathCSFirstUnlockMonitor: didReceiveFirstUnlock:checkFirstUnlocked getCurrentOSDAssetgetCurrentEndpointer AssetsetCurrentHEPAsset: setAsr Datapack InstallationStatus: _currentHEPAsset_ currentOEPAsset_asrDatapack InstallationStatusT@"CSAsset", &,N, V_currentHEPAsset T@"CSAsset", &,N,V_currentOEPAssetT@"NSDictionary", &,N,V_
asrDatapackInstallationStatussetStreamProvider: setStreaming: setStreamRequest:setStreamingUUID:
streamingUUID tandemStreamsstreamingupdateAudioStreamStartTime In SampleCount:setStartStreamOption: setScheduled FutureSample: prepare Audio StreamWithRequest: completion: audioStreamProvider: audioBuffer Available: lastForwardedSampleCount: scheduled FutureSamplestartStreamOptionisWeak StreamsetIsWeakStream: needsBoost12dBsetNeeds Boost12dB: _scheduledFuture Sample_isWeakStream_needs Boost12dB_streaming_streamProvider_startSampleCount_streamRequest_startStreamOption_ tandemStreams_streaming UUIDTC, V_streamingT@"NSUUID", &, V_streamingUUIDT@"<CSAudio StreamProviding>",W,N,V_stream Provider T@"<CSAudioStream Providing Delegate>",W,N,V_ delegate TQ,R,N,V_startSampleCount TQ,R,N,V_LastForwarded SampleCountTc, N, SsetScheduledFuture Sample:, V_scheduledFuture SampleT@"CSAudioStreamRequest", &,N,V_ streamRequestT@"CSAudioStartStreamOption", &, N, SsetStartStreamOption:, V_startStreamOption Tc,N,V_isWeakStreamT@"NSHashTable",R,N,V_tandemStreams Tc,N,V_ needsBoost12dBendpointTimesetEndpointTime: endPointerMetricssetEndPointerMetrics: _endpointTime_endPointerMetricsTd,N,V_endpointTime T@"CSEndpointerMetrics", &,N,V_ endPointerMetricssetEndpointerDelegate: attSiriNode: didDetectHardEndpointAtTime: with Metrics: attSiriNode: didDetectStartpointAtTime: resetForNewRequestWithSampleRate: recordContext: recordOption: voiceTrigger Info: endPointAnalyzer TypelogHybrid Endpoint FeaturesWithEvent: Locale: arrivalHostTime To Audio Recorder_ reportHardEndpoint ToXPC ClientWithTime: endpointerMetrics: attSiriNode: didUpdateOSDFeatures: with Frame DurationMs: attSiriNode: didDetectStartOfSpeechAt: attSiriNode: didDetectEndOfSpeechAt: attSiriNode: didUpdateFirstAudioPacketTimestamp: firstAudio SampleSensorTimestamp: firstAudioStartSampleCount: attSiriNode: didUpdateAnchor MachAbsTime: numSamples ProcessedBefore Anchor Time: isAnchor TimeBuffered:getUsesAutomatic EndpointingprocessASRFeaturesWithWordCount: trailingSilence Duration: eosLikelihood: pause Counts: silencePosterior: taskName: processed Audio Duration In Milliseconds: fromServer: proxysetProxy: endpointLatencyQueuesetEndpoint LatencyQueue:isNNVADsetIsNNVAD: endpoint Latency InfosetEndpoint Latency Info: cachedEndpointer InfosetCachedEndpointer Info:_isNNVAD_proxy _endpointLatencyQueue_endpointLatency Info_cachedEndpointer InfoT@"CSEndpointerProxy", &,N,V_proxy T@"NSObject<OS_dispatch_queue>", &,N,V_endpointLatencyQueueTc,N,V_ isNNVADT@"CSEndpointLatencyInfo", &,N,V_endpoint Latency InfoT@"CSAttSiriCachedEndpointInfo", &,N,V_cachedEndpointerInfoinitWithBundleIdentifier: isPermittedshould MakeRecordWithFrequency:_lastTriggerDataWithResult: isSATEnrollmentMigratedForSiriProfileId: for LanguageCode:_
fidesRecordInfoaddEntriesFromDictionary: saveRecordWithData: recordInfo: completion:_logDES RecordWithType:result:_
handleXPCTimeConvert ProvidingTypeHostTimeFromSampleCountMessage:messageBody: client: streamHandleId:_handleXPCTimeConvert Providing TypeSample Count FromHostTimeMessage :messageBody: client: streamHandleId: initWithUTF8String: initWithAudioDevice ID: sharedSessioncurrentInputRoutecurrentOutputRoute_inputRoute_ outputRouteuidisBluetoothsourcedestination_is Bluetooth_deviceName_uid_source_destinationT@"NSString",R,C,N,V_deviceNameT@"NSString",R,C,N,V_uidTc,R,N,V_ isBluetoothT@"NSString",R,C,N,V_sourceT@"NSString",R,C,N,V_destination_handleAlert ProvidingRequestTypeSetAlert SoundMessage: messageBody: client:_ handleAlertProvidingRequestTypePlayAlert SoundMessage: messageBody: client:_handleAlertProvidingRequestTypePlay RecordStartingAlertAndResetEndpointerMessage: messageBody: client: _handleAlert ProvidingRequestTypeAlertStartTimeMessage: message Body: client:_handleAlertProvidingRequestTypeConfigureAlert Behavior: messageBody: client:_audioAlertProviderT@"<CSAudioAlertProviding>",W,N,V_audioAlertProvider_didReceiveAOPListeningStateChange: listeningEnabledCompletionBlock: CSAlwaysOnProcessorStateMonitor: didReceiveStateChange:_isListeningEnabledinitWithSpeechManager: voice TriggerEnabledMonitor: siriClientBehavior Monitor: opportuneSpeakEventMonitor: phoneCallStateMonitor: other AppRecordingStateMonitor:_cancelLastAudioStreamHold_shouldProcessAudio_keywordAnalyzerNDAPI: hasResultAvailable: forChannel: _createSecondPass_addAudioStreamHold: removeLastObject initWithDescription: _startListenWithAudioProviderUUID: completion:_ shouldHearstAPModeEnabled_transitHearstAPEnable: shouldProcessAudio: keywordAnalyzerNDAPIsetKeywordAnalyzer NDAPI: recordingWillStartGroupsetRecordingWillStartGroup: isAPHearstFirstPassEnabled setIsAPHearstFirstPassEnabled: keyword ThresholdsetKeywordThreshold: secondPassTransactionsetSecondPassTransaction: opportuneSpeakAudioProviderUUIDsetOpportune SpeakAudio ProviderUUID: audioStreamHoldingsset AudioStreamHoldings:
opportuneSpeakEventMonitorsetOpportune SpeakEventMonitor: _isAPHearstFirstPassEnabled_keywordThreshold_keywordAnalyzerNDAPI_recordingWillStartGroup_
secondPassTransaction_opportuneSpeakAudioProviderUUID_audioStreamHoldings_opportune SpeakEventMonitor T@"CSKeyword Analyzer NDAPI", &,N,V_keyword AnalyzerNDAPIT@"NSObject<OS_dispatch_group>", &,N,V_recordingWillStartGroupTc,N,V_isAPHearst FirstPassEnabled Tf,N,V_keyword Threshold T@"CSOSTransaction", &,N,V_secondPass TransactionT @"NSString", &,N,V_opportuneSpeakAudioProvider UUIDT@"NSMutableArray", &,N,V_audioStreamHoldings T@"CSOpportune SpeakEventMonitor", &,N,V_ opportuneSpeakEventMonitorsetLast DuckedAudioDeviceID:LastDucked Audio DeviceIDsetLastDuckedLevel: lastDuckedLevel_lastDuckedAudioDeviceID_lastDucked LevelTI,N,V_ LastDuckedAudioDeviceIDTf,N,V_lastDucked LevelinitWithToken: score: startSampleID: endSampleId: kwdScorestartStampleId_kwdScore_bestToken_startStampleId_endSampleIdT@"NSString",R,N,V_bestTokenTf,R,N,V_kwdScoreTq,R,N,V_startStample IdTq,R,N,V_endSample Idrun RecognitionWithResultStream: addAudioSamples:count: tokenstokenNameendcancelRecognition speechRecognizer: didRecognizePartialResult: speechRecognizer: didFinishRecognitionWithError: speechRecognizer: didRecognizeFinalResults: speechRecognizer: didRecognizeFinalResults: tokenSausage:nBestChoices: speechRecognizer: didRecognizeFinalResultPackage: speechRecognizer: didProcessAudio Duration: speechRecognizer: didRecognize RawEagerRecognitionCandidate: speechRecognizer: didProduceEndpoint FeaturesWithWordCount: trailingSilenceDuration :eosLikelihood: pauseCounts: silencePosterior: processed Audio DurationInMilliseconds: speechRecognizer: didRecognize PartialResultNbest: speechRecognizer: didProduceLoggable Package: speechRecognizer: didRecognize FinalResultCandidate Package: recognizersetRecognizer:recognizerBuffersetRecognizerBuffer: currReqFirstSample IdsetCurrReqFirstSampleId: thresholdsMapset Thresholds Map: _recognizer_recognizerBuffer_currReqFirstSampleId_thresholdsMapT@"_EARSpeechRecognizer", &,N,V_recognizerT@"_EARSpeechRecognitionAudioBuffer", &,N,V_recognizerBufferTq,N,V_currReqFirstSample IdT@"NSDictionary", &,N,V_thresholds MapT@"<CSFLexKeywordSpotterDelegate>", W, N, VdelegatedataWithContentsOfFile: options: error: _exportedObject_ addSelfTriggerEnabledConditionscurrentPower SourcecommandControlBehavior Monitor: willStartStreamWithContext: option: commandControlBehavior Monitor: didStartStreamWithContext: successfully: option: command ControlBehavior Monitor: willStopStream: command ControlBehavior Monitor: didStopStream: numOfAVVCRecording Clients_ numOfAVVCRecording Clients TQ,R,N,V_numOfAVVCRecording ClientsgetAudioSessionStatecompletionBlocksetTimer: setTimerForSecs: completionBlock: cancelTimertimerset CompletionBlock:_timer_completionBlockT@"NSObject<OS_dispatch_source>", &,N,V_timerT@?, C, N, V
completionBlock receiveOpportuneSpeakListenerStartreceiveOpportune SpeakListener Stop_startObservingOtherAppRecordingState handle OtherAppRecordingStateChange: initWithStreamID: atStartHostTime: avvcAlertBehaviorsetSkipAlert: _alertBehaviorTypeFromAVVCOberrideType:_avvcAlertOverride Type:setAVVCAlertBehavior: isAlertBehaviorOverridedBeepgetBest SampleCountWithOption: applyNegative32dBGain ToFloatBuffer: applyNegative20dBGain ToFloatBuffer:applyNegative32dB Gain To ShortBuffer: applyNegative20dBGainToShortBuffer: firstPassDebuggingEnabledgetLastResultis Early Detecthost TimeBuffer setHostTimeBuffer: voice TriggerSample CountsetVoice Trigger SampleCount:_host TimeBuffer_voice Trigger SampleCountT@"CSKeywordAnalyzerNDEAPI", &,N,V_keyword Analyzer T@"NSMutableArray", &, N, V _hostTimeBuffer TQ,N,V_voiceTrigger Sample CountsmartSiriVolumeContextAwareEnabled_didReceive AutomaticVolume Toggled: initWithSuite Name: addObserver: forKeyPath: options: context: observeValueForKeyPath: ofObject: change:context: _isAutomaticVolume Enabled supportHangUpfetchHypotheticalRouteTypesiriInCallPolicydecodeBoolForKey: initWithDisable Endpointer: Tc,R,N,V_disableEndpointer_addAlwaysEnabledCondition_handleDeactivate AudioSession RequestMessage:messageBody: client: audioSessionEventProvidingWillSetAudio Session Active: audioSessionEvent ProvidingDidSetAudioSessionActive: initWithCrashMonitor: setAudioSessionState:_ audioSessionStateaudioSessionStateTQ, N, GgetAudio SessionState, V_audioSessionStateinitWithMasterAudioStream: name: attachToPrimaryStreamWithCompletion: handleAudioStopUnexpectly_fetchAudio DecoderForTV: packetsdefaultConverterinitWithData: numChannels: numSamples: sampleByte Depth: startSampleCount:hostTime: arrivalHostTimeToAudioRecorder: wasBuffered: remoteVAD: speexASBDattachToMasterStreamWithCompletion: decodersForTV setDecodersForTV: decoder Processed SampleCountForTVsetDecoder Processed SampleCountForTV: _decodersForTV_decoder ProcessedSampleCountForTVT@"NSMutableDictionary", &,N,V_decodersForTVTQ, N V_decoder ProcessedSampleCountForTVinitWithOverrideOption: reason: setOverrideState:LogSiriLaunchStartedWithVoiceTriggerEvent Info: setVoiceTrigger Ever Used LogSiri LaunchCompletedWithVoice TriggerEventInfo: initWithServicePort: deactivateForReason: options: context: completion: setActivationSource: setActivation Expiration Time: deactivateSiriActivationConnectionWithReason: withOptions: withContext:_setupStateMachine voice TriggerAOPModeEnabledPolicy_ shouldSecondPassKeepAliveinitWithTargetQueue: withSpeech Manager: withAudioRouteChangeMonitor:_transitVoiceTriggerStatus: force:_stopAOPVoiceTrigger_ transitAOPModeAsync:getAttendingState_updateCurrentSplitterState: shouldDisable Speaker VerificationInSplitterMode:_receivedHearstRoutedEvent:_ forceUpdateCarPlay EndpointWithJarvisConnected: setFirstPassConfig: firstPassConfigdelay SecondsForChannelSelection processingChunkSecondspowerLogSiriConfig With VoiceTr iggerEnabled: with Language: with ModelVersion: processing ChannelsBitsetsupportVoiceTriggerChannelSelection_shouldEnable AOPVoice Trigger_startAOPVoiceTrigger_state Name: powerLogVoice TriggerStartpowerLogVoice TriggerStop_notifyEvent:_transitAOPMode: setIsRequestDuringActiveCall:_stopAPVoiceTriggersetFirstPassRunningMode:_requestStartAudioStreamWithSource:context: completion: _shouldReuseBuiltInAudioProvider_APModeValidationTimerFired_startVoice TriggerWithCompletion: voice TriggerAOPModeStartPolicy_current Jarvis Trigger Mode_teardownSecondPassIfNeeded_shouldEnable APVoiceTrigger_startAPVoiceTriggerWithCompletion:_ hasSiriInputOutOfBandAndNotInSplitter_hasHearstRoutable DuringPhone Call_reportVoiceTriggerFirstPass FireFromAPmasterChannelScoreBoostresetBest_ handleVoiceTrigger SecondPassWithSource: deviceId: event: audioProvider UUID: firstPassInfo:_setIsSecondPassRunning: _createSecondPassIfNeededWithFirstPassSource:_ takeFullWakeAssertionnotifyProviderContextChanged_cancelAllAudioStreamHold_isBuiltInAOPVoiceTriggerEvent:_shouldHandle AOPVoiceTrigger_ isVoiceTriggerStateTransitionEvent: initWith Description: timeout: bypassPersonalizedHeySiri_eventName: _received JarvisConnectionEvent: _receivedHearst ConnectedEvent:_ receivedSiriInputSourceOutOfBandEvent: setAttSiriState: CSVoiceTriggerXPCServiceProxy: bypass PhraseSpotter: CSVoiceTriggerXPCServiceProxy: bypass RaiseToSpeak: attSiriStateMonitor: didRecieveAttSiriStateChange:_transitAOPModeSync: _has Phone CallOnNonBargeInDevice_ firstPassVoice TriggerSignalEstimate keywordAnalyzersNDAPIsetKeywordAnalyzers NDAPI: hasTrigger PendingsetHas Trigger Pending: setBestScore: bestChannel setBestChannel: onsetResultsetOnsetResult: last TriggeredOnsetResultsetLastTriggeredOnsetResult: last TriggeredBestChannelsetLastTriggered BestChannel: onsetChannelsetOnsetChannel: channelSelection DelaysetChannelSelection Delay: delay InSamplesRequiredForChannelSelectionsetDelay InSamplesRequiredForChannelSelection: channelSelectionScoresset ChannelSelectionScores: processing ChunkSamplesset Processing ChunkSamples: isSecondPassCancelledsetIsSecondPassCancelled: isListenPollingStartingsetIsListen PollingStarting:isPhraseSpotter Bypassed setIs PhraseSpotterBypassed: isHearst RoutedsetIsHearst Routed: setVoiceTriggerAOPModeStartPolicy: stateMachinesetStateMachine: currentSplitterStatesetCurrentSplitterState: shouldDisableOnSpeakerVerificationInSplitterModesetShould DisableOnSpeaker VerificationInSplitterMode:validationTimerset ValidationTimer: firstPassMyriad GoodnesssetFirstPass MyriadGoodness: attSiriStateis Jarvis ConnectedsetIsJarvis Connected: isHearst ConnectedsetIsHearstConnected: isSiriInputSourceOutOfBandsetIsSiriInputSourceOutOfBand: audioRouteChangeMonitorsetAudioRouteChangeMonitor: deviceConsideredAsSleepsetDeviceConsideredAsSleep: secondPassPower AssertionsetSecondPassPowerAssertion: fullWake PowerAssertionsetFullWake Power Assertion: fullWakePower AssertionRetainCountsetFullWake PowerAssertion RetainCount:_hasTrigger Pending_isSecondPassCancelled_is PhraseSpotterBypassed_
should DisableOnSpeaker VerificationInSplitterMode_isJarvisConnected_deviceConsideredAsSleep_bestScore_keywordAnalyzersNDAPI_firstPassConfig_best Channel_onsetResult _lastTriggeredOnsetResult_last TriggeredBestChannel_onsetChannel_channelSelection Delay_delay In SamplesRequiredForChannelSelection_channelSelectionScores_ processing ChunkSamples_voice Trigger AOPModeStartPolicy_stateMachine_currentSplitterState_validation Timer_firstPassMyriadGoodness_attSiriState_ audioRouteChangeMonitor_secondPassPower Assertion_fullWake PowerAssertion_fullWake Power AssertionRetainCountT@"NSMutableArray", &,N,V_keywordAnalyzersNDAPIT@"CSVoiceTriggerFirstPassConfig", &,N,V_firstPassConfigTc,N,V_hasTrigger PendingTf,N,V_bestScore TQ,N,V_best ChannelT@"CS KeywordAnalyzer NDAPIResult", &,N,V_onsetResultT@"CSKeywordAnalyzer NDAPI Result", &,N,V_lastTriggeredOnsetResultTQ,N,V_lastTriggeredBestChannelTQ,N,V_onsetChannelTQ,N,V_channelSelectionDelay TQ,N,V_ delayInSamplesRequiredForChannelSelectionT@"NSDictionary", &,N,V_channelSelectionScores TQ,N,V_processing ChunkSamplesTc,N,V_isSecondPassCancelledTc,N,V_ isListen PollingStarting Tc,N,V_isPhraseSpotter BypassedTc,N,V_isHearst RoutedT@"CSPolicy", &,N,V_voice Trigger AOPModeStartPolicy T@"CSStateMachine", &,N,V_stateMachine T@"CSVoiceTrigger AlwaysOnProcessor", &,N,V_alwaysOnProcessorControllerTQ,N,V_currentSplitterStateTc,N,V_should DisableOnSpeaker Verification InSplitterModeT@"NSObject<OS_dispatch_source>", &,N,V_validationTimerT@"NSNumber", &,N,V_firstPassMyriad Goodness TQ,N,V_attSiriStateTc,N,V_isJarvisConnectedTc,N,V_isHearstConnectedTc ,N, V_isSiriInputSourceOutOfBandT@"CSAudioRouteChangeMonitor", &,N,V_audioRouteChangeMonitor Tc,N,V_deviceConsideredAsSleep T@"CSDarkWake Power AssertionMac", &,N,V_ secondPassPower AssertionT@"CSPowerAssertionMac", &,N,V_fullWake Power AssertionTq,N,V_fullWakePowerAssertion RetainCount_setupNNVADEndpointer_ updateAccessibleEndpointer ThresholdIfNeedaccessibleEndpointer ThresholdisWatchRTSTriggeredlogEventWithType: machAbsolute Time: context: initForSidekickendpointerDelegate endpointer ImplDelegatesetEndpointer ImplDelegate: hybridEndpointerset HybridEndpointer: nnvadEndpointersetNnvadEndpointer: activeEndpointersetActive Endpointer: accessibleEndpointerEnabled setAccessibleEndpointerEnabled: recording DidStopsetRecordingDidStop: _accessibleEndpointerEnabled_ recordingDidStop_endpointerDelegate_endpointer ImplDelegate_hybrid Endpointer_nnvadEndpointer_active Endpointer T@"<CSEndpointAnalyzer Impl>", &,N,V_hybridEndpointerT@"<CSEndpointAnalyzerImpl>", &,N,V_nnvadEndpointerT@"<CSEndpointAnalyzer Impl>",W,N,V_activeEndpointerTc,N,V_accessibleEndpointerEnabledTc,N,V_recording DidStopT@"<CSEndpointAnalyzerDelegate>",W,N,V_endpointerDelegateT@"<CSEndpointAnalyzer ImplDelegate>",W,N,V_endpointerImplDelegatedecodeJson:_ getNumberFromASVDictionaryForKey: category: default: _adaptiveSiriVolume DictionarySSVDistance ChannelBitsetSSVCAMaxFrameSize SSVCA Voice TriggerBased TTS ValidForSecondsSS VCASmartSiriVolume Unsynced MetricLogs To RetainSSVCASmartSiriVolumeSynced Metric LogsToRetainSSVCA Voice Trigger InitialSilence DurationSeconds SSVCADistanceInputBufferDura tionSecondsSSVCAListen PollingIntervalAtStartInSeconds SSVCADefaultZeroFloating PointValueSSVCAAnnouncementStatusFetchTimeoutMsSSVCADefaultOutputTTSVolumeSSVCANoiseA ctivityCountThreshold SSVCASpeaker Distance FarBoostFactor SSVCASpeakerDistance Mid Boost FactorSSVCASpeakerDistance NearBoost FactorSSVCADistance ModelConfidence ThresholdS SVCAMinimumLinearSoundLevelSSVCAMaximumLinear Sound LevelSSVCALinearToDecibelConstant Multiplier SSVCA DecibelToLinearLogBaseSSVCASignalToSigmoid Noise DilationFactorSSV CASignalToSigmoidMusicDilationFactorDeviceDefaultSSVCASignalToSigmoidMusicDilationFactorDeviceSimpleSSVCASignalToSigmoidSpeech DilationFactor SSVCASignalToSigmoidNo iseVSpreadSSVCASignalToSigmoid Music VSpread DeviceDefaultSSVCASignalToSigmoid Music VSpreadDeviceSimpleSSVCASignalToSigmoidSpeech VSpreadSSVCASignalToSigmoidNoiseVOffs etSSVCASignalToSigmoid MusicVOffsetDeviceDefaultSSVCASignalToSigmoid MusicVOffsetDeviceSimpleSSVCASignalToSigmoidSpeechVOffsetSSVCASignalToSigmoidNoise HOffsetSSVCAS ignalToSigmoidMusicHOffsetDeviceDefaultSSVCASignalToSigmoidMusicHOffsetDeviceSimpleSSVCASignalToSigmoid SpeechHOffsetSSVCASignalToSigmoidMusicSteepness DeviceDefaul tSSVCASignalToSigmoidMusicSteepness DeviceSimpleSSVCASignalToSigmoidNoiseSteepnessSSVCASignalToSigmoidSpeechSteepnessSSVCADBTOTTSMinimumOutputSSVCADBTOTTSMaximumOu tputSSVCADBTOTTSTransition PointSSVCADBToTTSPreTransitionOffsetSSVCADBTOTTSPreTransition MultiplierSSVCADBTOTTSPost Transition OffsetSSVCADBTOTT SPost TransitionDCSSVCA DBTOTTSPostTransition MultiplierSSVCAMinimum DistanceUpdateWaitPeriodSecondsSSVCANoiseActivityThresholdSSVCANoise Results BufferSize SSVCAMusicResults BufferSizeSSVCADe faultSpeechStrength SSVCADefaultMusicStrengthSSVCANoiseActivity HistoricalSample CountSSVCADspCoefsCountSSVCADspNumStages SSVCADistanceResults BufferSize SSVCAExponenti alDistance HistoryDegradation FactorSSVCADistanceResult SampleCount Tolerance SSVCAMusic Historical SamplesInSecondsSSVCADevice SimpleOutputMinTargetDBSSVCA DeviceSimpleOu tputMaxTarget DBSSVCA DeviceSimpleOutputSlope SSVCADevice Simple Min TargetDBSSVCADeviceSimpleMaxTargetDBSSVCADevice SimpleDBToSystemVolSlope SSVCADevice SimpleMicSensitiv ityOffsetSSVCADevice SimplePreTrigger Silence SampleCountSSVCAMinTTSSystem Volume SSVCAMaxTTSSystem Volume SSVCA DeviceDefaultASVOffMin TTS Volume SSVCADevice Simple ASVOffMin TTSVolumeSSVCADeviceDefaultMicSensitivityOffsetSSVCAVolume HalfLifeSeconds SSVCAHistorical VolumeBufferSizeSSVCAMaximumCompensatedSpeechLevelNearFieldSSVDefaultNoiseChannelCountSSVDefaultLKFSChannelCount SSVDefaultDistanceChannelCountTI, R, NT@"NSDictionary", R, NTi, R, N_firstUnlockNotified_checkFirst Unlocked_didReceive FirstUnlock: _notifyObserver: with Unlocked: _didReceive First Unlock InQueue:_first Unlocked_didReceiveMediaserver Notification: setServerCrashedBlock: setServerResetBlock:_ notifyObserver: withMediaserverState: _mediaserverdDid RestartserverStatesetServerState: _serverState TQ,N,V_serverStatehadSignalsFrom: to: resetForNewRequestWithRecordContext: endpointerSettings: voice Trigger Info: resetForNewRequestWithRecordContext: endpointerSettings: voiceTrigger Info:osdMode: audioStartSampleCountfetchLast Known ConsecutiveBoronStartSampleCountsetSecondPassAssetQueryStartTime: setSecondPassAssetQueryCompleteTime: _ secondPassAssetQueryStartTime_secondPassAssetQueryComplete Time_secondPassAssetLoadStartTime_secondPassAsset Load CompleteTime_secondPassAudioStreamStartTime_ secondPassAudioStreamReady Time_secondPassFirstAudioPacketReceptionTime_secondPassLastAudio PacketReception Time_secondPassCheckerModelKeywordDetectionStartTime_ secondPassCheckerModelKeywordDetection End Time TQ,N,V_secondPassAssetQueryStartTime TQ,N,V_secondPassAssetQueryCompleteTime TQ,N,V_secondPassAssetLoadStartTime TQ,N,V_ secondPassAsset LoadCompleteTime TQ,N,V_secondPassAudioStreamStartTime TQ,N,V_secondPass Audio StreamReadyTime TQ,N,V_secondPassFirstAudioPacketReception Time TQ,N,V_ secondPassLastAudioPacket Reception Time TQ,N,V_secondPassCheckerModelKeywordDetectionStartTimeTQ,N,V_secondPassCheckerModelKeywordDetectionEndTime_ handleEnablePolicy Event:getAnalyzed Results FromAudioChunk: voiceTrigger PhIdsoutput AudioChannelsetOutputAudioChannel: selfTriggerConfigsetSelf TriggerConfig:_ outputAudioChannel_selfTriggerConfigT@"CSSpeechManager",W,N,V_speech Manager TQ,N,V_output Audio ChannelT@"CSContinuous Voice TriggerConfig", &,N,V_ selfTriggerConfigcontinuousAudioFingerprint Enabled PolicyreadAudioChunksFrom: block: playback Device Type List_recordDevice Info_playbackRoute_playback Device TypeListT@"CSAudioRecordDeviceInfo",R,C,N,V_recordDeviceInfoT@"NSString",R,C,N,V_playbackRouteT@"NSArray",R,C,N,V_playbackDeviceTypeList_ didReceiveNewSpeechEndpointAssetMetaDataattendingStatesetAttendingState:updateState:isAttendingisAttendingForDictation_attendingState TQ,N,V_ attendingStateprogCheckerConfigFileinitWithArray: _mapInputOriginFromAssetToCSAudioRecord Type: contConvConfigFilekeysOfEntriesPassingTest: supportedInputOrigins checker ThresholdsprogChecker ShadowModecontConvThresholdsT@"NSArray", R, NCSSiriAssertionMonitor: didReceiveEnabled: enableAssertionReceived disableAssertionReceived_assertionState_start Monitoringsession InfoQueuesetSessionInfoQueue:_sessionInfoQueueT@"NSObject<OS_dispatch_queue>",&,N,V_sessionInfoQueuemultiUserHighScore ThresholdmultiUserDeltaScore ThresholdmultiUserConfidentScore ThresholdctxdetectedToken triggerMachTimetrigger AbsStartSample Id_ctx_detectedToken_trigger MachTime_triggerAbsStartSample IdT@"CSAttSiriRequestContext",C,N,V_ctxT@"NSString", &,N,V_detectedTokenTQ,N,V_trigger MachTime TQ,N,V_ triggerAbsStartSampleIdgetFixedPrioritySerialQueueWithLabel: fixedPriority: setStreamState: allowExtended RingBufferSize_createCircularBuffer IfNeededWithNumChannel: playbackRoute: initWithAudioStreamHandleId: audioStreamType: audioRecordContext: audioRecorder: phoneCallStateMonitor: _holdRecording ExceptionIfNeeded:_ updateRemoteDeviceIdFromAVVCIfNeeded_streamState Name: setProviderDelegate:_setLatest RecordContext: recordDevice Indicator_canSetContext_prepareAudio StreamSync: request: error: historicalBuffer RequestStreams_audioStreamWithRequest: streamName:error:_ handleAudioSystemFailureinputRecording DurationInSecsExtendedinputRecording DurationnumInputChannels_startAudioStream:option: completion: _prepareAudioStream:request: completion: audioStreamTypestartPendingOnStoppingStreamsstartPendingOnStoppingStreamToCompletion Dict_did PlayStartAlertSoundForSiri: audioStream: alertPlayback FinishWaitingStreams alertPlaybackFinishWaiting Completions_scheduleAlertFinish Timeout:_ switchToRecording ModecircularBufferStartHostTime circularBufferStartSampleCount sampleCountFromHostTime: anchor HostTime: anchor SampleCount:sampleRate: startPendingStreamspendingStartCompletions_holdRecording TransactionIfNeeded_scheduleAudioPacketWatch Dog_scheduleDidStartRecording DelegateWatchDog_ resetCircular BufferStartTime setCircularBufferStartHostTime: setCircular BufferStartSampleCount: supportOpportunisticZLLstreams_ deliverHistoricalAudioToStreamsWithRemoteVAD: _cancelAudioPacketWatch Dog_clear DidStart Recording DelegateWatchDog_
releaseRecording TransactionIfNeeded audioPreprocessor_clearDidStop RecordingDelegateWatchDog_preEpilogueAudioStreamstopPendingStreamspending StopCompletions_ postEpilogueAudioStream_shouldHandleStartPendingOnStopping: withStopReason:_stopAudioStream: option: completion: _shouldStop Recording_ scheduleDidStop Recording DelegateWatchDog_switchToListening Mode_audioChunk From: to: _audioChunkFrom: to: channelIdx: copy SamplesFrom: to: channelIdx:_ saveRecording BufferFrom: to: toURL: saveAudioChunck: toURL: streamHolderssetSessionDelegate:_activateAudioSessionWithReason: error: _ shouldDuckOnBuiltInSpeakersupportNonInterruptibleSirisupportsDuckingOnSpeakerOutput_deactivateAudioSession: error: setAlertDelegate: _processAudioBuffer: remoteVAD: atTime: arrivalTimestamp To Audio Recorder: numberOfChannels: _handle DidStartAudioStreamWithResult: error:_handleDidStopAudio StreamWithReason: sessionDelegateproviderDelegate bufferLength_fetchHistoricalAudioAndForwardToStream: remoteVAD: setRemoteVAD: _deliverPostprocessAudio Chunk: toStream: LastForwardedSampleCount:addSamples: numSamples: atHostTime: _forwardAudioChunk: toStream: chunkForChannel: gainCompensatedChunk_forwardAudioChunk For TV: toStream:_ didReceiveFinishStartAlertPlaybackAt: alertDelegateinitWithName: clientQueue:_onAudio PacketWatchdogFire_schduleDidStart RecordingDelegateWatchDogWithToken:_ scheduleDidStop Recording DelegateWatchDog:_isDuckingOnSpeakerOutputSupportedWithCurrentRoutecircularBuffer NumInputChannelcircularBufferInputRecording Durationrecord QueuesetRecordQueue: LoggingQueuesetLoggingQueue: streamHandleQueuesetStreamHandleQueue: streamStatesetStartPendingStreams: setStartPendingOnStoppingStreams: setAlertPlaybackFinishWaitingStreams:setStreams: setStopPendingStreams: setPendingStartCompletions: setAlertPlaybackFinishWaitingCompletions: setPendingStopCompletions: setStartPendingOnStoppingStreamToCompletionDict:setStreamHolders: setHistoricalBuffer RequestStreams:
LastAudioRecorderContextsetLastAudioRecorderContext: audioSystemRecoveringsetAudioSystemRecovering: setAudioPreprocessor: recording TransactionsetRecording Transaction :waitingForAlertFinishsetWaiting For AlertFinish: setAudioStreamHandleId: alertPlaybackFinishTimeoutTokensetAlertPlaybackFinishTimeoutToken: startRecordingWatchDogTokensetStartRecordingWatchDogToken: stopRecordingWatchDogTokensetStopRecording Watch DogToken: audioPacketWatchdogsetAudioPacketWatchdog: setAudioStreamType: setRecordDevice Indicator: micUsageReportersetMicUsageReporter: audioPacketDeliveryCountsetAudioPacket DeliveryCount:adpAssertionsetAdpAssertion: currentSessionShould DuckOnBuilt In SpeakersetCurrentSessionShould DuckOnBuiltInSpeaker:_audioSystemRecovering_waitingForAlertFinish_ currentSessionShould DuckOnBuiltInSpeaker_recordQueue_loggingQueue_streamHandleQueue_streamState_startPendingStreams_startPendingOnStoppingStreams_ alertPlaybackFinishWaitingStreams_streams_stopPendingStreams_pendingStartCompletions_alertPlaybackFinishWaitingCompletions_pendingStopCompletions_ startPendingOnStoppingStreamToCompletion Dict_providerDelegate_sessionDelegate_streamHolders_historicalBuffer RequestStreams_alertDelegate_lastAudioRecorderContext_ audioPreprocessor_recording Transaction_audioStreamHandleId_alertPlaybackFinishTimeout Token_startRecordingWatch DogToken_stop RecordingWatchDogToken_ audioPacketWatchdog_circularBufferStartHostTime_circularBufferStartSampleCount_audioStreamType_recordDevice Indicator_micUsage Reporter_audioPacket DeliveryCount_
adpAssertionT@"NSObject<OS_dispatch_queue>", &,N,V_recordQueueT@"NSObject<OS_dispatch_queue>", &,N,V_LoggingQueueT@"NSObject<OS_dispatch_queue>", &,N,V_ streamHandleQueue TQ,N,V_streamState T@"NSHashTable", &,N,V_startPendingStreams T@"NSHashTable", &,N,V_startPendingOnStoppingStreamsT@"NSHashTable", &,N,V_ alertPlaybackFinishWaitingStreams T@"NSHashTable", &,N,V_streams T@"NSHashTable", &,N,V_stopPendingStreams T@"NSMutableArray", &,N,V_pendingStartCompletionsT@"NSMutableArray", &,N,V_alertPlayback FinishWaiting Completions T@"NSMutableArray", &,N,V_pendingStop CompletionsT@"NSMutableDictionary", &,N,V_ startPendingOnStoppingStreamToCompletionDictT@"<CSAudio Provider Delegate>",W,N,V_providerDelegate T@"<CSAudioSessionProviding Delegate>",W,N,V_sessionDelegateT@"NSMutableArray", &,N,V_streamHolders T@"NSHashTable", &,N,V_historicalBuffer RequestStreams T@"<CSAudioAlert ProvidingDelegate>",W,N,V_alertDelegateT@"CSAudioRecordContext", &,N,V_lastAudioRecorderContextTc,N,V_audioSystemRecovering T@"CSAudioPreprocessor", &,N,V_audioPreprocessorT@"CSOSTransaction", &,N,V_ recording Transaction Tc,N,V_waitingForAlertFinish TQ,N,V_audioStreamHandleIdT@"NSUUID", &,N,V_alertPlaybackFinishTimeoutTokenT@"NSUUID", &,N,V_ startRecordingWatchDogTokenT@"NSUUID", &,N,V_stop RecordingWatchDogTokenT@"NSObject<OS_dispatch_source>", &,N,V_audioPacketWatchdogTQ,N,V_ circularBufferStartHostTime TQ,N,V_circularBufferStartSampleCountTq,N,V_audioStreamTypeT@"CSAudioRecordDeviceIndicator", &,N,V_recordDevice IndicatorT@"CSMicUsageReporter", &,N,V_micUsageReporterTQ,N,V_audioPacket Delivery CountT@"CSADPPrevent Standby Assertion", &,N,V_adpAssertionTc, N,V_ currentSessionShould DuckOnBuiltInSpeakerfirstPassRunning Mode_firstPass RunningModeTq,N,V_firstPassRunningMode containsCategory:getValueForKey: category: satScore ThresholdgetBoolForKey: category: default: psrCombinationWeightsat Implicit Profile Thresholdsat Implicit Profile DeltaThresholdsat VTImplicit ThresholdpruningExplic itUttThresholdSATpruningExplicitUttThresholdPSRpruning ThresholdSATpruning ThresholdPSRpruningNumRetentionUtterancemaxAllowedEnrollment Utterances voiceProfile Pruning CookiekeywordDetectorQuasarConfigFilePathkeyword DetectorNDAPIConfigFilePathsat Implicit TrainingEnabledcontains MultiUser Thresholds Tq, R, NisDeviceRoleStereo_ isDeviceRoleStereo_descriptionisSpeaker RecognitionAvailable_did InstalledNewAsset trialAsset Monitorset TrialAsset Monitor: _lastUpdatedAssetType_trialAsset MonitorT@"CSTrialAssetDownloadMonitor", &,N,V_trialAsset Monitor_startObservingAVCallActiveChange_handleCallActiveDidChangeNotification: hasConnectedAVCall_hasConnectedAVCall_ asssetMetaUpdatedKey_didReceiveSpeaker RecognitionAssetMetaDataactivationMetadataisHSVoiceTrigger: mitigatonConfigFilemitigationModelDefaultAFTMScorenldaConfigFile allowKeywords File allowListWordCountThreshold mitigationConfigFileForCategory:
nldaConfigFileForCategory: shouldRunSpkrIdForCategory:getCategoryKeyWithRecordCtx: firstPass MyriadGoodnessScoresetFirstPassMyriadGoodness Score:_ firstPassMyriad Goodness ScoreTf,N,V_firstPassMyriad GoodnessScore_clear PendingRemoraVoiceTrigger_clear Pending BuiltInVoiceTriggerisBultInVoiceTriggerEvent: isRemoraVoice TriggerEvent: handlePendingRemora Voice Trigger IfNeeded handlePending Built In Voice Trigger IfNeeded setBuiltInVoice TriggerMetaData: accessoryVoice TriggerMetaDataByDeviceId_getHighest RemoraFirstPass Goodness Score:_
isRemoraSecondPass RunningbuiltInSeconPass ProgressProviderremora SecondPassProgressProviderpendingRemoraVoice TriggerResultset PendingRemoraVoice Trigger Result: pendingRemoraVoiceTriggerDeviceIdsetPendingRemoraVoiceTriggerDeviceId: pendingRemoraVoiceTriggerCompletionBlksetPendingRemoraVoiceTriggerCompletionBlk: pendingRemora Voice TriggerDetected Timeset PendingRemora Voice Trigger Detected Time: pending BuiltInVoice TriggerResultset Pending Built In VoiceTriggerResult: pendingBuiltInVoiceTriggerCompletionBlksetPendingBuiltInVoice Trigger CompletionBlk: pendingBuiltInVoice Trigger DetectedTimeset Pending BuiltInVoiceTriggerDetectedTime: builtInVoiceTriggerMetaDataset AccessoryVoiceTriggerMetaDataByDeviceId:_builtInSecon PassProgress Provider_remora SecondPass ProgressProvider_ pendingRemora Voice Trigger Result_pendingRemoraVoice TriggerDeviceId_pendingRemora VoiceTriggerCompletionBlk_pendingRemora Voice TriggerDetected Time_ pendingBuiltInVoiceTrigger Result_pending Built InVoice TriggerCompletionBlk_pending BuiltInVoiceTriggerDetectedTime_builtInVoiceTriggerMetaData_ accessoryVoiceTriggerMetaDataByDeviceIdT@"NSDictionary", &,N,V_pendingRemora Voice TriggerResultT@"NSString", &,N,V_pendingRemora Voice TriggerDeviceIdT@?, C, N, V pendingRemora Voice TriggerCompletionBlkTQ,N,V_pendingRemora Voice TriggerDetectedTimeT@"NSDictionary", &,N,V_pendingBuiltInVoiceTriggerResultT@?,C,N,V_ pendingBuiltInVoice TriggerCompletionBlkTQ,N,V_pending Built In Voice Trigger DetectedTimeT@"CSPreMyriad Voice Trigger MetaData", &,N,V_builtInVoice Trigger MetaDataT@"NSMutableDictionary", &,N,V_accessoryVoice Trigger MetaDataByDeviceIdT@"<CSSecondPassProgressProviding>",W,N,V_builtInSeconPassProgressProviderT@"<CSSecondPassProgressProviding>",W,N,V_remoraSecondPass Progress ProviderfakeVoice TriggerAssetPathsupportAcoustic ProgressiveCheckersupportsHybrid UnderstandingOnDevi ceinitWithEndpointerNode: osdNode: ssrNode: asrNode:ures Node: flexKwd Node: needs SSRNode: aFtmNode: speech DetectionNode: speech Manager: siriEnabled Monitor: siriClientBehavior Monitor: rcHandler: supportsAcoustic Progressive Checker: supports UnderstandingOnDevice: require ASROnDevice: supports Hybrid UnderstandingOnDevice: strongToWeakObjectsMapTableregisterEndpointer Node: register UresNode: preheatWithLanguage: should Download Missing Asset: _fetchRequiredAssets_ handleStartProcessingWithRecordContext: completion: _setupAudioSrcNodeWithSiriClientStream:_handleStopProcessingstopWith Reason: _tearDownBuildGraph:_ fetchVoiceTriggerAssets_fetchMitigationAssetssetAudioSrcNode:_forceBuildGraph: audioSrcNode_
holdAttSiriTransactionIfNeeded prepareToStartSpeechRequestWithStartStreamOption: audioRecordContext:voice Trigger Info:_release AttSiriTransactionIfNeededattSiriNode: didDetectSpeechWithTrigger Info:attSiriNode Did Not DetectSpeechWithTimeout_reconfigure RequiredNodes: enforceAttending AudioNode: setRcHandler: nodesCachesetNodesCache: setOsdNode: asrNodesetAsrNode:setSsrNode: siriClientAudioStartStreamOptionsetSiriClientAudioStartStreamOption: attSiriTransactionsetAttSiriTransaction: siriClientStreamsetSiriClientStream: mitigationAssetsetMitigationAsset: vtAssetsetVtAsset: siriEnabledMonitorsetSiriEnabled Monitor: flexKwdNodesetFlexKwdNode: aFTMNodesetAFTMNode: setNldaClassifier Node: speech DetectionNodesetSpeech DetectionNode: _rcHandler_nodesCache_asrNode_audioSrcNode_siriClientAudioStartStreamOption_ attSiriTransaction_siriClientStream_mitigationAsset_vtAsset_siriEnabledMonitor_flexKwdNode_aFTMNode_speechDetectionNodeT@"NSMapTable", &,N,V_nodesCacheT@"CSAttSiriEndpointerNode", &,N,V_endpointerNode T@"CSAttSiriOSDNode", &,N,V_osdNode T@"CSAttSiriAsrNode", &,N,V_asrNode T@"CSAttSiriUresNode", &,N,V_ures NodeT@"CSAttSiriAudioSrcNode", &,N,V_audioSrcNode T@"CSAttSiriSSRNode", &,N,V_ssrNode T@"CSAudioStartStreamOption", &,N,V_siriClientAudioStartStreamOptionT@"CSOSTransaction", &,N,V_attSiriTransactionT@"CSAudioStream", &,N,V_siriClientStreamT@"CSAsset", &,N,V_mitigationAssetT@"CSAsset", &,N,V_vtAsset T@"CSSiriEnabled Monitor", &,N, V_ siriEnabledMonitorT@"CSAttSiriFlexKwdNode", &,N,V_flexKwdNode T@"CSAttSiriAFTMNode", &,N,V_aFTMNodeT@"CSAttSiriNLDAClassifier Node", &,N,V_nldaClassifier Node T@"CSAttSiriSpeech DetectionNode", &,N,V_speech DetectionNode T@"CSAttSiriRCHandler", &,N,V_rcHandler_checkPhraseSpotterEnabledCSPhraseSpotterEnabledMonitor: didReceiveEnabled: _didReceivePhraseSpotterSettingChanged InQueue:_phraseSpotterEnabled DidChange_isPhraseSpotterEnabledsetWithObjects: decodeObjectOfClasses: forKey: totalAudioRecordedsetTotalAudioRecorded: endpointBufferHostTimesetEndpointBufferHostTime: featuresAtEndpointsetFeaturesAtEndpoint: endpointerTypeserverFeatureLatency DistributionsetServerFeatureLatencyDistribution: additional Metrics setAdditionalMetrics:trailingSilence DurationAtEndpoint setTrailingSilence DurationAtEndpoint: _totalAudioRecorded_endpoint Buffer HostTime_featuresAtEndpoint_endpointerType_ serverFeature Latency Distribution_additional MetricsTd,N,V_totalAudioRecordedTQ,N,V_endpointBufferHostTimeT@"NSArray", &,N,V_featuresAtEndpoint Tq,N,V_endpointerTypeT @"NSDictionary", &,N,V_serverFeatureLatencyDistributionT@"NSDictionary", &,N,V_additionalMetricsTd,N,V_trailingSilenceDurationAtEndpoint_sendMessage:connection: completion:_did InstalledNewAdBlockerAssetCSAdBlockerAssetDownload Monitor: did InstallNewAsset: assetProvider Type: monitorset Monitor: _monitorT@"CSTrialAssetDownloadMonitor", &,N,V_monitorassetChangeMonitor Did DetectAssetChange: startMonitoringT@"<CSVoiceTriggerAssetChangeDelegate>",W,N,V_delegate_ handleVoiceTriggerXPCService Message:client:_handleServiceConnectionLostIfNeeded_handlePhraseSpotterBypass Request: _handle VoiceTriggeredSiriSessionCancelled_ handleEnableVoiceTriggerWithSiriAssertionRequest:_handleRaiseToSpeakBypassRequest:_handleVoiceTriggerStatsFetchEvent: client:setPhraseSpotter Bypassing: timeout: setRaiseToSpeakBypassing: timeout: notifyVoiceTriggered SiriSessionCancelledenableVoiceTrigger: withAssertion: timestamp: fetchVoice Trigger Stats T@"<CSVoiceTriggerXPCConnectionDelegate>",W,N,V_delegate_createDeInterleaver IfNeeded_
startAudioFeeding TimerlpcmNonInterleavedASBDshouldDeinterleaveAudioOnCSlpcm InterleavedASBD_deinterleaveBufferIfNeeded: setFileOption: _defaultOutASBDinjectAudio: withScaleFactor: outASBD: playbackStarted: completion: lpcmFloat ASBDfileOptionsetIsRecording: bufferDuration setBufferDuration: injectionAudioFileListset InjectionAudioFileList: injectionStartNotifyBlockssetInjectionStartNotifyBlocks:
injectionCompletionNotifyBlockssetInjection Completion NotifyBlocks: de interleaversetDeinterleaver: pNon InterleavedABLsetPNonInterleavedABL: didSetScaleFactorset DidSetScaleFactor: setScaleFactor: _isRecording_didSetScaleFactor_fileOption_injectionAudioFileList_injectionStartNotifyBlocks_ injectionCompletionNotify Blocks_deinterleaver T@"CSAudioInjectionFileOption", &,N,V_fileOptionTc,N,V_isRecording Td,N,V_buffer DurationT@"NSMutableArray", &,N,V_ injectionAudioFileListT@"NSMutableArray", &,N,V_injectionStartNotifyBlocks T@"NSMutableArray", &,N,V_injection CompletionNotify BlocksT^{Opaque Audio Converter=},N,V_ deinterleaverT^{AudioBufferList=I [1{AudioBuffer=II^v}]},N, V_pNonInterleavedABLTC,N,V_didSetScaleFactorTf,N,V_scaleFactor initWithAppBundleIdentifier: initWithTaskDeliverer: initWith Message: makeAppFrontmost: handleSiriRequest: deliveryHandler: completionHandler:valueFor Entitlement: _getHost Power Source_ didReceiveHostSystemStateChangeNotification:_notifyObserver: withHostPower Source: CSHostPowerSource Monitor: didReceive Power SourceChange:_handleChangeIn PowerSource_ power RunLoopSource CSMyriadSelfTriggerCoordinator: didGenerate Myriad PHashForSelfTrigger: T@"<CSMyriadSelfTriggerCoordinator Delegate>",W,N,V_delegate_ notifyHearstConnectionState: preferredExternalRouteDidChange_fetchHearstRoutedStateWithDeviceID: _pickedRoutes ChangedBlock_handleActivate Event Messsage:client: CSActivationXPCConnectionReceived ClientError:clientError:client: T@"<CSActivate XPCConnectionDelegate>",W,N,V_delegatespeakAudio:setIsConnected:_isConnected_ enableAlwaysOnVoice Trigger_device ID_deviceUID_productIdentifier_injection EngineTq,R,N,V_deviceTypeT@"NSString",R,N,V_device NameT@"NSString",R,N,V_deviceIDT@"NSUUID",R,N,V_deviceUIDT@"NSString",R,N,V_productIdentifierTc,N,V_isConnectedTc,N,V_enable AlwaysOnVoice TriggerT@"CSAudioInjectionEngine",W,N,V_injectionEngine_ notifyObserver: withClamshellState: CSClamshellStateMonitor: didReceive ClamshellStateChange:_didReceiveClamshellStateChangeNotification: _notificationPort_ serviceNotificationfile LoggingIsEnabledgeckoLoggingLevelinitWithSpeech Manager: file LoggingEnabled: geckoLoggingEnabled: setFileLoggingEnabled:setGecko LoggingEnabled: _timeStampStringdataWithJSONObject:options: error: file LoggingEnabled_shouldSkipLogging:_should Log DeviceId: _metaFilenameWithRootDir: prefix: deviceId:_logVTResult: metaFilePath:audioFilePath: completion:_clearOldLoggingFiles_logGeckoWithFilePrefix:WithResult:_write Dictionary: toPath: geckoLoggingEnabled_gecko LogDirectory_ clearOldGecko LoggingFilesmax NumLogging Files removeLogFilesInDirectory: matching Pattern: beforeDays: _fileLoggingEnabled_geckoLoggingEnabledTc,N,V_fileLoggingEnabledTc ,N, V_geckoLoggingEnabledestimated UserSpeaking Started HostTime estimatedUserSpeakingEndedHostTime_reportUEIUserSpeaking ContextsetEndpoint DelayInNs: setEndpointModelDelay InNs:setSpeakingStartInNs:setSpeaking EndInNs: setEndpoint DelayContext: setExists: setStartedOrChanged: LogInstrumentation: mach AbsoluteTime: turnIdentifier: setEnded: initWithRequestMHUUID: turnIdentifier: setSpeech RecognizedContext: withEndpointerMetrics: reportEndpoint Delay IfNeed endpoint TimeInMssetEndpoint Time InMs: userSpeakingStartedTimeInMssetUserSpeaking Started TimeInMs: UserSpeaking EndedTimeInMssetUserSpeaking EndedTimeInMs: userSpeakingStarted HostTimesetUserSpeakingStarted HostTime: UserSpeakingEndedHostTimesetUserSpeaking Ended HostTime:stop Recording HostTimesetStop RecordingHostTime: turnIdentifierset TurnIdentifier: didReportEndpoint Delayset Did ReportEndpoint Delay: _didReportEndpoint Delay_endpoint TimeInMs_userSpeakingStarted TimeInMs_userSpeakingEndedTimeInMs_ userSpeakingStartedHostTime_userSpeaking Ended HostTime_stop Recording HostTime_turnIdentifierTd,N,V_endpoint TimeInMsTd,N,V_userSpeakingStartedTimeInMsTd,N,V_ UserSpeaking EndedTimeInMsTQ,N,V_UserSpeakingStarted HostTime TQ,N,V_userSpeaking Ended HostTime TQ,N,V_stopRecording HostTimeT@"NSUUID", &,N,V_turnIdentifierTc,N,V_ didReportEndpoint Delay_speaker Recognition ModelRetrainCallback_speakerRecognitionCleanup Duplicated ProfilesCallback_runVoiceProfile RetrainerWithAsset: withLanguageCode: triggerVoiceProfileDuplicates Cleanup cleanup Voice ProfileModelFilesForLocale: triggerVoiceProfileDownload_retrainingVoice Profile: voice Profile: asset: prune ImplicitUtterancesOfProfile: withAsset: setRemoteObjectInterface: processIdentifier clientConnections remoteObjectProxysetClientConnections: machServiceNamesetMachServiceName: _exported Interface_remote Interface_proxyObject_clientConnections_machServiceNameT@"NSMutableArray", &,N,V_clientConnectionsT@"NSString", &,N,V_machServiceName_addVoice Trigger AOPModeEnabledConditionsforce Voice Trigger APMode_addConditions ForIOSBarge In_addConditions For IOSAOP_ isInPhoneCallStateWithHSPhone CallCapable Route_isSpeechDetection DevicePresent_
isHearst RoutedAndWithNo Phone CallisSiriClientConsideredAs RecordsetIsSiriClientConsideredAsRecord: setPendingRecordingStopUUID: notifyCallbackWithOption: pendingRecordingStopUUID_recordStateQueue_isSiriClientConsideredAs Record_pendingRecordingStopUUIDTC,N,V_isSiriClientConsideredAs RecordT@"NSString", &,N,V_ pendingRecordingStopUUIDinitWithAssertion Monitor: _fetchAssertionMonitorsystemUptime notifyServiceConnectionLostisRaiseToSpeakBypassed setIsRaiseToSpeakBypassed: assertionMonitorsetAssertion Monitor:_isRaiseToSpeakBypassed_assertionMonitorTc,N,V_is Raise To SpeakBypassed T@"CSSiriAssertion Monitor", &,N,V_assertionMonitor_ add MacBargeInConditionsencode Integer: forKey: decode IntegerForKey: initWithRequestSource: reqSrcsetReqSrc:_reqSrcTQ,N,V_reqSrc_ didReceiveNewAdBlockerAssetMetaDatainitWith VoiceTriggerAsset Download Monitor: LanguageCode UpdateMonitor: firstUnlockMonitor: trialAssetDownloadMonitor: asset Manager: trialAsset Manager: _getVoiceTriggerAsset FromAsset Manager:_getVoice TriggerAsset FromAsset ManagerWithLocale: completion: _handleVoice TriggerAssetWithCompletion:_ handleEndpointVoice TriggerAsset:completion: isEqualAsset: cachedEndpointAssets_checkNewAsset Availablity_checkNewAsset AvailablityForEndpointsetCachedEndpointAssets: voice TriggerAsset Download MonitorsetVoice TriggerAssetDownloadMonitor: languageCode UpdateMonitor setLanguageCode UpdateMonitor:firstUnlockMonitorsetFirstUnlockMonitor: trialAssetDownload Monitorset TrialAsset DownloadMonitor: _cachedEndpointAssets_voiceTrigger Asset DownloadMonitor_languageCode Update Monitor_firstUnlockMonitor_trialAssetDownloadMonitor T@"NSMutableDictionary", &, V_cachedEndpointAssets T@"CSVoiceTriggerAsset Download Monitor", &,N,V_voice Trigger Asset Download MonitorT@"CSLanguageCodeUpdateMonitor", &,N,V_languageCodeUpdate Monitor T@"CSFirst UnlockMonitor", &,N,V_firstUnlockMonitorT@"CSTrialAssetDownloadMonitor", &,N,V_ trialAssetDownload Monitorset IsStreaming:_isStreamingTc,N,V_isStreaming initWithNumChannels: recording Duration: samplingRate: initWithSiriSession UUID: addAudioChunk: fetchAudioFromCircularBuffer T@"CSAudioCircularBuffer",R,N,V_circularBufferT@"NSString",R,N,V_siriSession UUIDinitWithAttSiriController: localSpeechRecognizer: isFileLoggingEnabled:_setLocalSpeechRecognizerState: _handleStop Deliver LocalSpeechRecognition absoluteHostTimeToContinuous HostTime: _preheatWithLanguage: preheatSource: should Download MissingAsset:requestId_stopPrevious RecognitionTaskIfNeededWithNewRequestId: speechRecognitionTask_ startDeliverLocalSpeech RecognitionResultsWithRequestId: _startLocalSpeechRecognizerIfNeeded_handleStopSpeechRecognition TaskIfNeeded:_ clearAudioProcessWaitingBuffer IfNeeded_invalidateLocalSpeechRecognizer:_interactiveLocalSpeechRecognizerpauseRecognition resumeRecognitionWithPrefix Text: postfixText:selected Text: initWithDelegate:instanceUUID: _processAudioChunk: endpointModeFromEndpoint Metrics:_queryShould AcceptEagerResultForDuration: requestId: rcId: _clearEndpointHintstartMissing AssetDownload_preheatWithLanguage: preheatSource: initWithLanguage: assetType:_sourceStringFromPreheatSource: preheatSpeech RecognitionWithAssetConfig: preheatSource: modelOverride URL: _setRecordingStartTimeWithStartStream Option: audio RecordContext:voiceTriggerInfo:_ adjustEndpointStartTime With VoiceTriggerEvent:_shouldDisableLocalSpeechRecognizerWithOption: audioRecordContext: isDictationsupportsDictationOnDevice_stateToString: taskString:sharedUserInfosloggingFilePathWithDirectory: token:postfix:dictationUI InteractionIdshouldStoreAudioOnDeviceoverrideModelPath_
fetchInputOriginWithRecordContext: deliverEagerPackageUILanguage_fetchRecognizerLanguageWithSiriLanguage: UILanguage:taskString:_ resetLocalSpeechRecognizerParametersapplication NamerecognitionOverrides detectUtterances secure OfflineOnlycontinuousListening shouldHandleCapitalizationmaximumRecogn itionDurationlocationjitGrammarenable EmojiRecognitionenableAutoPunctuationenable Voice Commands prefix Textpostfix TextselectedTextpowerContextinitWithLanguage: requestIdentifier: dictationUIInteraction Identifier: task: logging Context: application Name: profile: overrides: modelOverride URL: originalAudioFileURL: codec: narrowband: detectUtterances: censor Speech: farField: secure OfflineOnly: shouldStore AudioOnDevice: continuousListening: shouldHandleCapitalization:isSpeechAPIRequest: maximumRecognition Duration: endpointStart: inputOrigin: location: jitGrammar: deliver Eager Package: disable Delivering Asr Features: enable EmojiRecognition: enableAutoPunctuation: enable Voice Commands: sharedUserInfos: prefixText:postfixText: selectedText: powerContext: recognitionStart: startSpeech RecognitionWithParameters: didStartHandlerWithInfo: addAudioPacket:_scheduleRecording Transaction Release Timer finishAudio_releaseRecording TransactionIfNeededWithToken: writeDESRecord_ handleShould AcceptEager ResultWithRequestId: rcId: duration: should Accept: featuresToLog:isReceived Time Interval: matchCurrentTime Interval:_ enforceEndpointHintWithRequestId: rcId: shouldAccept: featuresToLog:isFinal_getFirstTokenSilenceStartTimeFromSpeechPackage:_handleDid Recognized FinalSpeechPackage: requestId:metadata:_handleDidRecognizedSpeech Package For Eager RecognitionCandidate:requestId: rcId:metadata:_markTimeToFirstWordMetric_ getProcessedAudioDurationFromSpeech Package:_getUserSpeaking Ended Time From Speech Package: setEndpointerFeatureEoS: modelRootsetASR ModelRootDirectory: inputOrigin_ getAsrInputoriginFromContext:isRequestFromSpoken NotificationisiOSButtonPressrawRecognitionphrasesinterpretationssilenceStartTime endTimelocalSpeechRecognizer: didSelectRecognition ModelWithModelProperties: localSpeechRecognizer: didRecognizeTokens: localSpeechRecognizer: didProcessAudio Duration:localSpeechRecognizer: didRecognizeRawEager RecognitionCandidate:localSpeechRecognizer: didRecognize Package: LocalSpeechRecognizer: didCompletion RecognitionWithStatistics: error: LocalSpeechRecognizer: did Produce Endpoint FeaturesWithWordCount: trailingSilenceDuration: eosLikelihood: pauseCounts: silencePosterior: processedAudioDurationInMilliseconds: localSpeechRecognizer: didProduce LoggablePackage: LocalSpeechRecognizer: didRecognizeTokens: with Metadata:localSpeechRecognizer: fetchCurrentStatedidDetected Endpoint shouldStopProcess ASROnEndpointlocalSpeechRecognizerDeliverAudioDurationdetectedEndpointTime_
didRecognizePackage: withMetadata:localSpeechRecognizer: didRecognizeFinalResultCandidate Package:
setupRecognizerState For MagusAsrNodeLocalSpeechRecognizerQueuesetLocalSpeechRecognizerQueue: interactiveLocalSpeechRecognizersetInteractiveLocalSpeechRecognizer: presetLocalSpeechRecognizerset PresetLocalSpeechRecognizer:localSpeechRecognizerTaskStringsetLocalSpeechRecognizerTaskString: LocalSpeechRecognizerStatesetLocalSpeechRecognizerState: audioWaitingBuffersetAudioWaitingBuffer:setLocalSpeechRecognizerDeliverAudioDuration: languagesetLanguage: setRequestId: eager ResultIdsetEagerResultId: speechHasAcceptedResultCandidatesetSpeechHasAcceptedResultCandidate: speechRecognitionSettingsset Speech RecognitionSettings: shouldProcessAudioset Should ProcessAudio: asrResult DeliveryTransactionsetAsr ResultDeliveryTransaction: recording TokensetRecordingToken: voiceTriggerFireMachTimesetVoiceTriggerFireMachTime:isFileLoggingEnabledsetIsFileLoggingEnabled: endpointStart Time InSecsetEndpoint Start TimeInSec: audio SampleCountToSkipsetAudio Sample CountToSkip: setDid DetectedEndpoint: setDetectedEndpointTime: setShouldStop ProcessASROnEndpoint: LastEndpointHint Duration setLastEndpointHintDuration: lastEndpointHintRCIdsetLastEndpointHintRCId: LastEndpointEager ResultTimesetLastEndpointEagerResultTime: lastEndpointHintFeaturessetLastEndpointHintFeatures: endpoint Delay ReportersetEndpoint DelayReporter: recordingStartTimesetRecording StartTime: firstPartialResultTimesetFirstPartialResultTime: timeToSpeakFirstWordsetTimeToSpeakFirstWord:_ speechHasAcceptedResultCandidate_isFileLoggingEnabled_didDetectedEndpoint_should StopProcessASROnEndpoint_localSpeechRecognizerQueue_presetLocalSpeechRecognizer_ LocalSpeechRecognizerTaskString_localSpeechRecognizerState_audioWaitingBuffer_localSpeechRecognizerDeliverAudioDuration_language_requestId_eagerResultId_ speechRecognitionSettings_asrResult Delivery Transaction_recording Token_voiceTriggerFireMachTime_endpointStartTimeInSec_audioSampleCountToSkip_detectedEndpointTime_ lastEndpointHintDuration_LastEndpointHintRCId_lastEndpoint Eager ResultTime_endpoint DelayReporter_recordingStartTime_firstPartialResultTime_timeToSpeakFirstWordT@"NSObject<OS_dispatch_queue>", &,N,V_localSpeechRecognizerQueueT@"CoreEmbedded SpeechRecognizer", &,N,V_interactiveLocalSpeechRecognizerT@"CoreEmbedded SpeechRecognizer", &,N,V_presetLocalSpeechRecognizerT@"NSString", &,N,V_LocalSpeechRecognizerTaskStringTQ,N,V_LocalSpeechRecognizerStateT@"CSAudioProcessWaitingBuffer", &,N, V_audioWaitingBufferTd,N,V_LocalSpeechRecognizerDeliverAudioDurationTI,N,V_activeChannelT@"NSString", &,N,V_language T@"NSString", & ,N, V_requestIdTQ,N,V_eagerResultIdTc,N,V_speechHasAccepted ResultCandidate T@"LBLocalSpeechRecognition Settings", &,N,V_speechRecognition SettingsTc,N,V_ should Process AudioT@"CSOSTransaction", &,N,V_asrResult DeliveryTransactionT@"NSUUID", &,N,V_recording Token TQ,N,V_voice TriggerFireMach TimeTc,N,V_ isFileLoggingEnabledTd,N,V_endpointStartTimeInSecTQ,N,V_audioSampleCountToSkipTC,N,V_didDetectedEndpointTd,N,V_detectedEndpointTimeTc,N,V_ shouldStopProcessASROnEndpoint Td,N,V_lastEndpointHint DurationTq,N,V_lastEndpointHintRCIdTQ,N,V_LastEndpoint EagerResultTime T@"NSArray", &,N,V_ lastEndpointHintFeaturesT@"CSEndpointDelayReporter", &,N,V_endpoint DelayReporterTQ,N,V_recordingStartTime TQ,N,V_firstPartialResultTime Td,N,V_timeToSpeakFirstWordT@"NSObject<OS_dispatch_queue>",R,N,V_targetQueueT@"CSAtt SiriEndpointerNode", W, N, SregisterEndpointer Node:, V_endpointerNode T@"CSAtt SiriUresNode", W, N, SregisterUres Node:, V_ures NodesetSiriLanguageCode Darwin: _didReceiveLanguageCode Update:getLocalUrl_compatibilityVersionstringValue_version_ footprintassetForAssetType:resourcePath: configVersion:isPremium_notifyStopOpportune Speak With Delay:isOpportuneSpeak ListeningsetIsOpportuneSpeakListening:_ isOpportuneSpeakListening TC,N,V_isOpportune Speak Listening_fetchSystemUserActivityStatesystemUserActivityNotificationTokensetSystemUserActivityNotificationToken: UserActivityStatussetUserActivityStatus: workQueuesetWorkQueue:_systemUserActivityNotificationToken_userActivityStatus_workQueueTi,N,V_ systemUserActivity NotificationTokenTq,N,V_userActivityStatusT@"NSObject<OS_dispatch_queue>", &,N,V_workQueue_hasPending ActivationForType:_isVoiceTriggerEvent: delegatessetDelegates: pendingActivationEventsetPendingActivationEvent: pendingCompletionset PendingCompletion: _delegates_pending ActivationEvent_pendingCompletionT@"NSMapTable", &,N,V_delegatesT@"CSActivationEvent", &,N,V_pendingActivationEventT@?,C,N,V_pending CompletionlpcmInt16NarrowBand ASBDopusNarrowBandASBD_ configureAudioConverter:_convertBuffered LPCM: allowPartial: timestamp: arrival TimestampToAudio Recorder: replaceBytesInRange:withBytes: Length: narrowBandOpusConverter_ opusConverter_buffered LPCM_recordBasePacketsPerSecond_opusOutASBD_convertPacketCount_convertAudioCapacity_lastTimestamp_lastArrivalTimestamp ToAudio Recorder_ outPacketSizeInSecT@"<CSAudioConverterDelegate>", W, V_delegateadBlocker Asset DecoderWith Version:_isSecond Chance Run_firstPassTrigger Info_rejection MHUUIDTQ,R,N,V_ firstPassSourceT@"NSString",R,N,V_audioProviderUUIDT@"NSDictionary",R,N,V_firstPassTrigger InfoT@"NSUUID",R,N,V_rejection MHUUIDTC,R,N,V_isSecond ChanceRunT@"CSVoiceTriggerFirstPassMetrics",R,N, V_firstpassMetricsmainRunLooprun_ addSelfTriggerDetectorEnabledConditionsself TriggerEnabled Policy MacsetSelfTriggerEnabled PolicyMac: _selfTriggerEnabled PolicyMacT@"CSPolicy", &,N,V_ selfTriggerEnabled PolicyMac_checkCanUseVoiceTriggerDuringCallEnabledcanUseVoiceTriggerDuring Phone Call_didReceiveCan Use Voice Trigger During CallSettingChangedInQueue: _voiceTriggerDuringCallEnabled DidChange_isEnabledcontainsValueForKey: base64 EncodedStringWithOptions: substringToIndex:initWithHash:locale: modelLocalemodelHashdigestsignaturecertificate_modelData_modelLocale_modelHash_digest_signature_certificateT@"NSData",R,N,V_modelDataT@"NSString",R,N,V_ modelLocaleT@"NSString",R,N,V_modelHashT@"NSData",R,N,V_digestT@"NSData",R,N,V_signature T@"NSData",R,N,V_certificate_notifyStopCommandControl_ isCommandControlStreaming_didReceive NewVoiceTriggerAssetMetaDatanotifyNewVoice TriggerAssetMetaDataUpdated_ startObservingSpeech DetectionVADPresence handleSpeech DetectionVADPresent Change:setPrimaryStream: primaryStream_primaryStreamT@"CSAudioStream",W,N,V_ primaryStreamshadowMicScore ThresholdhearstNumberOfBytesPerChunkhearstNumberOfSamplesPerChunkprocessAudioBytes: with NumberOfSamples: shadowMicScoreCreatorsetShadowMicScoreCreator: dataBufferNDEAPIsetDataBuffer NDEAPI: dataBufferPositionNDEAPIsetDataBuffer PositionNDEAPI:
:
hasReceivedEarly DetectNDEAPIResultsetHas Received Early DetectNDEAPIResult:_has ReceivedEarly DetectNDEAPIResult_shadowMicScoreThreshold ForVAD_shadowMicScoreCreator_ dataBufferNDEAPI_dataBufferPositionNDEAPIT@"CSShadowMicScoreCreator", &,N,V_shadowMicScoreCreatorT@"NSMutableData", &,N,V_dataBufferNDEAPITQ, N,V_ dataBufferPosition NDEAPITC,N,V_hasReceived EarlyDetectNDEAPIResultT@"<CSPhraseNDEAPIScorerDelegate>",W,N,V_delegateTf,R,N,V_shadowMicScore ThresholdForVAD_ handleDidStartRecording Message:_handle TwoShot Detected Message: submitRemoteCoreSpeech Issue Report: context: initWithQueue: IsRemote Recording: setDevice:_ isRemoteRecording T@"OS_remote_device", &,N,V_deviceT@"<CSRemoteRecordClientDelegate>",W,N,V_delegateTQ,R,N, V_audioStreamHandleId_ setMaximumBufferSizeFromInUseServices createAudioFileWriter ForAdBlockerWithInputFormat: outputFormat: with Accessory ID: copyBufferWithNumSamplesCopiedIn: isAdBlocker AudioLoggingEnabledstartWithUUID: with MaximumBufferSize: stopWithUUID: audioLoggingBufferset Audio LoggingBuffer: inUseServicesset InUseServices: currentMaximumBufferSizesetCurrentMaximumBufferSize:_currentMaximumBufferSize_audioLoggingBuffer_inUseServices T@"CSAudioCircular Buffer", &,N,V_audioLoggingBufferT@"NSMutableDictionary", &,N,V_inUseServicesTf,N,V_currentMaximumBufferSize%s invalid remote device %s observer doesn't conform to either V1 or V2 protocol%s Cancelling remote connection%s Cancelling remote device%s Dealloc of CSRemoteControlClient, it should close connection%s %s Connected to unexpected device type : %lu (expected type: %lu) %s Service: %{public}s not found %s Device connection waiting %{public}.3f seconds timed out %s Device is connected but RemoteXPC service is not connected %s cannot handle server event since event is nil%s remote XPC connection get failed %s Ignore unknown type message%s connection disconnected%s connection error: %{public}s%s XPC command recevied %{public} @%s RequestVoiceTriggerAssetDownload config Version %{public}@, languageCode %{public}@%s Attempt to send message while connection does not exist%s File does not exists: %{public}@%s Transfer of file %{public}@ failed %{public}d %s Transfer of file %{public} @succeed %s Failed to create xpc file transfer %s attempt to send message while connection does not exsit%s ERR: speaker Profile passed is nil Bailing out%s Speaker model file %{public}@ is being transmited to %{public}@%s ERR: Speaker model transmission timed out%s ERR: %{public} @%s Voice Trigger asset file transmission timed out%s Cannot transfer VoiceTrigger asset %{public}@%s set enable %{public}d %s Interstitial file transmission timed out %s xpcObject key or value is NULL%s LanguageCode: %{public}@%s Exchange protocol info with host info: %{public}@%s Invalid host ProtocolInfo%s Failed to fetch accessory protocol info, fallback to default info%s Fetched accessory device info: %{public}@%s Wrong reply type received %s Sending training data from %{public}@ to remote%s ERR: training data transfer timed out %s Failed to create remote voice profile%s splitterState: %{public}lu, should DisableSpeaker Verification: %{public}@%s ERR: Failed to fetch audio data from %{public}@%s setting remote SelfTrigger enable %{public}d %s Metric Providing Request Message has arrived %{public}lld%s Unexpected XPC Metric providing request: %{public}lld %s audioMetric = %{public}@%s audioMetric Provider not existing %s Mobile Timer is not available on this platform.%s Start monitoring VoiceTriggerAsset Download %s Stop monitoring: VoiceTriggerAsset Download %s New Voice Trigger is now installed %s Dealloc CSAudioInjectionEngine: %@%s Failed to create NDAPI%s Received active route change notification%s Start monitoring AudioRouteChangeMonitor %s Stop monitoring : AudioRouteChangeMonitor %s Notifying Hearst Routed State: %{public}d %s Notifying Siri Input Source Out Of Band State: %{public}d %s notification = %{public}@%s SmartSiriVolume cannot be resumed since we should not monitor audio%s Failure disposing audio file %{public}d %s Audio file already configured, closing first%s Creating audio file at URL %{public}@%s Failed creating audio file at url %{public}@ %{public}d %s Error setting input format %{public}d%s No audio file to append data%s Failed writing audio file %{public}d %s Closing file at URL %{public}@, audio size: %{public}u%s Couldn't create CoreSpeech log directory at path %{public}@ %{public}@%s SmartSiriVolumeContextAware TTS volume post lower and upper bounds is: %f%s TTS volume offset post lower and upper bounds is: %{public}f%s Start monitoring Siri setting switch, Siri is %{public}@%s Stop monitoring : Siri setting switch%s Siri Enabled = %{public}@%s _bestStartDetectSample %lu was greater than bestEarly DetectSample %lu or _best End DetectSample %lu%s _bestEarly DetectSample %lu was greater than bestEndDetect Sample %lu%s _speech Voice Level %lu is 0%s _numberOfTotalFramesETFT %lu is 0%s Using high priority queues for remora second pass%s CSRemoraFirstPass Request is deallocated %s First pass signal estimate for device %{private}@: %{private}@%s Cannot handle remora Voice Trigger request since VoiceTrigger is disabled %s We already have matched Remora second pass request : %{public}@%s Remora second pass request is prune out from PreMyriad %{public}@, error: %{public}@%s There is no matched remora second pass request, creating new one %{public}@%s Failed to create voice Trigger SecondPass remora since asset is nil : %@%s accessory id %{private}@, ascore: %{private}f (raw = %{private}f, bump=% {private}f)%s Pre-Myriad is cancelling activation on device %{private}@ (activation goodness score: %f (deviceId: %{private}@), competing goodness score: %f (deviceId: %{private}@)) %s Siri Client (Remora: accessoryId: %{private}@) start listening now, CSVoiceTriggerFirstPass Remora can stop listening now%s Audio provider available %s Failed to fetch audio audio provider with error: %{public}@%s %@%s Teardown remora second pass request for device id %{public}@%s SecondPass Result, %{public}d, %{public}@, %{public}@, %{public}@%s Voice Trigger SecondPass has failed %{public}@%s Voice Trigger SecondPass has been marked for cancellation.%s Cancelling audio stream hold for accessory: %{private}@%s Trying to cancel all 2nd pass in Remora%s Invalid device UUIDString%s Failed to fetch property of %{public}@ from device UUID %{public}@%s Failed to fetch deviceUID %s Add (%{public}@, %{public}@) pair into mapping table %s Invalid deviceUID%s Found (%{public}@, %{public}@) pair in mapping table %s Did not find deviceUID (%{public}@) in mapping table%s Primary device UUID: %{public}@, input device UUID: % {public}@%s Invalid deviceUUID %s Return existing simple UID (%{public}@) %s Can't find corresponding deviceUID from UUID, return existing UUID instead %s Testing: Add (%{public}@, %{public}@) pair into mapping table%s Cannot find voicetrigger asset from asset manager, let's fallback to asset in the framework%s CSDarwinVoiceTriggerHandler dealloc%s Voice Trigger start policy changed: %{public} @%s CSDarwinVTHandler [%{public}@]: Creating VoiceTrigger enable retry timer%s CSDarwinVTHandler [%{public}@]: %s CSDarwinVT Handler [%{public}@]: Cannot access masterport%s CSDarwin VTHandler [%{public}@]: IOPMConnectionSet Notification failed: % {public}d %s CSDarwinVTHandler [%{public}@]: IOPMConnectionCreate failed: %{public}d %s CSDarwinVT Handler [%{public}@]: Register power notification succeed%s CSDarwinVTHandler [%{public}@]: Activation session%s CSDarwinVTHandler [%{public}@]: Deactivation session%s CSDarwinVTHandler [%{public}@]: Prewarming complete: %d on early wake with error %@%s CSDarwinVTHandler [%{public}@]: Invalid darwin device %s CSDarwinVTHandler [%{public}@]: Connecting to remote corespeechd failed%s CSDarwinVTHandler [%{public}@]: Connected remote corespeechd successfully%s CSDarwinVTHandler [%{public}@]: darwin client: %{public}@%s CSDarwinVT Handler [%{public} @]: Skip handling Darwin connected event since user session is inactive%s CSDarwinVTHandler [%{public}@]: It try to disconnect remote corespeechd connection even though it does not exist%s CSDarwinVTHandler [%{public}@]: Report darwin device (%{public}@) disconnected %s CSDarwinVTHandler [%{public} @]IOPMAssertionDeclare NotificationEvent succeed with remoteClient: %{public}@%s CSDarwinVTHandler [%{public}@]: IOPMAssertionSet Property failed: %{public}d%s CSDarwinVTHandler [%{public}@]: IOPMAssertion Declare NotificationEvent failed (Not Privileged): %{public}d %s CSDarwinVTHandler [%{public}@]: IOPM AssertionDeclare NotificationEvent failed (Not Ready): %{public}d %s CSDarwinVT Handler [%{public}@]: IOPMAssertion Declare NotificationEvent failed: %{public}d%s CSDarwinVTHandler [%{public}@]: Voice Trigger token returned NO%s CSDarwinVT Handler [%{public}@]: Does not get power assertion since user session is deactivated%s CSDarwinVTHandler [%{public}@]: Not the primary remote device, ignore%s CSDarwinVTHandler [%{public}@]: Received VoiceTrigger token with remoteClient: %{public}@ (deviceUID %{public} @) %s CSDarwinVTHandler [%{public}@]: isVoiceTriggerFromFullWake = %{public}d%s CSDarwinVTHandler [%{public}@]: Does not wake Siri%s CSDarwinVTHandler [%{public}@]: Does not wake Siri since user session is not activated %s CSDarwinVTHandler [%{public}@]: Successfully write Myriad hash%s CSDarwinVTHandler [%{public}@]: Cannot write Myriad hash into file%s CSDarwinVTHandler [%{public}@]: Myriad hash is nil%s CSDarwinVTHandler [%{public}@]: remoteClient : %{public}@%s CSDarwinVTHandler [%{public}@]: Posted siri audio hash notification%s CSDarwinVTHandler [%{public}@]: Does not advert self trigger since user session is not activated %s CSDarwinVTHandler [%{public}@]: Ignore request since user session is inactive%s CSDarwinVTHandler [%{public}@]: Mismatched language code between host (%{public}@) and remote (%{public} @) %s CSDarwinVTHandler [%{public}@]: Unspecified configVersion, abort downloading request%s CSDarwinVTHandler [%{public}@]: New asset detected, transfering to %{public}@%s CSDarwinVTHandler [%{public}@]: Sleep manager is unavailable.%s CSDarwinVTHandler [%{public}@]: Setting PreventSystemSleep timer for %f seconds%s voice trigger enabled: %d, is user session active?: %d %s System User Activity State %ld %s CSDarwinVTHandler [%{public}@]:user session is not active on macOS, should stop this timer %s CSDarwinVTHandler [%{public}@]: VoiceTrigger is disabled on macOS, should stop this timer %s CSDarwinVTHandler [% {public}@]: Voice Trigger from macOS was enabled but it wasn't in darwinOS, try to enable now%s CSDarwinVTHandler [%{public}@]: VoiceTrigger on both are enabled, we should stop this timer %s CSDarwin VT Handler [%{public}@]: Error while getting Voice Trigger enabled value from darwin OS%s CSDarwinVT Handler [%{public}@]: Skip transfer since user session became inactive %s CSDarwinVTHandler [%{public}@]: ERR: No Speaker Profile, remote VoiceTrigger %{public}@ will be turned on without PHS%s CSDarwinVTHandler [%{public}@]: ERR: cannot find AES key, remote Voice Trigger %{public}@ will be turned on without PHS%s CSDarwinVTHandler [%{public}@]: Failed to transfer explicit training utterances : %{public}@%s CSDarwinVT Handler [%{public}@]: Does not enable remote Voice Trigger since user session is deactivated%s CSDarwinVTHandler [%{public}@]: Successfully disable remote Voice Trigger %s CSDarwinVTHandler [%{public}@]: Cannot disable remote Voice Trigger%s Disable Voice Trigger in Darwin timed-out!! %s CSDarwinVTHandler [%{public}@]: Download new asset%s CSDarwinVT Handler [%{public}@]: LanguageCode changed to: %{public}@%s CSDarwinVTHandler [%{public}@]: Screen is locked.Cannot handle AssetChange.Delaying until after screen is unlocked %s CSDarwinVTHandler [%{public}@]: Screen is unlocked.Can handle AssetChange%s CSDarwinVT Handler [%{public}@]: Performing _safeAssetChangeHandler %s CSDarwinVTHandler [%{public}@]: Screen Unlocked.Performing deferred AssetChangehandling%s IOPMISAEarlyWake%s IOPMISAUserWake%s IOPMISASleep%s IOPMISADarkWake%s IOPMConnectionAcknowledge Event failed %{public}d%s Failed to fetch speaker state muted info, error: %{public}@%s Queried built-in speaker mute state as %{public}@%s Timed-out for fetching speaker state muted info, setting isMuted = YES%s Failed to fetch builtIn speaker active state, error: %{public}@%s Queried built-in speaker state as %{public}@active%s Timed-out for fetching speaker state active info, setting speakerStateActive = NO%s Speaker state changed %{public}@%s Failed to get speaker state from AVVC, default to inactive%s Speaker mute state changed: %{public}@%s Failed to enable speakerStateListening: %{public}@%s Start monitoring Speaker state from AVVC%s Failed to disable speaker State Listening: %{public}@%s Stop monitoring Speaker state from AVVC%s Start monitoring Siri language code%s Stop monitoring Siri language code%s Siri language changed to %{public}@%s Ignore notifying change of language code, since it is nil%s Failed to create AVVC %{public}@%s Create new CSAudioRecorder = %{public}p%s Tear down _remoteRecordClient if needed%s CSAudioRecorder %{public}p deallocated %s AVVC initialization failed %s Successfully create AVVC %{public}p%s Setting announced call flag to: %d with stream handle Id: %lu%s Calling AVVC setContext: %@%s Failed to get handle id %{public}@%s Replace streamId to CSAudioStreamHandle ID_Bridge since it is going to use bridge %s setContext elapsed time = %{public}lf, streamHandleId = %{public}lu, streamType = % {public}lu%s Calling AVVC setContextForStream: %{public}@%s Tried to setCurrentContext with mode %ld.This method can only be used for auto and post%s
setCurrentContext elapsed time = %{public}lf%s Remote device with device id: %{private}@ not found %s Failed to prepare remote device: %{public}@%s Calling AVVC prepareRecordForStream (%{public}llu): %{public}@%s AVVC prepareRecordForStream failed %{public} @%s prepareRecordForStream elapsed time = %{public}lf%s ::: CSAudioRecord will inject audio file instead of recording %s Resetting AudioFilePath Index %s Increase AudioFilePath Index = %d %s AudioFilePathIndex is out-of- boundary audioFilePath Index: %d injectAudioFilePaths: %d %s AudioFilePathIndex: %d accessing: %@%s Unable to find injectAudioFilePath = %@%s Asking startRecording to remote device with context: %{public}@ (original context: %{public}@)%s Failed to fetch valid context%s Failed to startRecording: %{public}@%s startRecordingWithOptions elapsed time = %{public}lf%s Calling AVVC startRecordForStream %{public}@%s startRecordForStream failed %{public}@%s startRecordForStream elapsed time = %{public}lf%s Failed to stopRecording to remoteRecordClient: %{public}@%s stop Recording elapsed time = %{public}lf%s Calling AVVC stopRecordForStream%s Failed to stop RecordForStream: %{public}@%s stopRecordForStream elapsed time = %{public}lf%s Session State = %d %s AudioSessionState = YES%s AudioSessionState = NO%s fetch recordDeviceInfo elapsed time = %{public}lf%s AVVC sampling rate = %{public}f%s AVVC doesn't return sampleRate, assume it is default sample rate %s isNarrowBand = NO for streamHandleId = %{public}lu%s (darwinOS) is NarrowBand = NO for streamHandleId = %{public}lu %s is NarrowBand = % {public}@ for streamHandleId = %{public}lu %s Calling AVVC setSession Active for Prewarm%s Calling AVVC setRecord Mode to mode: %{public}d %s AVVC successfully setRecordMode%s setRecord Mode elapsed time = %{public}lf%s Calling AVVC setSessionActivate for activation with streamId(%{public}lu) %s AVVC successfully activated audioSession%s setSession Activate elapsed time = %{public}lf%s Calling AVVC setSessionActivate for deactivation: %{public}tu%s Calling AVVC setSessionActivate for deactivation for stream %d: %{public}tu %s Calling AVVC setDuckOthersForStream (%d) for DuckOthers/MixWithOthers%s Failed to setDuckOthersForStream %{public} @%s setDuckOthersForStream elapsed time = %{public}lf%s enable MiniDucking elapsed time = %{public}lf %s %{public}@%s Failed to configureAlert Behavior ForStream : % {public}@%s configureAlert Behavior elapsed time = %{public}lf%s VoiceTriggerInfo is nil from AVVC%s Updated languageCode to: %{public}@ in VTEI received from remote%s isLocalDevice failed %{public}@%s AVVCAudioBuffer contains %{public}d packet descriptions, size %{public}d, channels %{public}d.Ignoring %s packets count %{public}d %s Peak: %f, Avg %f%s Bad packet length %{public}d.Skipping rest of record buffer.%s Cannot handle audio buffer unexpected format (%{public} u)%s Compensating %{public}u channel(s), heartbeat = %{public}lld%s Audio record route is %{private}@ for stream id %{private}lu%s Calling AVVC playAlertSoundForType to play alert%s Ignore playing endpoint beep (record stopped beep) since it already played beep in gibraltar %s Calling AVVC playAlertSoundsForType: %{public}ld %s Unsupported SPI has been called alertStartTime%s Received didStart Recording: %{public}p, forStream: %{public}llu, successfully: %{public}d, error: %{public}@%s Received audio buffer %{public}d, heartbeat = %{public}llu, streamID (%{public}lu) %s Received didStop Recording: % {public}p for Stream: %{public}llu forReason: %{public}ld%s Received Stream Invalidated %{public}llu%s to Configuration %{public}d %s type: %{public}d, error : % {public}@%s Encoder error: %{public}@%s AVVC lost mediaserverd connection%s AVVC informed mediaserverd reset, no further action required %s Recording not started yet, cache the twoShot notification, token: %{public}llu%s hasLocalPending Two Shot = %{public}d, token: %{public}llu%s Unsupported audio format! %s Existing remoteRecordClient (deviceId = % @) doesn't match required one (deviceId = %@), create new remoteRecordClient%s The input streamHandleId (%{public}lu) is not expected (%{public}lu) %s Start monitoring: CSDefaultInputAudioRouteChangeMonitor Mac%s Stop monitoring CSDefaultInputAudio RouteChangeMonitorMac%s Error retrieving property name (OSStatus = %{public}d) %s AudioDevice doesn't have transport Property%s Error retrieving property transport type (OSStatus = %{public}d) %s AudioDevice doesn't have DataSource Property %s Error retrieving data source id (OSStatus = %{public}d%s Error retrieving input routing list size (OSStatus = % {public}d)%s Error retrieving input routing data (OSStatus = %{public}d)%s Default Input Device: %{public}@ isBuiltInMic: %{public}d %s Error retrieving output routing list size (OSStatus = %{public}d) %s Error retrieving output routing data (OSStatus = %{public}d) %s Default output Device: %{public}@ transport type: % {public}c dataSourceId: %{public}c is Built In Speaker: %{public}d %s Send a In-Ear Myriad notification%s Using audio InjectionProvider as recorder%s SelfTrigger start policy changed %{public}@%s Creating Voice Trigger enable retry timer %s Cannot access masterport%s IOPMConnection Set Notification failed %{public}d%s IOPMConnectionCreate failed %{public}d %s Register power notification succeed %s Activation session%s Deactivation session %s Connecting to remote corespeechd failed %s It try to disconnect remote corespeechd connection even though it does not exist%s Wake reason: %@%s SleepType: %d %s IOPMAssertion DeclareNotificationEvent succeed %s IOPMAssertionSetProperty failed: %{public}d%s IOPMAssertion Declare NotificationEvent failed (Not Privileged) : % {public}d%s IOPM AssertionDeclare NotificationEvent failed (Not Ready) : %{public}d %s IOPMAssertion Declare NotificationEvent failed %{public}d%s Wake reason is not VoiceTrigger or it woke from S3%s Does not get power assertion since user session is deactivated %s Voice Trigger token returned NO%s Received VoiceTrigger token%s isVoice TriggerFromFullWake = %{public}d %s Does not wake Siri %s Does not wake Siri since user session is not activated %s Invoked Siri Client %s Cannot invoke Siri client: %{public}@%s Successfully write Myriad hash%s Cannot write Myriad hash into file%s Myriad hash is nil%s Posted siri audio hash notification%s Does not advert self trigger since user session is not activated %s enable %{public}@, force %{public}@%s Ignore sending remote SelfTrigger enable request since user session is deactivated %s Failed to set SelfTrigger enabled, error: %{public}@%s user session is not active on macOS, should stop this timer%s VoiceTrigger is disabled on macOS, should stop this timer %s Voice Trigger from macOS was enabled but it wasn't in bridgeOS, try to enable now%s Voice Trigger on both are enabled, we should stop this timer%s Error while getting VoiceTrigger enabled value from bridgeOS%s ERR: Failed SSR voice profile migration with error % {public}@%s ERR: No Speaker Profile, we cannot turn on Voice Trigger!!!!!! %s Retrain failed with %{public}@, we cannot turn on VoiceTrigger!!!!!!%s Successfully finished retraining on %{public}@ in %{public}@%s Does not enable remote Voice Trigger since user session is deactivated %s ERR: No voice profile - Bailing out%s ERR: no asset found - Bailing out%s Failed to enable remote Voice Trigger%s Failed to transfer VoiceTrigger assets: %{public}@, turn-off selfTrigger%s Successfully disable remote Voice Trigger%s Cannot disable remote Voice Trigger%s Download new asset%s LanguageCode changed to: %{public}@%s Screen is locked.Cannot handle AssetChange.Delaying until after screen is unlocked %s Screen is unlocked.Can handle Asset Change%s Performing safeAssetChangeHandler %s Screen Unlocked.Performing deferred AssetChangehandling%s Attentive Siri not supported on device%s Endpointer xpc connection started listening%s LocalSpeechRecognition xpc connection started listening %s AttSiriServiceListener xpc connection started listening: _attSiriSvc Listener=%@%s SSR xpc connection started listening%s RC Processing xpc connection started listening %s Notifying CoreSpeechDaemon Launched %s Start monitoring corespeechd state%s Cannot start monitoring corespeechd state because it was already started %s Stop monitoring corespeechd state %s CoreSpeechDaemon state changed to %{public}u%s CSHearst SecondPassRequest is deallocated%s asset is nil, stop initialization%s Ignore %{public}@ since VoiceTrigger was turned off%s Ignore %{public}@ since Siri client is currently in a
ringtone and does not support A2DP%s Ignore %{public}@ since Siri client is currently in a connected call %s Ignore %{public}@ since Siri client is currently in an outgoing call %s Ignore %{public}@ since there is an other non eligible app recording %s Ignore %{public}@ since Siri client is current listening %s We already have matched hearst second pass request: %{public}@%s There is no matched hearst second pass request, creating new one : %{public}@%s deviceID = %{public}@, RemoteMicVADScore = %{public}f, Threshold = %{public}f%s RemoteMicVAD event will be ignored since firstPassSource: Hearst, device id does not match%s Siri Client start listening now, CSVoiceTriggerFirstPassHearst can stop listening now%s Handle Remote Mic VAD Event: remoteMicVADScore is %{public}f, remoteMic VADThreshold is %{public}f, remoteMicVADMyriad Threshold is %{public}f%s Remote VAD Score overwritten to %{public}f%s Audio stream started %s Failed to start audio stream error %{public}@%s Teardown hearst second pass request for device id %{public}@%s Ignoring boron based decision making as triggered phrase %@%s remoteMicVADScore: %{public}f, remoteMicVADThreshold %{public}f, triggerEnd Seconds: %{public}f, minPhraseLength: %{public}f shadowMic Score: %{public}f shadowMicScoreThreshold: %{public}f%s Using triggerEndSeconds to determine rejection: %{public}f%s Trigger is rejected since remoteMicVADScore is %{public}f, remoteMicVADThreshold is %{public}f, triggerEndSeconds is %{public}f, minPhraseLength is %{public}f%s Failed to get audio stream: %{public}@%s Getting audio stream provider has failed %{public}@%s ContinousAudioFingerprint cannot be resumed since we should not monitor audio%s SmartSiriVolume cannot be resumed because Siri is not enabled %s Audio steam %{public}@ is still streaming when we get new stream Provider %s CSAudioStreamProviding Proxy has received xpc disconnection%s Trying to stop audio stream on CSAudioStream Providing Proxy%s Unknown body type: %{public}lld%s Cannot handle setCurrentContext throught XPC : audioStreamProviding is nil%s Cannot handle setCurrentContext throught XPC given context is nil%s Cannot handle AudioStreamRequest throught XPC given audioStreamRequest is nil%s Cannot handle AudioStreamRequest throught XPC audioStreamProviding is nil%s Getting audio stream has failed %{public}@%s Cannot handle PrepareRequest throught XPC audioStream Providing is nil%s Given audioStreamRequest is nil, use default audioStreamRequest%s Cannot handle startAudioStream given audio stream option is nil%s Cannot handle startAudioStream: audioStream is nil%s Cannot handle startAudioStream: audioStreamProviding is nil%s Cannot handle stopAudioStream: audioStreamProviding is nil%s Cannot handle stopAudioStream: audioStream is nil%s Fail to parse recordContext%s Cannot handle IsRecording audioStreamProviding is nil%s Cannot handle RecordRoute: audioStream Providing is nil%s Cannot handle RecordDeviceInfo: audioStreamProviding is nil%s Cannot handle Audio DeviceInfo: audioStreamProviding is nil%s Cannot handle RecordSettings audioStream Providing is nil%s Cannot handle IsNarrowband : audioStreamProviding is nil%s Cannot handle PlaybackRoute: audioStreamProviding is nil%s CSAudioStreamProviding Proxy%s Proxy received two-shot detected at % {public}lf%s Using override asset: %@%s Updated cache with new Trial asset %@%s Ignore MA asset update%s Ignore Trial asset update for type: %lu%s Setting mixable to yes as we are in an active call %s ::: incrementing false wakeup to %{public}llu%s Power Log HeySiriFalse Trigger numFalse Wake Up: %{public}d, secondsSince LastReport: %{public}lf, phrase: %{public}@%s ::: accumulated false wakeup count is %{public}llu so far, not reporting yet because it has been only % {public}.2f seconds since last report with current phrases %{public}@%s Sending event with non determenistic triggerLengthSampleCount %llu, triggerLength SampleCount DetermenisticFromFirstPass %llu, and delta of %lld samples%s Not implemented%s audioStreamProvider is nil, fetch audioProvider from context%s attSiriAudioStreamProvider is nil!%s Failed to start audio data source: %{public}@%s Unsupported receiver: %@%s CSAttSiriAttending AudioSrcNode deallocated %s CSVoiceTriggerSecondPass [%{public}@]: initialized with PHS: %d %s CSVoiceTriggerSecondPass [%{public}@]: deallocated %s CSVoiceTriggerSecondPass [% {public}@]: asset is nil, stop initialization%s CSVoiceTriggerSecondPass [%{public}@]: Failed to get language code!!! %s CSVoiceTriggerSecondPass [%{public}@]: ERR: Failed to retrieve voice profiles for %{public}@%s CSVoiceTriggerSecondPass [%{public}@]: ERR: More than one Siri voice profile present for %{public} @- %{public}@, trigger cleanup%s Found speaker recognition asset: %@%s CSVoiceTriggerSecondPass [%{public}@]: Falling back to VT-assets%s CSVoiceTriggerSecondPass [%{public} @]: Failed to create SSR context with error %@%s CSVoiceTriggerSecondPass [%{public}@]: Failed to create SSR controller with error %@%s CSVoiceTriggerSecondPass [% {public}@]: Not creating SAT objects: use PHS %{public}d, shouldSkipRegular PHS %{public}d%s CSVoiceTriggerSecondPass [%{public}@]: Clearing VoiceTrigger candidate in the second pass%s CSVoiceTriggerSecondPass [%{public}@]: DeviceID: %@, audio ProviderUUID: %@%s CSVoiceTriggerSecondPass [%{public}@]: Start audio stream with request%s CSVoiceTriggerSecondPass [%{public}@]: Has received audio stream: %{public}@%s CSVoiceTriggerSecondPass [%{public}@]: Failed to get audio stream: % {public}@%s CSVoiceTriggerSecondPass [%{public}@]: Getting audio stream provider has failed: %{public}@%s CSVoiceTriggerSecondPass [%{public}@]: Received first pass triggered in channel: %{public}tu with trigger start: %{public}tu %s CSVoiceTriggerSecondPass [%{public}@]: Second pass timeout (%{public}.2fs) should not exceed the ring buffer size, set to ring buffer size%s CSVoiceTriggerSecondPass [%{public}@]: Second pass set to analyze %{public}tu samples (%{public}.2fs) from %{public}tu to %{public}tu%s CSVoiceTriggerSecondPass [%{public}@]: Expecting first pass source as Hearst%s CSVoiceTrigger SecondPass [%{public}@]: Setting second pass timeout for hearst %{public}d%s CSVoiceTriggerSecondPass [%{public}@]: Expecting first pass source as Remora%s current host:%llu delta: %f estimatedStartHostTime: %llu%s CSVoiceTriggerSecondPass [%{public}@]: Expecting first pass source as Jarvis %s CSVoiceTriggerSecondPass [%{public}@]: Received first pass Jarvis triggered in channel: %{public}tu with trigger start: %{public}tu %s CSVoiceTriggerSecondPass [%{public}@]: Second pass set to analyze %{public}tu samples (%{public}.2fs) from %{public}tu to %{public}tu, with prepending samples %{public}tu, trailing samples %{public}tu%s CSVoiceTriggerSecondPass [%{public}@]: Cancel Voice Trigger second pass request has received %s There are nils in starting second pass with firstPass Source: %{public}lu firstPassInfo: %{public}@%s CSVoiceTriggerSecondPass [%{public}@]: Second pass generated mhUUID for rejections: %@%s CSVoiceTriggerSecondPass [%{public}@]: Sending early detect notification upon first pass trigger%s CSVoiceTriggerSecondPass [%{public}@]:AFSiriActivation Built In Mic Voice Trigger Prewarm failed: %{public}@%s CSVoiceTriggerSecondPass [%{public} @]:AFSiriActivationBuiltInMicVoiceTrigger Prewarm success%s CSVoiceTrigger SecondPass [%{public}@]: Use legacy early detection notification%s CSVoiceTriggerSecondPass [%{public}@]:AFSiriActivation Bluetooth Device Voice Trigger Prewarm failed: %{public}@%s CSVoiceTriggerSecondPass [%{public} @]:AFSiriActivationBluetooth Device VoiceTrigger Prewarm success%s CSVoiceTriggerSecondPass [%{public}@]: Finished prewarming Remora %{public}@, error: %{public}@%s CSVoiceTriggerSecondPass [%{public}@]: Unable to handle VoiceTrigger AOP first pass on this platform%s CSVoiceTriggerSecondPass [%{public}@]: Unable to handle VoiceTrigger first pass : %{public} @%s CSVoiceTriggerSecondPass [%{public}@]: Ignoring first pass trigger since we are already performing second pass on a trigger candidate %s CSVoiceTriggerSecondPass [%{public}@]: %s audioStream not existing %s CSVoiceTriggerSecondPass [% {public}@]: Could not find Assets.Cannot process Audio%s CSVoiceTriggerSecondPass [%{public}@]: second pass has made decision, skip processing %s CSVoiceTriggerSecondPass [%{public}@]: Stop feeding audio at sampleCount: % {public}tu%s nil second pass metrics instance%s Report as rejection since the detected phId is not the default%s CSVoiceTriggerSecondPass [%{public}@]: PHS Scores
=
%{public}d,
not available, ignoring for now !%s CSVoiceTriggerSecondPass [%{public}@]: Setting secondPassTimeout = %{public}d, Prepending Samples analyzer Trailing Samples = %{public}d %s CSVoiceTriggerSecondPass [%{public}@]: Marking SecondPassTrigger MachAbsolute Time: %llu%{public, signpost.description: begin_time}llu, %s %s%{public, signpost.description: end_time}llu, %s %s Voice TriggerLatency%s Reporting VT Latency: %lu%s CSVoiceTriggerSecondPass [%{public}@]: VT switch toggled: VoiceTrigger has been ACTIVE for an interval of %{public}5.3f seconds.%s CSVoiceTrigger SecondPass [% {public}@]:VT switch toggled: VoiceTrigger has been INACTIVE for an interval of %{public}5.3f seconds.%s CSVoiceTriggerSecondPass [%{public}@]: VoiceTrigger uptime/ downtime reset%s CSVoiceTriggerSecondPass [%{public}@]: Failed to get AOP trigger-time%s CSVoiceTriggerSecondPass [%{public}@]: Failed to get AOP trigger-length%s CSVoiceTriggerSecondPass [%{public}@]: Second pass timeout (%{public}.2fs) should not exceed the max size of %{public}.2fs, set to max size%s CSVoiceTriggerSecondPass [%{public}@]: Second pass set to analyze %{public}tu samples (%{public}.2fs) %s ERR: No known voice profile reported in %@%s CSVoiceTriggerSecondPass [% {public}@]: ERR: Failed to retrieve PHS score, letting trigger through - %{public}@%s Override PHS threshold to 0%s CSVoiceTriggerSecondPass [%{public}@]: PHS Accept: Score %{public}.3f (%{public}d, %{public}d), PSR = [%{public}.3f, %{public}.3f], SAT = [%{public}.3f, % {public}.3f] Threshold %{public}f
%s CSVoiceTriggerSecondPass [%{public}@]: PHS Reject: Score %{public}f (%{public}d, %{public}d) PSR = [%{public}.3f, %{public}.3f], SAT = [%{public}.3f, % {public}.3f] Threshold %{public}f
=
%s CSVoiceTriggerSecondPass [%{public}@]: Mediaserverd/bridgeaudiod recovered from crash%s Couldn't create voice trigger audio logging directory at path %{public}@ %{public}@%s CSVoiceTriggerSecondPass [%{public}@]: set StartAnalyzeSampleCount %{public}llu%s Schedule secondPassComplete WDT %{public}@ for %{public}lf seconds%s secondPass Complete WDT did fire: %{public}@, currentToken: %{public} @%s Secondpass didn't complete within %{public}lf seconds with token: %{public}@%s secondPassComplete WDT token doesn't match.Ignore this fire%s Clearing secondPassCompletion Watch DogTimer : %{public}@%s Resetting audio preprocessor : %{public} f, containsVoiceTrigger:%{public}d%s Flushing audio preprocessor%s Zero Filter Metrics: %{public}@%s Beep Canceller Metrics: %{public}@%s Cannot send nil message%s Unable to send message to client since there is no connection%s event = %{public}p client = %{public}p cannot handle event %s ignore unknown types of message%s message = %{public}p, client = %{public}p, cannot handle message%s Unexpected message type %{public}lld %s Cannot handle audio providing message%s Audio Providing Request Message has arrived %{public}lld %s Unable to handle audio providing switch message context is nil%s Setting XPCClientType to %{public} d%s Client %{public}p connection disconnected, noticing xpc listener%s Handing Ping Pong message%s Voice Trigger cannot be turned on since clamshell is closed %s VoiceTrigger cannot be turned on since VoiceTrigger is disabled %s VoiceTrigger cannot be turned on since Siri restricted on lock screen AND screen is locked%s VoiceTrigger cannot be turned on since current user doesn't activated %s Stop monitoring HomePod voice Trigger Assertion%s Notifying Wake Keyword Spoken Event%s Event Notifier received Voice Trigger event%s Notifying VoiceTrigger Trigger!!!!%s Activating Siri on Homekit accessory%s Jarvis VoiceTrigger result doesn't have trigger end mach time%s notifying built-in VT trigger by notify_post%s Darwin device connected, ignore Voicetrigger notification from built-in device%s splitterState = %{public}lu%s Hearst Routed, ignore Voicetrigger notification from other remote devices%s Darwin device connected, ignore trigger from Gibraltar machine%s Other non eligible app is recording, ignore trigger from Darwin device%s Notifying Gibraltar VoiceTrigger Trigger!!!! %s Notifying Darwin VoiceTrigger Trigger!!!!%s Unsupported trigger type: %{public}lu%s Current user doesn't have owner ship of AOP, it cannot enable AOP VoiceTrigger%s Updating VoiceTrigger Configuration %s Unable to send model to AOP since it failed to initialize NDEAPI%s Successfully validate model with NDEAPI%s Enabling VoiceTrigger in AOP %s Failed to enable AOP VoiceTrigger%s Failed to update AOP Voice Trigger configuration %s RTModel doesn't exist, fail to enable VoiceTrigger in AOP %s Current user doesn't have owner ship of AOP, it cannot disable AOP VoiceTrigger%s Disabling VoiceTrigger in AOP %s Failed to disable AOP VoiceTrigger%s Dealloc audioStreamHolding : % {public}@%s :: Error reading file %@, err: %d %s CSAudioFileReader requires prepare recording settings to feed audio%s CSAudioFileReader only support Linear PCM to feed%s Setting ExtAudioFileSetProperty failed: %d %s Starting audio file feed timer, bufferDuration = %f sampleRate %f, bytesPer Frame = %d, channelsPer Frame = %d %s: Error reading data from audio file: %d %s Reach to EOF, chunkSize = %d %s Stopping audio file feed timer %s Handler is already removed in the pool%s Dealloc CSAudioInjectionProvider: %@%s Stopping Audio Injection Provider: %@%s Calling start audio stream: %@%@%s Calling stop audio stream : %@%s Asset Manager cannot be turned on since isFirstUnlocked is NO%s Asset Manager cannot be turned on since network is not available %s CSVoiceTriggerXPCListener start listening%s Received new remote control connection request%s Connection request is nil%s Error = %{public}s %s Getting new client connection: %{public}p%s Client connection disconnected, removing %{public}p from client connection pool%s Voice Trigger enabled notification observed %s VoiceTrigger enabled = %{public}@%s Hour power timer fired %s Cannot create SampleRateConverter using AudioConverterNew: %{public}d %s Cannot set Quality property to audioConverter %s Cannot set Complexity property to audioConverter %s Override result as 'mpty '%s Audio resampling done %lu%s AudioConverter is sad: 0x%{public} xd %s Start monitoring Software update checking state%s Cannot start monitoring software update checking state because it was already started %s Stop monitoring Software update checking state%s Software update checking running: %{public}@%s Cannot create NSNumber if xpcObject is NULL%s XPC object type should be BOOL, DOUBLE, INT64, or UINT64%s Cannot create xpcObject if objcType is NULL%s Cannot create xpcObject since there is no matching type%s Invalid device with deviceId %{public}@%s Error retrieving routing list size (OSStatus = %{public}d) %s Error retrieving routing list data (OSStatus = %{public}d) %s Error retrieving transport type for deviceID %{public}lu (OSStatus = %{public}d) %s Device has transport type %{public}c%s Error retrieving data source id for deviceID %{public}lu (OSStatus = %{public}d) %s Gibraltar has built-in mic!%s Start monitoring screen lock/unlock state%s Stop monitoring screen lock/unlock state%s Screen Lock Status Changed %{public}@%s Cannot create NSData with size 0%s xpc object should be XPC_TYPE_DATA%s Celestial is not available on this platform.%s accessoryId %{private}@%s Start monitoring SRF user setting%s Stop monitoring SRF user setting %s notification = %@%s This call is not supported on darwinOS device (splitterState) %s Start monitoring : Wireless Splitter start%s Stop monitoring: Wireless Splitter %s VoiceTrigger is already %{public}@, received duplicated notification! %s Start monitring : Voice Trigger setting switch%s Cannot start monitoring VoiceTrigger setting switch because it was already started %s Stop monitring: VoiceTrigger setting switch%s Smart Siri Volume not supported on this platform Bailing out%s ERR: Failed to initialize Smart Siri Volume with sampling %{public}f and %{public}@%s AlarmState changed to %{public}d %s TimerState changed to %{public}d%s MusicVolume changed to %{public}f%s AlarmVolume changed to %{public} f%s Automatic Volume State changed to %{public}d%s Register CoreSpeech Services%s Received accept request: %{public}@%s Connectin request %{public}@ rejected due to missing entitlement%s we got unknown types of XPC connection request%s get test response.return string Test%s Setting Delay Interstitial Sound%s Get Trigger Count%s Clear Trigger Count%s Get FirstPass running mode%s Received Activation Event: %{public}@%s Cannot handle activation event: %{public}@%s activation client not exist%s Unsupported protocol for this device%s Providing voice TriggerEventInfo with deviceId %{public}@%s Providing built-in voiceTriggerEvent Info%s Timed-out for fetching voice Trigger Info%s TiggerInfoProviding is nil%s VoiceTrigger cannot be turned on since Voice Trigger is disabled on mac-mini connected to remote darwin device %s Listening on watch cannot be turned on since speech detection VAD is disabled %s Listening on watch cannot be turned on since Siri is disabled %s Listening on watch cannot be turned on since SpringBoard is not started %s Listening on watch cannot be turned on since device is not unlocked after restart %s Hey Siri is enabled.Checking if we are in a call.%s Hey Siri is disabled.Not checking if we are in a call.%s Listening on watch cannot be turned on since Siri assertion is disabled and or its not in a ringtone hfp state%s Listening on watch cannot be turned on since audioInjection is enabled %s Listening on watch cant be turned on because we are in a ringtone with A2DP, connected or outgoing call %s Replace deviceId (%{public}@) to nil for Voice Trigger from Gibraltar.%s CSHostDaemonMac did Launch %s Daemon WillShutdown?%s Register Kill Signal notification%s Received hang up signal%s Received termination signal%s mhUUID = %@, class = %@%s MHID not set, skipping SELF Logging%s Submit MHEndpointerAccessibleContextEvent to SELF for MH ID: %@%s Submit MHEndpoint DetectedEvent to SELF for MH ID: %@%s %{public}.2f ms after firstBufferStart%s Invalid timestamp (currentMachTime: %{public}llu timestamp: %{public}llu) %s Invalid timestamp (currentMach Time: %{public}llu arrival Timestamp: %{public}llu)%s numOfAudioPackets: %{public}lu, numOfValidTrailing Packets: %{public}lu, numOfValidTrailing SpeechPackets: %{public}lu,
trailingPktLatencies: %{public}@
trailing PktSpeech Latencies: %{public}@%s Submit MHEndpoint Latency InfoReportedEvent to SELF for MH ID: %@%s Received RC %lu with duration %f from server, make RC acceptance and mitigation decision %s should Accept = %d, is Mitigated = %d %s rcId: %lu%s Vault already exists and is NOT secure.Attempting to secure: %{public}@, notSecure: %{public}d %s Success setting up DataVault at: %{public}@%s Request to init device with deviceType: %ld, deviceName: %@, deviceId: %@, productId : %@%s Request inject audio %@ into device with UUID %@ and scale factor %f%s Audio url %@ is nil, or url not existing in path%s Can't find device with uuid %@%s Device speak audio with startTime = %llu, stopTime = %llu%s Request connect device with UUID %@%s input device uuid is nil%s Request disconnect device with UUID %@%s device UUID %@ not existing in deviceDictionary, already disconnected %s Request fetching primary input device %s Error fetching primary device! %s input dictionary is nil%s Initializing new xpc Connection%s Sending XPCClientType: %{public}d%s Prepare Audio Provider with Context: %{public}@%s Failed to get reply result correctly%s Received alertStartTime = %{public}llu%s Received peakPower = %{public}f%s Received average Power = %{public}f%s Sending audioMetric request%s Failed to get audioMetric reply%s audioMetric: %{public}@%s Received invalid audioMetric%s Error creating message%s audioStreamWithRequest for stream %{public} @%s xpcConnection not exist%s Invalid message: stream is nil or request is nil%s Prepare Audio Stream %{public}@%s Sending AcousticSLResult request%s Failed to get AcousticSLResult reply%s Received AcousticSLResult %{public}@%s Failed to parse Acoustic SLResult from raw data%s Message not valid %s Sending VoiceTrigger Info request%s Failed to get VoiceTriggerInfo request%s Received Voice Trigger Info %{public}@%s Failed to parse VoiceTrigger Info from raw data%s Received rtsTrigger Info %{public}@%s Failed to parse rtsTriggerInfo from raw data%s NO reply!!! %s No message!! %s No reply for hostTimeFromSampleCount request with sampleCount %{public} llu%s xpcConnection not existing %s No message for hostTimeFromSample Count request with sampleCount %{public}llu%s No reply for sampleCount FromHostTime request with hostTime %{public}llu%s No message for sampleCount FromHostTime request with hostTime %{public}llu%s cannot handle event event = %{public}p%s ignore unknown types of message %s Cannot handle nil message%s cannot handle error error = %{public}p%s Listener connection disconnected %s AlertProviding Delegate messageType : %{public}lld%s Unexpected type: %{public}lld %s Session Providing Delegate messageType: %{public}lld %s context: %{public}@%s invalid context%s SessionInfoProviding Delegate messageType: %{public}lld %s Received notificationInfo %{public}@%s Failed to parse notification Info from raw data%s Start Listening request with deviceId: %{public}@%s CSOpportuneSpeakListener received didStart : %{public}d, %{public}@%s remote VADDuration = %{public}d, spgDuration= %{public} d, remoteVADSPGRatio = %{public}d %s AudioStreamRequest has failed %{public}@%s CSOpportuneSpeakListener received didStop: %{public}d, %{public}@%s Request stop CSOpportuneSpeakListener%s Audio coming from DoAP should contains RemoteVAD%s boronScore: %{public}d, reportBoron %{public}d, slienceScore: %{public}lf%s Meter Providing Request Message has arrived %{public}lld %s Unexpected XPC Meter providing request: %{public}lld %s setMeteringEnabled: %{public}d%s audioMeterProvider not existing %s update Meters %s power = %{public}f with powerType %{public}u%s audioAlertProvider not existing %s init-_current LanguageCode: % {public}@%s Asset Manager Policy has been %{public}@%s Asset Manager Policy has been enabled, start fetching meta data now%s Need to fetch remote meta now, since we have new asset need to be downloaded %s Does not need to fetch remote meta now%s Cannot fetch VoiceTrigger asset meta data%s Undefined assetType: %{public}u%s _currentLanguageCode changed: %{public}@%s Trying to start download meta data%s Periodical downloading is already scheduled, ignore request.%s No periodical downloading is scheduled, ignore request.%s Releasing old assertion%s Acquiring assertion for active user%s last assertion acquired date is nil.Acquiring asssertion%s current date: %@, last assertion acquired date: %@, time difference: %f seconds%s The user is idle beyond the timeout interval.Ignoring acquiring assertion%s UserSessionActive has changed: %d %s Dealloc CSAudioInjection Engine Remora Engine: %@%s ERR: Failed to get Speaker Recognition assets with error % {public}@%s getVoice TriggerAsset error: %{public} @%s VoiceTrigger initialization started %s Voice Trigger will be started %s Starting all clients%s speechController = %{public}p%s xpcListener = %{public}p%s context = %{public}@%s Failed to create audio recorder %{public}@%s For Context: %{public}@, audioStreamId (%llu) has allocated %s Failed to get audio stream handle ID: %{publid} @%s has match with audio stream handle id %llu%s does not match with audio stream handle id (%llu), creating new audio provider%s No audio Recorder available, return nil for audio Provider%s have matched audioProvider with stream handle id %llu%s provider's streamId(%tu) is invalid, return nil%s don't have matched audio Provider with stream handle id %llu, need to create one later%s audioProvider [%{public}@] invalidated with streamHandleId %{public}llu%s No matched audio Provider found for streamHandleId %{public}llu%s Received Voice Trigger cached asset change.notification, let's reinitialize Voice Trigger%s new asset available, change to new model%s Trying to start clear logging files%s Clear logging file timer is already started, ignore startClearLogging FilesTimer request.%s setup VoiceTrigger due to Hearst connection %s setup Voice Trigger due to Jarvis connection%s setup VoiceTrigger due to remora connection %s Teardown VoiceTrigger due to bluetooth device disconnection%s UserIdleSystemSleepAssertion%s SystemSleepAssertion%s Could not take power assertion%s IOPMAssertionSetProperty failed: %{private}d%s Taking power assertion %{private}@%s Taking power assertion %{private}@ for a max of % {private}f seconds%s Successfully released power assertion for %{private}@%s Failed to released power assertion for %{private}@%s xpc object should be XPC_TYPE_DICTIONARY%s Cannot decode non-plist types of XPC object %s Cannot encode non-plist types into XPC object: %{public}@%s Cannot encode key into xpcobject since the key is not NSString class type%s zeroFilterWinSz: %{public}tu, numHostTicks PerAudio Sample: %{public}f%s _vtEndInSampleCount:%{public}ld, _numSamplesProcessed: %{public}ld, voice TriggerInfo: %{public}@%s Could NOT copyFrom: %{public}lu to: %{public}lu, retSampleCount: %{public}lu%s Invalid request: reqStartSample=%{public}lu, reqEndSample=%{public}lu, oldest SampleInBuffer: %{public}lu, latest SampleInBuffer=%{public}lu %s Seccessfully fetch audit token%s Failed to get audit token%s Reporting Mic Usage: %d %s Failed to report Mic Usage due to missing audit token%s STDynamic Activity Attribution Publisher reporting Dictation with bundleID: %{public} @%s STDynamic Activity AttributionPublisher reporting Siri%s STDynamic Activity Attribution Publisher reporting Siri and Dictation%s network state notify key : %s%s Start monitoring network availability%s Stop monitoring network availability%s Network availability changed %s Registering for post build install/first unlock activity - %s%s Received event for XPC activity: %@ in state: %ld %s XPC activity: %@ deferred: %@ first Unlock: %@%s Registered XPC activity got triggered...%s Skipping post build activity on ATV %s VT is disabled, skipping post build activity !%s Post build install/first unlock tasks got completed with error - %{public}@%s Registered XPC activity complete.State: %@.%s ERR: Failed SSR post build install chores with error %{public}@%s Clearing VoiceTrigger candidate in the voice Trigger Jarvis %s Jarvis firstpass writing audio file into %{public}@%s record stop unexpectly with reason: %ld %s Could not find Assets.Cannot process Audio%s NDEAPI Jarvis first pass heart beat %{public}llu, isSecondPassRunning? %{public}d, isSiriClientListening? %{public}d %s Send Jarvis Myriad notification%s FirstPass Jarvis received endpoint detected notification.%s result = %@, error = %{public}@%s rtModel is nil!%s keywordAnalyzerNDEAPI is nil!%s Sending early detect notification upon first pass trigger%s Ignoring external Jarvis trigger since we are already handling a trigger candidate%s Notify jarvis handler reject at: %{public}tu%s SecondPass Result, %{public}d, %{public}@, %{public}@%s Stopping firstpass Jarvis audio as second-pass made decision%s FirstPassJarvis stopped audio stream successfully? %{public}@, error: %{public} @%s Siri Client starts listening now, FirstPassJarvis shouldn't listen now%s Siri Client stops listening now, FirstPassJarvis can listen now%s Siri Client will stop listening, resume FirstPass Jarvis listen %s Couldn't create jarvis audio logging directory at path %{public}@ %{public}@%s SmartSiriVolume: deleted %{public}u elements in energy buffer.%s SmartSiriVolume: number of elements to delete exceeds energy buffer size, ignore.%s SmartSiriVolume init value for noise estimation %{public}f%s SmartSiriVolume init value for LKFS estimation %{public}f%s SmartSiriVolume enable policy changed %{public}@%s Already started listen polling, skip%s listen polling has failed %{public}@%s Skip listen polling since audio is streaming / Siri disabled %s Start audio stream successfully? %{public}@, error: %{public}@%s Received didStartRecording when Siri is off%s Failed in requesting audio stream: %{public}@%s Failed to stop audio stream: %{public} @%s No audio stream to stop, we shouldn't hit this%s SmartSiriVolume received MediaRemote initial state as %{public}@%s SmartSiriVolume haven't got Media Remote callback yet, let's assume media is playing.%s SmartSiriVolume received alarm initial state as %{public}@%s SmartSiriVolume received timer initial state as %{public}@%s asset is nil, use default parameters (this should not happen).%s SmartSiriVolume configure: %{public}@%s SmartSiriVolume: estimated noise level %{public} f%s SmartSiriVolume: estimated LKFS %{public}f%s SmartSiriVolume: pause SSV calculation.%s SmartSiriVolume: resume SSV calculation.%s Siri is disabled, we shouldn't receive audio here, heartbeat = %{public}lld %s stream stopped unexpectedly %{public}ld%s SmartSiriVolume received VT event! %s SmartSiriVolume remove samples from VT utterances by %{public}llu, with startAnalyze SampleCount = %{public}llu, samples Fed = %{public}llu, triggerStartSampleCount = %{public}llu%s SmartSiriVolume trying to delete too many VT samples, set triggerDurationToDelete to be limited max: %{public}llu %s SmartSiriVolume got empty VT event! %s SmartSiriVolume dismiss alarm firing as VoiceTrigger detected.%s SmartSiriVolume dismiss timer firing as Voice Trigger detected.%s SmartSiriVolume: final estimated TTS volume in dB %{public}f%s SmartSiriVolume: adjust TTS volume since alarm/timer is firing.%s SmartSiriVolume: TTS volume in dB from noise %{public}f, from LKFS %{public}f, with user offset %{public}f%s SmartSiriVolume: soft volume algorithm in use %s SmartSiriVolume: pause LKFS calculation according to MediaRemote notification.%s SmartSiriVolume: resume LKFS calculation according to MediaRemote notification.%s SmartSiriVolume received unknown media playing state, let's assume media is playing.%s SmartSiriVolume received unknown alarm state, let's reset alarm state.%s SmartSiriVolume: alarm firing status = %@ according to Mobile Timer notification.%s SmartSiriVolume received unknown timer state, let's reset timer state.%s SmartSiriVolume: timer firing status = %@ according to MobileTimer notification.%s Mediaserverd/bridgeaudiod recovered from crash%s SmartSiriVolume dismiss alarm firing as Siri client is recording.%s SmartSiriVolume dismiss timer firing as Siri client is recording.%s SmartSiriVolume: set StartAnalyzeSampleCount = %{public}lld %s SmartSiriVolume: final estimated TTS volume %{public}f with music volume %{public} f%s NewReq: sampleRate: %lu, recordContext: %@%s Err: %@%s triggerEndSeconds: %{public}f, _vtEndInSample Count: %{public}lu, _vtExtraAudioAtStartInMs: %{public}lu, _nnvadAudioOriginInMs: % {public}f, _num SamplesSkipped ForVT: %{public}lu, _finished SkippingSamples ForVT: %{public}d, voiceTrigger Info: %{public}@, %s Processing Done.Returning %s Rx first sample: %{public}ld, _numSamplesReceived = %{public}lu, _vtEndInSampleCount=%{public}lu%s _numSamplesSkipped For VT=%{public}lu, finishedSkippingSamplesForVT=% {public}d %s Recording Stopped For Reason: %{public}ld %s CSEndpointer Proxy: ep-time: %{public}f, triggerEnd: %{public}f, nnvad EndWaitTime: %{public}f, delta: % {public}f, legacy Two ShotThreshold: %{public}f, enterTwo Shot: %{public}d%s No Startpt detected even after %{public}f secs.startWaitTime = %{public}f secs%s Postponing endpt as Endpoint (%{public} f) < _automatic EndpointingSuspensionEndTime (%{public}f) %s Processing finished.Not scheduling %s Processing finished.Ignoring%s request: %{public}@, returnedError: %{public}@%s endpointedBuffer.hostTime = %{public}llu, isAnchor TimeBuffered=%{public}d %s No Preheat required%s Created FlexKwd-AS node%s Unable to start Flex Kwd with error %{public}@%s Unable to start audio stream for Flex Kwd with error %{public}@%s Trigger info already sent, ignore result%s Reporting trigger with result: %{public}@%s Initializing CSRawAudio InjectionProvider%s Done initializing CSRawAudio InjectionProvider%s Dealloc CSRawAudio InjectionProvider%s Calling StreamId for : %@%s Calling prepare%s Calling start audio stream: %@%s Calling stop audio stream%s Calling isRecording %s Calling prewarm%s Calling activate audio session%s _cs Assets Dictionary %{public}@%s CSAssetController cannot query for nil language%s ::: found % {public}lu installed assets for assetType=%{public}lu, matching query: %{public}@%s Error running asset-query for assetType:%{public}lu, query: %{public}@, error: %{public}lu%s ::: found %{public}lu assets for assetType=%{public}lu, matching query: %{public}@%s Asset state: %{public}ld%s ::: assetType: %{public}lu%s ::: % {public}s; query: %{public} @%s Found %{public}lu assets %s Error running asset query: error %{public}lu, or result is empty %s ::: Request Fetching RemoteMetaData : assetType: %{public}d %s Fetching remote meta data failed, scheduled retry after %{public}f seconds%s ::: Request fetching remote asset%s::: found %{public}lu assets for assetType %{public}lu%s Failed to finish query for assetType %{public}lu with error %{public}lu%s Meta data downloaded successfully for assetType % {public}lu%s Failed to download meta data for assetType %{public}lu with error %{public}lu%s ::: Fetching remote asset %s ::: Purging installed asset: %{public}
=
@%s Request downloading remote asset for assetType %{public}lu %s ::: Start downloading asset%s ::: download progress: %{public}3.0f%%%s ::: Error downloading from %{public}@ with error %{public} @%s ::: download completed successfully from %{public}@.%s Attempting to download asset %{public}@, asset state: %{public} ld%s ERR: Unknown AssetType: %{public}lu%s RT specific configuration %{public}@ does not exist, defaulting to unified configuration %{public}@%s Creating RT blob using: %{public}@%s Corealis RT model creation done successfully: %{public} @%s Failed to create Corealis RT model%s Defaulting to en_US Corealis RT model%s Default Corealis RT model creation done successfully%s Failed to create default Corealis RT model%s RT Model queried - %{public}@ %{public}@%s latestMajorVersion = %d, LatestMinorVersion = %d %s corespeech.json doesn't contains rtblobs%s blob file name is not exists%s blob file is not exists at %{public}@%s Reading blob from : % {public}@%s Blob is nil %{public} @%s Locale map for %{public}@ is not available on asset %s CSAudio Session Providing Proxy has received xpc disconnection _streamClient Type: %{public}d%s Trying to release audio stream on CSAudioSession Providing Proxy%s deallocated %s Session Providing Request Message has arrived : % {public}lld %s Unexpected XPC session providing request: %{public}lld %s Failed to prewarm audio session, error: %{public}@%s Session activate reason: %{public} u, dynamicAttributeType: %{public}u, bundleId: %{public}@%s Failed to activate audio session, error: %{public}@%s Session activate reason: %{public}u%s Failed to deactivate audio session, error: %{public}@%s Session set duck others option: %{public}d %s Trying to set duck others option when audioSessionProvider is nil%s Manual ducking handler not supported! %s Session %{public}@ mini ducking%s Trying to enalbe mini ducking when audioSessionProvider is nil%s Session %{public} @smart routing consideration%s Trying to enable smart routing consideration when audioSessionProvider is nil%s Start monitoring Springboard start%s Cannot start monitoring Springboard start because it was already started %s Stop monitoring Springboard start%s SpringBoard started = %{public}@%s Non internal build, Ignoring command %@ from peerId%@ Bailing out! %s Received Malformed command %@ from peerId %@ Bailing out! %s Command %@ received from peerId %@%s Unknown Command: (%@) Ignoring%s Triggering sync with peer - %@%s Triggering near miss sync with peer %@%s Triggering voice profile sync with peer %@%s Triggering acoustic data sync with peer - %@%s Triggering gecko sync with peer %@%s CSP2P_Remote HeySiriCmd: ENABLE HeySiri: Not Implemented Yet: %s CSP2P_RemoteHeySiricmd: DISABLE HeySiri: Not Implemented Yet: %s Cannot read contents of directory: %@, err: %@%s Unable to get %@ for file at %@: %@%s Could not determine if [%@] is a directory or not.Err=% @%s Found dir: %@.Skipping compression %s _compressFilesInDirectory: Malloc failed for file % @ (%lu) Discarding%s _compressFilesInDirectory: Compression failed for file %@ (%lu) Sending Uncompressed %s _compressFiles InDirectory: File %@ compressed from %ld to %ld %s Failed in compressing %{public}@ with errror %{public}@ - Bailing out%s Transfering NearMiss file % @ with Compression %{public}@ and size %ld in batch %{public}@%s Transfering grading file %@ with Compression %{public}@ and size %ld in batch %{public}@%s Grading log file successfully transfered for file %@ in task %@%s Grading log file failed to transfer for file %@ in task %@%s %@ is nil - Bailing out%s Failed in transporting Voice file %@ with reponse: %@, error %@%s Failed to remove the file %@ with error %@%s Failed to move the file %@ to %@ with error %@%s CSP2P_Voice ProfileParallelRecording TransferCmd: received malformed command %@%@ %@%s CSP2P_VoiceProfileParallelRecording TransferCmd: unknown IDS peer with passed Identifier %@, %@ %@%s CSP2P_VoiceProfile ParallelRecording TransferCmd: received malformed command - %@%s CSP2P_Voice Profile ParallelRecording TransferCmd: Creating directory failed with error %@%s Ignoring sync of existing file %@ from %@%s Syncing parallel recorded audio file - %@ from %@%s Uncompressed file %@ sent by peer %@%s ERR: Failed to allocate buffer of size %zu, bailing out%s Writing to file (%@) failed!.Err=%@%s received malformed command - %@%@ %@%s unknown IDS peer with passed Identifier %@, %@ %@%s received malformed command - %@%s Syncing audio file - %@ from %@%s Error setting remoteP2Plog file to NSFile ProtectionComplete UntilFirstUserAuthentication.file=%@ Err=%@%s CSP2P_VoiceProfile TransferCmd: received malformed command - %@%@ %@%s CSP2P_VoiceProfile TransferCmd: received malformed command: CSP2P_VoiceProfileData_Key: %@CSP2P_Voice ProfileFileName_Key: %@CSP2P_VoiceProfileSpeakerName_Key: %@CSP2P_VoiceProfileLocale_Key: %@CSP2P_VoiceProfileDataType_Key: %@CSP2P_Voice Profile TotalSegments_Key: %@CSP2P_VoiceProfileSegment_Key: %@%s CSP2P_Voice Profile Transfer Cmd: Received VoiceProfile Segment (%@/%@) from peerId %@%s CSP2P_VoiceProfile TransferCmd: Failed to delete the directory %@ with error %@%s CSP2P_VoiceProfile TransferCmd: received VoiceProfile Segment %@, expected %d%s CSP2P_VoiceProfile TransferCmd: Creating directory failed with error %@%s CSP2P_VoiceProfile TransferCmd: Writing to file failed!!! %s Received request to delete VoiceProfile %@ from peerId %@%s Cannot send data across when _adCompanionServiceProvider is nil returning%s ERR: Rejecting command %@ sent to non Horseman device%s ERR: received malformed command - %@%@%s ERR: unknown IDS peer with passed Identifier %@, %@ %@%s ERR: received malformed command with locale nil %@%s Fetching homeUserId for siriProfileId %{public}@%s siriProfileId %{public}@ maps to homeUserId %{public}@%s ERR: Home User Id erred %{public}@ for Siri Profile Id %{private}@%s ERR: %@%s ERR: received malformed command with profileId nil - %@%s ERR: Failed to find voice profile with identifier %@%s CSP2P_VoiceProfileFetchCmd: Transferring voice profile %{public}@%s CSP2P_VoiceProfileFetchCmd: File %@ isCompressed: %d, compressedSize: %ld, err: %@%s CSP2P_VoiceProfile Reverse Transfer Cmd: Failed Voice Profile Transfer: %@, error %@%s CSP2P_Voice Profile Reverse Transfer Cmd: Successfully transferred %@%s CSP2P_VoiceProfile Reverse Transfer Cmd: Failed transferring voice profile %@ with error %@%s CSP2P_VoiceProfileReverse TransferCmd: Successfully transferred voice profile %@%s ERR: Rejecting command %@ sent to Horseman device %s ERR: received malformed command with relative path nil - %@%s Failed in sending trigger for Voice profile update to peer %@ with error %@%s SpkrId:: path is nil Bailing out%s SpkrId:: Direntry with same name exists, this will be removed: %@%s SpkrId:: Creating Directory: %@%s SpkrId:: Creating Directory failed: %@%s Error reading directory at %@: err: %@%s %@ is empty %s message Type %08lx, arg %08lx %s Received device willSleep Notification%s Sending Acknowledge of willSleep Notification%s Received device hasPoweredOnNotification%s Failed to register for system power%s Prefetched Asset Vers (VT): %{public} @%s _shouldCleanup Voice Profile: %lu%s SSR Assets is nil for %{public} @- Bailing out%s Asset Vers: %{public}@%s Voice Profiles not present for %{public}@ Bailing out%s magus voice profile - %{public}@%s Recording leading utterance - %{public}@%s Setting up SSR controller with {%{public}@, %{public}@, %{public}ldusers, %{public}fsecs}%s ERR: Failed to create SSR context with error %@%s ERR: Failed to create SSR controller with error %@%s Failed to get asset with %{public}@%s Asset Vers (VT): %{public}@%s Initialized SSRNode with assets %{public}@%s XPC connection with client established%s Received SSR asset download notification, updated asset cache to %{public}@%s UserClassification: %{public}@ UserIdentified: %{public}@ Scores: %{public}@%s _speaker RecognitionScores: %@%s voiceIdScoreCard: %@%s speaker RecognitionScores is nil!%s spkrRecognizeris nil!%s speaker Info is nil!%s ERR: Discarded reporting final ScoreCard!! %s SpeakerIdInfo from incorrect SpeakerRecognizer: expected: %{public}@, spkrRecognizer: %{public} @%s ERR: Failed to get classified user from % {public}@%s mapped Speaker IdInfo for {% {public}d, %{public}.2fsec %dms} %{public}@%s Nil mappedSpeaker IdInfo since mappedScores is not valid, no score will be sent out%s Voice Profile for profileID %@ not found %s Overriding score to %@ for profile %@%s Dropping id: [%@, % @] %s ERR: Failed to retrain voice profile %
=
{public}@ with asset %{public} @%s ERR: Failed to init retrainCtxt for profileID %{public}@ with error %{public}@%s ERR: Failed to add profileID %{public}@ with error %{public}@%s trigger VoiceProfileCleanup%s ERR: Failed Voice Profile Cleanup with error %{public}@%s Submit Speaker False Trigger Mitigation score msg to SELF metrics for MH ID: %@, speakerMatchScore: %f, audioProcess Duration: %f%s could not allocate %{public}d bytes for %{public}@%s Surface PSD: PSD Score = %d, PSDSum = %f, PSDLength = %lu%s sigsum = %{public}f sigNorm= %{public}d sigFrac = %{public}d %s BTLE padded %{public}ld samples to fill out buffer%s No posting as trigger source is %{public}@%s BTLE AudioPayload ringBuffer startpoint: %{public}lld toEnd, active Channel: %{public}tu %s BTLE raw audio size = %{public}ld%s Surface PSD elapsed time = %{public}lf%s Advert data: %{public}@%s Decoded myriad PHash hash (%lu), goodness (%lu), confidence (%lu), absTime (%llu), frac (%lu)%s Invalid myriad pHash: %{public}@%s advert data write failed %s trigger end machAbsolute Time: %llu hex: %llx%s Invalid active channel in VTEI: %{public}tu, defaulting to master channel: %{public}tu %s Logging audio file into : %{public}@%s BTLE raw audio size = %{private}ld, audio length = %{private}ld%s Input recording is not float %s CSXPCListener start listening%s Device is firstUnlocked.Fetching HEP assets%s Device is NOT firstUnlocked.Will fetch assets after firstUnlock%s Language changed to: %{public}@%s New hybrid endpoint asset downloaded %s FirstUnlock notification received: %{public}d %s Failed to get HEP asset%s HEP Asset: %{public}@, path: %{public} @%s installationString: %@, for language: %@%s File not exist: %{public}@%s endpointAsset: %{public}@, osdAsset: %{public} @%s elapsed time to get HEP mobile assets: %{public}lf%s %{public}@ doesnt exist%s Could not read: %{public}@%s Could not decode contents of: %{public}@: err: % {public}@%s Fake endpoint asset: %@%s stream %{public}@ initialized%s stream %{public}@ is deallocated %s Creating UUID for start audio stream request : %{public} @%s Delivering didStop to %{public}lu tandem stream(s) %s AudioStream<%{public}@> is streaming: %{public}d %s Stream %{public}@ set startTime InSampleCount : % {public}llu%s AudioStream<%{public}@> has received didStopStream Unexpectly%s AudioStream<%{public}@> has received didHardware Configuration Change%s EndpointerNode added receiver: %@%s EndpointerNode removed receiver: %@%s %{public}.2f ms after vtEnd %s shouldReportHard Endpoint = %lu%s endpointerListener: %@%s Skipping DES record creation%s Failed to create DES record: %{public}@%s Created DES record with identifier: %{public}@%s Fides trigger (trigger): %{public}@%s Fides trigger (near-miss): %{public}@%s Unexpected XPC audioTimeConvert providing request: %{public}lld %s From sampleCount %{public}llu fetched hostTime = %{public}llu%s From hostTime %{public}llu fetched sampleCount = %{public}llu%s xpc object string return nil%s xpc object should be XPC_TYPE_STRING%s Input route changed %s Output route changed %s Failed getting audio property %{public}.4s %{public}d%s Failed getting audio property size %{public}.4s %d{public} %s Failed registering for property listener %{public}.4s %{public}d %s Alert Providing Request Message has arrived %{public}lld %s Unexpected XPC alert providing request: %{public}lld%s Alert sound url: %{public}@, alertType = %{public}d, force = %{public}@%s Set alert sound successful? %{public} @%s AlertType = %{public}d%s Play alert sound successful? %{public}@%s Play RecordStartingAlertAndResetEndpointer successful? %{public}@%s alertStartTime = %{public}llu%s Invalid alert behavior%s Alert behavior: %{public}@%s Failed to fetch listeningEnabled %{public}@%s listening property in AOP %{public}d%s Failed to fetch listeningEnabledOnNotification : %{public}@%s Stop monitoring AOP Listening state%s Received AOP Listening state change notification: %{public}d %s Entering recordWillStartGroup%s Leaving recordWillStartGroup%s didStartRecording received when CSVoiceTriggerFirstPass HearstAP is turned off%s Waiting for recordWillStartGroup before scheduling stpoAudioStream%s Scheduled stopAudioStream after waiting for recordingWillStartGroup%s Cannot stop listening: %{public}@%s Bypass audio here because isSecondPassRunning = %d, isSiriClientListening = %d, _isAPHearstFirstPassEnabled = %d %s Hearst AP first pass best score = %{public}.3f for heartbeat = %{public} lld%s Detected: %@, %@%s SecondPass Result, %d, %{public}@, %{public}@%s We are inside of an invalid phone call state.Do not start Hearst AP mode%s There is a non eligible app recording.Do not start Hearst AP mode%s Siri Client starts listening now, FirstPassHearstAP shouldn't listen now%s Siri Client stops listening now, FirstPassHearst AP can listen now%s Siri Client will stop listening, resume FirstPassHearstAP listen %s Trying to reset duckAudioDevice for deviceID %{public} u%s Call AudioDevice Duck with deviceID: %{public}u, duckedLevel %{public}f, ramp Duration %{public}f%s Unduck the legacy audio device (%{public}lu) %s Unduck the Legacy audio device (%{public}lu) and duck on new device (%{public}lu) %s Unable to get VT asset for FlexKwd Spotter %s configPath=%@%s _thresholdsMap=%@%s startProcessing SampleCount=%{public}ld, recognizer: %{public}@%s did FinishRecognition: err=% @%s FinalResults: %@%s PWinning Tok=%@, bestScore=%f==== %s Unexpected! %s Json file doesnt exist at: %{public}@%s Could not read Json file at: %{public}@, err: %{public}@%s Failed to parse json at: %{public}@, err: % {public}@%s CSAudioInjection XPCListener start listening %s SelfTrigger on Mac cannot be turned on since clamshell is closed %s SelfTrigger on Mac cannot be turned on since VoiceTrigger is disabled, or Siri disabled, or Siri enabled but Mac is on battery %s SelfTrigger on Mac cannot be turned on since Siri restricted on lock screen AND screen is locked %s SelfTrigger on Mac cannot be turned on since current user doesn't activated%s SmartSiriVolume cannot be resumed since Siri is speaking%s Timer already running.Cannot schedule another task%s CSAttSiriTimer fired: event-handler called %s Starting CSAttSiriTimer...%s Cancelling pending timer...%s startListenWithOption: %{public}d, %{public}@%s stopListenWithCompletion: %{public}d, %{public}@%s has Remote VADAvailable: %d %s hasVADAvailable : %d %s didStopUnexpectly: %d %s Another non eligible app is recording %s Start Recording Host Time = %{public}llu%s Entering assets query for AOP model in audio injection%s Done with assets query for AOP model in audio injection%s Error: Model is missing%s Looking up audio diff: %llu sampleCount:%llu %@%s First Pass Score : %f, First Pass Best Start: %llu, First Pass Best End %llu%s Non-AOP Voice Trigger cannot be turned on since voiceTriggerInCoreSpeech is NO%s Non-AOP VoiceTrigger cannot be turned on since VoiceTrigger is disabled %s HomePodSettings have turned off VoiceTrigger%s Automatic Volume Toggled.Automatic Volume Enabled: %{public}d%s Hang up toggle: %d %s VoiceTrigger cannot be turned on since we are not in the desired call state%s VoiceTrigger cannot be turned on since we are in a hang up supported call state but it is not first party.%s VoiceTrigger cannot be turned on because we are in a ringtone and hsPhoneCallCapable HeadsetConnected: %d builtInState: %d isInSplitter Mode: %d %s Cannot handle unexpected message type: %lld%s CSFallbackAudio SessionReleaseProvider is nil from CSSpeech Manager%s Primary stream is nil !%s CSAttSiriAudioSrcNode deallocated %s Tandem stream stopped unexpectly for reason: %ld %s Unexpected audioFormat for ATV %{public}u%s Create audio Decoder for audio Format %{public}u%s Overriding Myriad state as request was made during a ringtone%s Invoked Siri client%s Cannot notify wake keyword spoken event: %{public}@%s AFSiriActivation CarPlay Device VoiceTrigger Prewarm success%s AFSiriActivationCarPlay DeviceVoice Trigger Prewarm failed %{public}@%s Invoked Siri client for voice trigger from Jarvis %s Cannot invoke Siri client for voice trigger from Jarvis : %{public}@%s SiriActivationConnection deactivated due to %ld %s Invoked Siri client for voice trigger from Darwin%s Cannot invoke Siri client for voice trigger from Darwin: %{public}@%s Voice Trigger AOP mode start policy changed %{public}@%s Initializing first pass Corealis for channel: %{public}tu, with configPath: %{public} @%s Trying to access out-of-bound channel (index = %tu), asset configPath: %{public}@%s Trying to have multiple NDAPIs on platform not supporting channel selection, for channel: %tu, asset configPath: %{public} @%s Failed to create keyword analyzer%s %tu first pass Corealis were created %s bestEnd = %{private}d, bestChannel = %{private}d%s audio chunk: %{private}@%s Received VoiceTrigger %{public}@abled at state %{public}@%s _voiceTriggerEnabled = %{public} @%s Skip listen polling since Voice Trigger AP mode is disabled %s Skip listen polling since audio is streaming / VoiceTrigger disabled %s didStartRecording received when Voice Trigger is turned-off%s Waiting for recordingWillStartGroup before scheduling stopAudioStream%s Cannot startListen Polling: %{public}@%s APModeValidationTimer fired VoiceTriggerEnabled (%d), shouldBeAOPMode (%d), currentState (%d) %s User doesn't have ownership of AOP.ignore AOP trigger notification%s phraseSpotter bypassed, ignore AOP trigger notification%s Hearst Connected running and device doesn't wake from sleep, ignore AOP trigger notification%s Remote darwin running, ignore AOP trigger notification%s Siri Client is already streaming, ignore AOP trigger notification%s Device has wireless splitter mode with two hearst, ignore AOP trigger notification%s Voice Trigger current state: %{public}@%s skip stopAPVoice Trigger as audioStream not existing%s Bypass audio here because :: 1> VoiceTrigger enabled = %{public}d; 2> phrase spotter bypassed = %{public}d; 4> has hearst routable during call = %{public}d;
3> should ignore due to accessory connected and not in splitter = %{public}d; 5> AVVC recording client # = %{public}lu heartbeat %{public}lld %s First Pass Score: %lf, First Pass Best Start: %llu, First Pass Best End : %llu, CHANNEL: %d %s NDAPI first pass best score = %{public}.3f for channel = %{public}tu, heartbeat = %{public}lld%s NDAPI in channel: %{public} tu passed threshold with score %{public}.3f at sample %{public}tu, best = %tu, setting up decision delay in samples: %{public}tu %s Set to use the alignment of channel % {public}tu that first crossed the threshold: %{public} @%s Update to use the alignment of channel %{public}tu: %{public} @%s NDAPI first pass best score for channel selection = %{public}.3f for channel = %{public} tu at sample %{public}tu%s Boosting master channel (ch0) score to %{public}.3f by %{public}.3f for stream selection%s Assertion count: %ld %s HFP during phone call.We will set value to ignore pocket detection.%s SecondPass request is marked for cancellation before second pass completion %s Not notifying audioProvider Invalidation since VoiceTrigger result is %{public}d %s Notifying audioProvider Invalidation due to Voice Trigger result(%{public}d) so Siri client needs to setContext again %s Siri Client starts listening now, VoiceTrigger shouldn't listen now%s Siri Client stops listening now, VoiceTrigger can listen now%s Siri Client will stop listening, resume Voice Trigger listen %s Mediaserverd/bridgeaudiod crashed %s SecondPass shouldn't be created here%s Disable PHS since wireless splitter includes non-DoAP device, and non-DoAP device is in contacts%s Disable PHS since bypass personalized HeySiri is enabled in internal settings %s event: %{public} @%s Requested cancelling 2nd pass%s Received Wireless Splitter State Change%{public}d -> %{public}d, should Disable Speaker Verification: %{public}d -> %{public}d %s Received audio route change monitor event: %{public}d %s Received Jarvis %{public}@ event%s Received Hearst %{public}@ event%s Received Siri Input Source %{public}@ event%s Updated attSiri state to: %lu%s Received Device is about to sleep notification%s Received Device is awaken notification%s from: %{public}@ to: %{public}@ by: %{public}@%s Ignore event (%{public}@) from (%{public}@) since we don't have transition%s signal estimate: %{ private } f%s Endpointer is disabled in recordOption: %@%s CSHybridEndpointer canProcessCurrentRequest%s CSHybrid Endpointer can-NOT- ProcessCurrentRequest, fallback to NNVAD%s _activeEndpointer=%{public}@%s shouldUseCVT2Shot Decision: %{public}d, isWatchRTSTriggered=%{public}d %s preheat%s endpointer: %{public}@: didDetectStartpointAtTime: %{public}f%s EP_PROXY:: Recording DidStop: Ignoring startPoint-reporting%s EP_PROXY:: Recording DidStop: Ignoring didDetectHardpoint-reporting %s %{public}@: Endpointer didDetectHardEndpointAtTime: withMetrics: %{public}f, CallingDelegate: %{public}@%s Reported 2-shot at: % {public}f secs%s Queried endpointerModelVersion: %{public}@%s WARN: endpointerModelVersion called when CSHybridEndpointer is not available %s Skip update endpointer threshold from server for accessible endpointer request%s WARN: LogEndpointFeatures called when CSHybrid Endpointer is not available%s Dilation factor requested for device default !%s V Spread requested for device default !%s V Offset requested for device default ! %s H Offset requested for device default!%s Music steepness requested for device default !%s Minimum TTS volume for ASV disabled case requested for device default !%s Cannot access to %{public}@ %{public}@ using default value=%{public} @%s Start monitoring First unlock %s Cannot start monitoring first unlock because it was already started %s Stop monitoring: First unlock%s Unlocked since boot = %{public}@%s Received mediaserverd or bridgeaudiod crashes event%s Received mediaserverd or bridgeaudiod reset event%s Start monitoring Mediaserverd crash recover event%s Skip listen polling since audio is streaming selfTrigger disabled %s Received didStart Recording when enablePolicy is off%s SelfTrigger enabled %{public}d%s enable Policy is NO, we shouldn't receive audio here, heartbeat = %{public}lld %s Output NDAPI self trigger best score = %{public}f for channel = %{public}tu, client listening? %{public}@%s Notifying self trigger detected %{public}@%s Siri Client starts listening now, selfTrigger shouldn't listen now%s Siri Client stops listening now, selfTrigger can listen now%s Siri Client will stop listening, resume selfTrigger listen%s Error reading audio file: %{public}d, skipping...%s Start monitoring speech endpoint asset meta update%s Stop monitoring speech endpoint asset meta update%s New speech endpoint asset is available %s Updating attSiri state to: %lu%s Start monitoring: siri assertion enable/disable%s Stop monitoring: siri assertion enable/disable%s did receive enable assertion%s did receive disable assertion%s ERR: top ScoringUser is nil from %{public}@%s ERR: invalid arguments passed % {public}@ %{public}@%s ERR: Incorrect category %{public}d passed %s CSAudioProvider is deallocated %s CSAudio Provider [%{public}@]: StreamState changed from : % {public}@ to: %{public}@%s CSAudio Provider [%{public}@]: Setting audio Recorder: %{public}p%s Reset recordDevice Indicator as we have new audioRecorder%s CSAudioProvider [%{public}@]: %s CSAudio Provider [%{public}@]: setCurrentContext: %{public} @%s CSAudioProvider [%{public}@]: Cannot change context since audio recorder is currently recording %s CSAudioProvider [%{public}@]: audioStreamWithRequest for stream <%{public}@>%s Failed to prepare AudioStreamSync %{public}@%s Attached stream %{public}@ as tandem to master stream %{public}@ %{public}@, error %{public}@%s PrimaryStream is already tandem of stream %{public}@, can't add mutual tandem relation here! %s Invalid input streams%s CSAudio Provider [%{public}@]: Prepare audio stream reuqested while state is %{public}@%s CSAudioProvider [%{public} @]: Cannot prepare, audio system is recovering%s CSAudio Provider [%{public}@]: Asking Audio Recorder prepareAudioStreamRecord %s CSAudio Provider [%{public} @]: prepareAudioStreamRecord failed: %{public} @%s CSAudio Provider [%{public}@]: Create circular buffer numChannels (%d), duration (%f)%s CSAudioProvider [%{public} @]: startAudioStream with stream: %{public}@ with stream state: %{public}@, option: %{public}@, streamId: %{public}llu%s CSAudio Provider [%{public}@]: state was %{public}@, prepareAudioStream first%s CSAudio Provider [%{public}@]: prepareAudioStreamSync with stream: %{public}@ with stream state: %{public}@, request: % {public}@%s CSAudio Provider [%{public}@]: prepareAudioStream with stream: %{public}@ with stream state: %{public}@%s CSAudio Provider [%{public}@]: Cannot handle start audio stream on: %{public}@%s CSAudio Provider [% {public}@]: Cannot startAudioStream, audio system is recovering %s CSAudio Provider [%{public}@]: Requested startHostTime = %{public}llu, _clientStartSampleCount = %{public}tu%s CSAudioProvider [%{public}@]: %{public}@ is requesting earlier audio than asked, we can't deliver earlier audio%s CSAudioProvider [%{public}@]: Set circularBufferStartHostTime = %{public}llu, circularBufferStartSampleCount = %{public}lu%s CSAudioProvider [%{public}@]: Entering dispatch group for recordingWillStartGroup %s CSAudioProvider [%{public}@]: Failed to fetch historical audio since _clientStartSample Count is newer than audioBuffer sample count (%{public}llu) %s Start deliver historical audio buffer immediately %s CSAudio Provider [%{public} @]: Leaving dispatch group for recordingWillStartGroup %s CSAudio Provider [%{public}@]: Received didStart Recording while %{public}@%s CSAudio Provider [%{public} @]: Received didStopRecording reason: %{public}d, streamState: %{public}@%s Calling unexpected didStop for all weak streams%s CSAudioProvider[%{public} @]: Received did StopRecording while %{public}@%s CSAudio Provider [%{public}@]: Waiting for recordingWillStartGroup before scheduling stopAudioStream%s CSAudioProvider [%{public}@]: Scheduled stopAudioStream after waiting for recordingWillStartGroup stopAudioStream %{public}@ with streamState: %{public}@%s CSAudioProvider [%{public}@]: requested stop audio stream while stoppingWithScheduledStart, take out audio stream from schedule%s CSAudio Provider [%{public}@]: Stream %{public}@ is not streaming on stream state: %{public}@, ignore the stopAudioStream request%s CSAudio Provider [%{public}@]: Cannot handle stop audio stream on : % {public}@%s CSAudio Provider [%{public}@]: requested stop audio stream while stopping, adding audio stream into stop pending %s CSAudio Provider [%{public}@]: Stop all recordings, moving stream state to %{public}@%s CSAudio Provider [%{public}@]: Failed to stop audioStream: %{public}@%s Saving circular buffer from %{public}lu to % {public}lu%s CSAudio Provider [%{public}@]: %{public}@ ask for audio hold stream for %{public}f%s CSAudioProvider [%{public}@]: Timeout for %{public}@ has fired%s CSAudioProvider [%{public}@]: Removing %{public}@ from stream holders %s CSAudio Provider [%{public}@]: %{public}@ stream holder was already removed from stream holders%s CSAudio Provider [%{public}@]: %{public}@ ask for cancel hold stream%s Failed to prewarmAudioSessionWithError: %{public} @%s Failed to activate Audio SessionWithReason: %{public}@%s CSAudio Provider [%{public}@]: Activating Audio Session under : %{public}@%s Failed to activateAudioSession: %{public} @%s Failed to fetch duckingSupported result: %{public}@%s Failed to deactivate audio session : %{public}@%s CSAudio Provider [%{public}@]: Deactivating Audio Session under : %{public}@%s Failed to deactivateAudioSession: %{public} @%s Unable to disable duckOthers in Home Pod%s CSAudioProvider [%{public}@]: AVVC is recovering, ignore command...%s Not handled by this function%s Fetching voiceTrigger Info from audioRecorder%s CSAudio Provider [%{public}@]: Cannot stopRecording as there are %{public}tu streamHolders%s CSAudio Provider [%{public}@]: Shouldn't stop AVVC recording as there are %{public} tu streams %s CSAudio Provider [%{public} @]: Buffer under run!!!!, lastForwardedSample Time: %{public}lu, oldest Sample TimeInBuffer:%{public}lu, stream: %{public}@%s CSAudio Provider [%{public}@]: Ignore forwarding stream %{public}@ the audio packets until sampleCount == %{public}lu (the Most Recent SampleCount: %{public}lu)%s CSAudioProvider [%{public}@]: Buffer overrun!!! LastForwardedSample Time: %{public}lu, the Most RecentSampleCount:%{public}lu, stream: %{public}@%s Forward %d samples from historical audio buffer%s Schedule AlertFinishTimeout: %{public}@%s Schedule AlertFinishTimeout will be ignored : % {public}@, %{public}@%s Received finishStartAlertPlaybackAt:%{public}llu streamState: %{public}@%s CSAudioProvider [%{public}@]: Requested alertFinishHostTime = % {public}llu, clientStartSampleCount = %{public}tu, circularBufferSampleCount = %{public}tu %s Audio Streaming already stopped %s Will invalidate current builtIn audio stream: %{public}@%s failed to stopAudioStream: %{public}@%s CSAudioProvider [%{public}@]: Audio Recorder Disconnected %s CSAudioProvider [%{public} @]: Mediaserverd/bridgeaudiod crashed %s CSAudioProvider [%{public}@]: Mediaserverd/bridgeaudiod recovered from crash%s CSAudio Provider [%{public}@]: AudioRecorder will be destroyed%s CSAudioProvider [%{public}@]: recording Transaction already released %s CSAudio Provider [%{public}@]: Release recording transaction at streamState: % {public}@%s Audio Packet Delivery WatchDog fired, trying to recover%s Schedule didStart WDT %{public}@ for %{public}lf seconds%s startRecordingWatch DogDidFire: % {public}@, currentToken: %{public} @%s startRecordingWatch DogToken doesn't match.Ignore this WDT fire%s Clearing didStartRecording Delegate WatchDogTimer : % {public}@%s Schedule didStop WDT %{public}@ for %{public}lf seconds%s stopRecording Watch DogDidFire: %{public}@, currentToken %{public}@%s stopRecordingWatch DogToken doesn't match.Ignore this WDT fire%s Clearing didStop Recording Delegate WatchDogTimer : %{public}@%s Update remote deviceUId fetched from AVVC %{public}@ (this must be deviceUID of Darwin device only)%s Failed to fetch remote deviceUId from AVVC%s PHS threshold for %lu doesn't exist, use default%s Start monitoring: SACInfo%s Stop monitoring SACInfo%s Device is in stereo mode: %{public}@%s Could not take dark wake power assertion%s Taking dark wake power assertion %{public}@%s Taking dark wake power assertion %{public}@ for a max of %{public}lf seconds%s Successfully released dark wake power assertion % {public}@%s Failed to release dark wake power assertion %{public}@%s Start monitoring Speaker Recognition Asset Download%s Stop monitoring Speaker Recognition Assets Download%s New SpeakerRecognition Assets is now installed %s ERR: Delegate received for invalid Trial assetType:%lu%s Cannot deactivateAudioSession since audio recorder doesn't exist%s Cannot deactivate AudioSession with %{public}@%s Start monitoring Speaker Recognition Asset meta update%s Stop monitoring : SpeakerRecognition Asset meta update%s New Speaker Recognition asset metadata is available %s Clearing pending homekit accessory voice trigger %{private}@%s Handling Pending Remora VoiceTrigger Event%s Time since last pending remora voice trigger %f.Ignoring.%s Clearing pending built-in voice trigger %{private}@%s Handling Pending BuiltInVoiceTrigger Event%s Time since last pending builtin voice trigger %f.Ignoring.%s client: %lu, deviceId: %{private}@%s context: %@%s context:%@, flag: %u option: %@, eventUUID: %@%s _requestMHUUID set to : %@%s Skip asking audioSrc Node to record since Siri client failed to start audio%s Cached siri client stream, attach after nodes start %s Skip asking audioSrcNode to prepare since Siri client failed to prepare audio%s Siri enabled %{public}d %s currDp:%@ newRequiredNodes: %@%s % @ is ready%s Updating mitigation asset to %@%s Unable to get Trial mitigation assets with err: %@, asset: %{public}@%s Updating VT asset to %@%s Unable to get Trial VT assets with err: %@, asset: %{public}@%s Attached to siri client stream with result: %d error: %@%s Failed to setup audioSrcNode%s Skip processing for remora requests! %s AFTM started for siri request status: %{public}d with error: %{public}@%s attSiriTransaction already released %s PhraseSpotter enabled = %{public}@%s PhraseSpotter is already %{public}@, received duplicated notification! %s disconnect activationXPCClient%s Start monitoring: AdBlocker Asset Download %s Stop monitoring: AdBlocker Asset Download %s New AdBlocker Asset is now installed %s Cannot handle wrong message type %s Request to bypass PhraseSpotter: %{public}d with timeout %{public}lf seconds%s Received Siri Session did cancelled %s Cannot create de-interleaver using Audio Converter New: % {public}d%s Created de-interleaver %s Stopping Audio Injection Engine: %@%s Failed to open audio file %@, error: %d %s Streaming from %@%s Cannot speak nil Audio URL%s Cannot speak since audio file does not exists: %@%s Calling stopAudioStream%s Failed to deinterleave the data: %{public}d%s %@ task delivered.%s %@ completed with response %@ and error %@.%s Siri language is nil, falling back to %@%s endpointUUID not provided, fallback to legacy query%s Failed to query Language code with endpointId %@, trying legacy query%s Start monitoring Power source state update%s Stop monitoring Power source state update%s Power source changed %{public}tu%s Continous Audio Fingerprint cannot be turned on since Siri is disabled %s Received external route change notification%s deviceID: %{public} Triggering voice
lu%s Device name = %{public}@%s Error retrieving supportDoAP (OSStatus = %{public}d)%s supportDoAP value = %{public}lu%s Notifying Hearst Connection State : % {public}d%s Message type = %{public}lld %s Cannot handle activate EventMessage since event is nil%s Failed to register clamshell notification%s Start monitoring: clamshell open/close update%s Stop monitoring clamshell open/close update%s root domain for clamshell state is null%s No meta data to write, skip%s Error writing out event info meta: %{public}@%s Failed to get Gecko log directory %s _requestMHUUID: %@, _turnIdentifier: %@%s _userSpeaking Started Time InMs %{public}f, _userSpeaking Ended TimeInMs: %{public}f, userSpeakingStarted HostTime: %{public}llu, _userSpeaking EndedHostTime: %{public}llu, _stopRecording HostTime: %{public} llu, endpointBuffer HostTime: %{public}llu %s EPD: %{public}f, EPD_Model: %{public}f, EPD_Latency: %{public}fEndpoint Delay%s Submit MHEndpoint DelayContextEvent to SELF for MH ID: %@%s endpointTime InMs %{public}f, userSpeaking EndedTime: %{public}f, _user Speaking Ended MachAbsTime: %{public}llu, stopRecording MachAbsTime: % {public}llu%s LogInstrumentation for speakingStarted %s logInstrumentation for speaking Ended %s Created CSVoiceProfile Retrain Manager %@%s LanguageCode is nil - Bailing out%s Retraining on %{public}@ with asset %{public}@%s Voice Trigger is enabled, trigger retraining if needed! %s Fetched latest assets %@ for retraining%s Cannot retrain since we cannot look-up VoiceTrigger asset: %{public}@%s Language Changed to %{public}@ Triggering voice profile retraining%s ERR: Ignoring CSSpeakerRecognition Asset Download Monitor Delegate for non-TVOS platforms !%s New Speaker Recognition assets downloaded - Triggering voice profile retraining%s Fetched latest SSR asset %@ for retraining%s Cannot retrain since we cannot look-up SSR asset with error %@%s Speaker Recognition Model Missing profile retraining %s Triggered cleanup of duplicated profiles%s Fetched latest VT asset %@ for retraining%s Triggered migration if needed...%s ERR: Failed voice profile migration with error %{public}@%s Completed one-time migration...%s No voice profiles found, trigger a download %s languageCode: %{public}@ -voiceProfileArray: %{public}@, _current Asset:%@%s Speaker recognition asset not found%s ERR: Constraining pruning and retraining to first profile%s Skipping retraining as device isn't unlocked even once !%s recognitionAsset:%@%s Retraining done for profile %@ with error %@%s ERR: Mach Service Name is nil - Bailing out%s ERR: Proxy Object is nil - Bailing out%s ERR: Exported interface is nil - Bailing out%s Set up queue for %@%s Started listening for %{public}@%s Service % {public}@ dealloced - %{public}@%s Got connection on service %{public}@%s [Service: %{public}@] Invalid listener %{public}@%s Rejecting connection to %{public}@ due to entitlement%s [Service: %{public}@] Listener Interruption Handler: %{public}@, client PID: %{public}d) %s [Service: %{public}@] Listener Invalidation Handler: %{public}@, client PID: %{public}d exited %s machService Name (%@) with clientConnCount: %lu %s Sending message to remote object: %@%s RemoteObjectProxy is nil for client PID (%{public}d) %s [Service: %{public}@]%s Turn on AP mode since device is hands free state with HS phone-call capable route connected %s CommandControl Streaming %{public}d %s Turn on AP mode since command control is streaming%s VAD is not present or Hearst routed without phone call%s VoiceTrigger AOP mode cannot be turned on since builtIn speaker is active%s AudioRecordContext = %{public}@, recordState = RECORDING%s CarPlay is connected, we will still run AOP mode%s VoiceTrigger AOP mode cannot be turned on since Siri client is recording %s AOP Listening is disabled %s Turn on AP mode since siri is in attending state%s Speech Detection VAD is not available, we will still running in AOP mode%s Will notify Siri Client record state change to STOPPED in %{public}f seconds, eventUUID = %{public}@%s Notifying Siri Client record state change to STOPPED, eventUUID = %{public} @%s There is no pending event to timeout: pendingRecordingStop UUID = % {public}@, timeout TargetUUID = %{public}@%s ::: %{public}s enable: %{public}d reason: %{public}@ timestamp: %{public}lf%s Ignoring request to enable/disable voice trigger with nil reason.%s ::: Asserting that VoiceTrigger should be %{public}@ with reason: %{public}@.Existing assertions (%{public}lu): %{public}@; times: %{public}@ vs %{public}f%s Ignoring request to enable/disable voice trigger time order violation.%s ::: Ignore request as phraseSpotter already %{public} @%s Asserting that PhraseSpotter should be %{public}@, timeout: %{public}f%s ::: Timeout!! PhraseSpotter should be NOT bypassed %s ::: Ignore request as raiseToSpeak already %{public}@%s ::: Asserting that raiseToSpeak should be %{public}@, timeout: %{public}f%s ::: Timeout!! raiseToSpeak should be NOT bypassed%s HandleDisconnect%s Turn off Voice Trigger AP mode, since hearst is routed %s Turn off VoiceTrigger AP mode, since audio accessory is selected as default input device%s Turn off VoiceTrigger AP mode, since audio accessory is selected as default output device%s Turn off Voice Trigger AP mode, since Built InSpeaker is not active%s Start monitoring: AdBlocker Asset meta update%s Stop monitoring AdBlocker Asset meta update%s New AdBlocker asset metadata is available%s CSVoiceTriggerAsset (%{public}@) found: %{public} @%s Cannot get a VoiceTrigger mobile asset: %{public}@%s Trial assets not available, fallback to MA assets%s Asset Query failed %{public}@%s cached asset:%{public}@, new asset:%{public}@%s New asset is same as cached asset, ignore notification%s New asset is different from cached one.Updating cached asset%s new Voice Trigger asset downloaded %s Language Code Changed %{public}@%s First unlock notification received: %{public} d%s Successfully? %{public}@%s Notify release of audio session %s siriSessionUUID = %{public}@%s CSAudioProcessWaitingBuffer deallocated %s Reason: %{public}lu%s Received xpc disconnection %s Updated endpoint start time in sec %{public}.3f%s Adjusted endpoint start time to: %{public}.3f, audioSampleCountToSkip: % {public}lu%s Preheat LocalSpeech Recognition now%s Settings: %{public}@%s Unsupported speech recognizer task: %{public}lu%s _localSpeechRecognizerState: %lu%s Received nill requestId, generate requestId under corespeechd %s Start deliver asr results with requestId: %@%s Handle late start request from Request Dispatcher%s Clear audio waiting buffer since current requestId (%@) doesn't match expected one (%{public}@) %s Reason: %{public}lu, requestId: %@%s requestId doesn't match current one (%@), ignore%s requestId : %@%s requestId doesn't match current siriSession UUID (%@), ignore%s Request Dispatcher hasn't asked to start local ASR yet, cache the audio%s ASR already process enough audio until endpoint, stop processing it%s %lf%s Already accepted result candidate for request%s Sending RC selection delegate with parameters, RcId: %{public}lu mitigationSignal: %{public}d shouldAccept %{public}d requestId: %@%s Reset endpointStart and audioSampleCountToSkip since recordContext is %{public}@%s shouldResetWaitingBuffer: %u %s Preheat local speech recognizer with language: %@%s Local speech recognizer disabled, ignore prepare%s cached requestId : %@, newRequestId : %@%s Disable local SR for dictation%s current state = %{public}@%s speech recognizer task not specified, fallback to SearchOrMessage%s Calling local speech recognition with settings : task (%{public}@), endpointStart (%{public}.3f), inputOrigin (%{public}@), location (%{public} @), shouldCensorSpeech (%{public}@), jitGrammar (%{public}@), enableVoice Commands (%{public}@) on device_Voice TriggerEndToASRStart Latency%s Voice trigger end to ASR Start Latency: %{public}.2f ms %s didStart local speech recognition with error :%@, model properties: %@%s Setting local speech recognizer state to [Idle] as not able to start local ASR%s Local speech recognizer can't started locale (%{public}@), taskName (%{public}@) %s Added %{public}lu samples to local speech recognizer%s Stopping task %@%s Request dispatcher didn't ask to start until end %s Complete task now since taskString (%{public}@) or localSR (%{public}p) is nil%s Complete task now since local SR is disabled %s Schedule Recording TransactionRelease Timer %{public}@ for %{public}lf seconds%s Token %{public}@, currentToken: % {public}@%s recording Token doesn't match, ignore %s %@ created speech recognizer %@%s Ignoring completion from previous recognizer! %s Ignoring completion with metadatapackage as enable condition not satisfied! %s Exceeding max local speech recognition duration (%{public}f): %{public}f, force endbooking the ASR task%s Skip query as already accepted result candidate for request%s did Detected Endpoint = %{public}@, usesAutomatic Endpointing = %{public}@, waiting %s Eager results accepted: %{public}d.Duration: %{public}lf last duration: %{public}lf%s Received duration not matching last duration %s isFinal package: %{public}@%s There is no valid RC to deliver, or previous RC already got accepted %s Enforce previous endpointHint%s SpeechPackage processed audio duration: %f ms%s Speech recognition encountered error: %{public}@%s Invalidating local speech recognizer for finishondevice_Eager CPL %s eagerCPL time interval: %{public}f, userSpeaking EndedHostTime: %{public}llu, lastEndpointEagerResultTime: %{public}llu%s wordCount = %ld, trailingSilence Duration = %ld, eosLikelihood %f, pauseCounts = %@, silencePosterior = %f, processedAudio DurationInMilliseconds = %ld %s Received ASR datapack root directory: %{public}@%s Received inputOrigin: %{public}@ from Request Dispatcher, use hard-coded map%s set current state from %{public}@ to %{public}@%s Selected recognizer language: %{public}@%s Can't calculate TTFW due to missing metric: %llu %llu %fondevice_TimeToFirstWord %s Language code already up-to-date: %{public} @%s Fetching Command Control Listening State: %d %s Received user activity notification%s Failed to register for user activity state%s Failed to fetch user idle activity state %s Current user activity: %llu%s Invalid notification token %d%s Found pending activation: %{public}@, handle pending activation immediately%s Received Activation Event in CoreSpeech Daemon: %{public} @%s Returning error for already existing pending activation event: %{public}@%s No delegate registered Postpone activation event handling until we have delegate registered%s Pending Timeout fired for %{public}@ returning error for timeout%s There is no pending activation event to timeout%s corespeechd received mediaserverd launched event%s Start monitoring: AOP First Pass trigger%s Stop monitoring: AOP First Pass trigger%s There is not audio buffer to convert.Skip this.%s Got asked for % {public}u packets, have %{public}u%s [%{public}02u of %{public}02u %{public}fs] Opus packet with %u bytes%s %{public}d bytesConsumed from opus coverter, remains % {public}d bytes%s Resetting Audio Converter buffer%s createAudio Converter initial frames per buffer = dur %{public}.2fsr %{public}.2f = %{public}u%s Failed to get audioConverter property (kAudioConverterCurrentOutputStream Description): %{public}d %s _configureAudioConverter: encoded audio needs minimum of %{public}u bytes per output buffer%s _configureAudioConverter: AudioConverterGetProperty(kAudioConverter PropertyMinimum OutputBufferSize) returned status %{public}d%s _configureAudioConverter: final frames PerBuffer: %{public}u%s _configureAudioConverter: convertPacketCount: %{public}u%s _configureAudioConverter: AudioConverterGetProperty (MaximumOutputPacketSize): returned status %{public}d %s createAudioConverter: outputSizePerPacket: %{public}u%s _configureAudioConverter: _convertAudio Capacity %{public}u bytes%s Cannot create AudioConverter using AudioConverter New: %{public}u%s Cannot set encoder bit rate %{public}u%s Error reading file%s Version of AdBlockerAsset: %d %s $HOME not set, falling back to using getpwuid%s failed to get passwd entry for uid %u %s failed to resolve user's home directory: %{darwin.errno}d%s failed to initialize temporary directory: %{darwin.errno}d %s failed to resolve temporary directory: %{darwin.errno}d%s failed to initialize cache directory: %{darwin.errno}d %s failed to resolve cache directory: %{darwin.errno}d%s failed to resolve user directory: %{darwin.errno}d%s Failed to enter sandbox: %{public}s%s SelfTriggerDetector in ASMac cannot be turned on since Siri enabled policy is disabled %s SelfTriggerDetector in ASMac cannot be turned on since builtInSpeaker is inactive%s SelfTriggerDetector in ASMac cannot be turned on since deviceIsInSleep%s VoiceTrigger DuringCall enabled = % {public}@%s VoiceTrigger during a call is already %{public}@, received duplicated notification! %s Connection %{public}p rejected due to missing entitlement%s xpc object should be XPC_TYPE_ARRAY%s xpcObject value is NULL%s Taking IOPMAssertion DeclareNotificationEvent power assertion for a max of %{public}lf seconds%s Successfully released power assertion%s Failed to release power assertion%s Start monitoring VoiceTriggerAsset meta update%s Stop monitoring: VoiceTriggerAsset meta update%s New VoiceTrigger asset metadata is available %s primaryStream already torn down %s Early DetectSample = %{public}d%s CSActivationXPCListener start listening %s There is no remote device %s Device connection waiting timed out%s DidStart Recording error: %{public}@%s Cannot report two shot since delegate doesn't have protocol implemented %s Cannot handle Two Shot Detected message since it failed to decode xpcObject to NSDictionary%s Cannot start recording while connection does not exist %s Cannot stop recording while connection does not exist %s Cannot ask didPlayEndpoint Beep while connection does not exist%s Getting reply timed out!!%s Cannot ask Voice TriggerEventInfo while connection does not exist%s Raw Voice TriggerEventInfo from remote = %{public}@%s Cannot ask hasPending Two ShotBeep while connection does not exist%s UUID was nil will not start fingerprint provider%s Updated in use services for fingerprintProvider.%lu services in use%s Starting continuousFingerprintProvider%s UUID was nil will not stop fingerprint provider%s Updated in use services for fingerprintProvider.%lu services remaining%s Stopping continuousFingerprintProvider CSRemoteControlClientDelegate V1NSObjectCSRemoteControlClientDelegateV2CSRemoteControlClientCSRemoteControlClient ProtocolV1CSRemoteCon trolClientProtocol V2CSRemoteControlClientProtocolV3CSAudioMetricProviding ProxyCSXPC ConnectionDelegate TrialBitsetCSTimer MonitorCSAlert Behavior Predictor CSVoiceTrigg erAsset Download MonitorCSAudioInjection Hearst Engine CSAudioInjectionEngineDelegate1! ACSSmartSiriVolume EnablePolicyFactoryCSAudioRouteChangeMonitorImplWatchCSServerEndpoint Features1!
CSAdBlockerAsset Decoder V2CSSmartSiriVolumeEnablePolicy Home PodCSAudioFileLogaCSAsset DownloadingOptionKeywordDetector CSSmartSiriVolume Run PolicyHomePod CSSmartSirivol umeUserIntentCS Language Code Update MonitorCSSiriEnabled Monitor CSOpportuneSpeakListenerDeviceManager RMS SampleCSShadowMicScoreCreatorBCSRemora SecondPass Audio StreamHol dingContextCS RemoraSecondPassRequest!
CSVoiceTriggerFirstPass RemoraCSActivationEvent NotificationHandler Delegate CSAccessorySiriClientBehaviorMonitorDelegateCSSecondPassProgress Providing& CSRemoteDarwin Device InfoCSVoiceTriggerAssetHandlerCSDarwinVoiceTriggerHandlerCSVoiceTriggerAssetDownloadMonitorDelegateCSLanguageCodeUpdateMonitorDelegateCSScreen LockMonitorDelegateCSBluetooth Wireless SplitterMonitor Delegate CSSystemUserActivityMonitorDelegate# CSAudioInjectionEngine Factory CSBuiltinSpeakerStateMonitorCSAudioServerCrashMonitorDelegate CSXPCClientFactory CSStateMachine 2CSLanguage Code Update MonitorImplAttSirid ebugDescription remote Voice ActivityVADBufferCSAudioRecorder AVVoiceController RecordDelegateCSAudioDecoderDelegateCSAudioFileReaderDelegateCSRemoteRecordClientDelega teCSUserSessionActiveMonitorDelegateCSAudioServerCrashEvent Providing CSAudio SessionEvent ProvidingC5!
ŎCSDefaultAudioRouteChangeMonitor MacCSMyriadNotifierCSVoiceTriggerSecond ChanceContextCSOpportuneSpeakListenerOptionCSAudioRecorderFactoryCSAudioStartStreamOptionNSCopyingCSAtt SiriAFTMNodeCSAttSiriNode!
1CSGibraltarVoiceTriggerHandler##¡CSEndpointerXPCServiceCSEndpointerXPCServiceDelegateLBLocalSpeechServiceLBLocalSpeechServiceDelegateCSAttSiriService ProtocolCSAttSiriServiceDelegate CSSSRXPCService CSSSRXPCServiceDelegate CSRCHandlingXPCServiceCSAttSiriConnectionManagerCSCoreSpeechDaemonStateMonitorCSAttSiriNLDAClassifierNode!
CSMediaPlayingMonitorCSHearstSecondPassRequestCSVoiceTriggerFirstPassHearst CSSiriClientBehavior MonitorDelegateCSPhoneCallStateMonitorDelegate9CSRemote XPCVoiceTrig gerEnabledPolicyCSSelfTriggerDetectorEnabled PolicyFactoryCSContinuousAudioFingerprintEnabled Policy HomePod CSSmartSiriVolume Run Policy CSAudioStreamProvidingProxyCSAU dioStreamProviding Delegate DCSVoiceTriggerFirstPass MetricsCSAttSiriMitigationAssetHandlerCSTrialAsset DownloadMonitorDelegate AVVCCSVoiceTriggerStatAggregatorCSDigit alZeroReporting CSAtt SiriAudioDataReceiverCSAttSiriAttendingAudioSrcNode!
CSVoiceTrigger SecondPass Result Holder CSVoiceTrigger SecondPassCSPhraseNDEAPIScorerDelegate CSVoiceTriggerEnabledMonitorDelegate CSMediaPlaying MonitorDelegateCSVolumeM onitorDelegate SSRSpeaker Recognition ControllerDelegate CSSelf TriggerDetectorDelegateQA1QaooCSAudioPreprocessor CSVoiceTrigger AwareZeroFilterDelegate CSBeepCancellerDe legate$CSBiometric MatchMonitor CSXPCConnectionRecordContextCSVoiceTriggerEnabledPolicy MacIndexing CSBluetooth Wireless SplitterMonitorCSHostLauncher DarwinCSHomePodSet tingsMonitorCSVoiceTriggerEventsCoordinatorCSAudioRouteChangeMonitorDelegateCSVoiceTriggerDelegate CSAttSiriMotion NodeCSPhoneCallStateMonitorFactoryCSSPGEndpointAn alyzerCSActivation EventCSVoiceTriggerAlwaysOnProcessorCSAttSiriAttentionNodeCSAudioStreamHolding CSVoiceTrigger DarwinHandler TestContextCSAudioFileReaderCSDarwinVoi ceTriggerHandler PoolCSDarwinVoiceTriggerHandlerDelegateis PluginContextCSAudioInjectionProviderQCSMSNExceptionManagerCSAssetManagerEnablePolicyCSVoiceTriggerXPCLis tenerCSVoiceTriggerXPCConnectionDelegateCSAVVoiceTriggerClientManagerCSVoiceTriggerEnabledMonitor Remote DarwinCSVoiceTrigger Statistics SCSCore SpeechServiceListenerD elegateCSAudioSample RateConverterCSSoftwareUpdateCheckingMonitor XPCObjectAudio Hardware CSScreenLockMonitor CSVolumeMonitorCSAdBlocker Asset Decoder V1CSAccessorySiricl ientBehavior MonitorCSSRFUserSetting Monitor CSJarvis TriggerModeMonitor CSBluetoothWirelessSplitterMonitorImplDarwinCSAudioRouteChangeMonitorCSAttSiriUres Node4CSVoiceTriggerEnabledMonitorCSSmartSiriVolumeManager CSAlarm MonitorDelegateCSTimer MonitorDelegateCSAutomatic VolumeEnabled MonitorDelegate CSCoreSpeech ServicesListener NSXPCL istenerDelegateCSAudioInjectionTvRemoteEngine CSAudioConverterDelegateCSAttSiriSpeechDetectionNode!
с11CSAlarmMonitorCSAudioInjectionFileOptionCSAlways Disabled PolicyCSActivationEvent Notifier CSRemoteDevice ProtocolInfoCSAudioRecordDeviceInfoNSSecureCoding NSCodingCSVoiceTriggerEventInfoProviderCSVoiceTriggerEnabled PolicyMacWith Remote DarwinCSListeningEnabled PolicyWatchCSAudioRecordDevice IndicatorCSBattery Monitor CSHostDaemonMa CSEndpointLoggingHelper CSEndpointLatencyInfoCSAttSiriRCHandler"RootlessCSAudioInjectionXPC Audio InjectionXPCProtocolStatistics CSXPCClientCS Audio Session ProvidingCSF allbackAudioSession Release ProvidingCSAudioStream ProvidingCSAudioAlertProviding CSAudioSessionInfoProviding CSAudioMeterProvidingCSAudio MetricProviding CSAudioTimeCon versionProvidingCSTrigger InfoProviding HCSOpportune SpeakBehavior Monitor CSOpportuneSpeakListenerCSSPGEndpointAnalyzerDelegate& CSAudioMeterProvidingProxyCSBuiltInVoiceTriggerEnabled Policy CSAsset ManagerCSVoiceTriggerAsset MetaUpdateMonitorDelegate CSSpeechEndpointAssetMetaUpdate MonitorDelega teCSAdBlockerMetaUpdateMonitorDelegate CSAssetControllerDelegateCSSpeakerRecognition Asset MetaUpdateMonitorDelegate CSVoiceTriggerDataCollector CSDarwin PreventSystemS LeepManagerCSHybridEndpointAnalyzer CSEndpointAnalyzer ImplCSEndpointAnalyzer 2 AQCSUserSessionActiveMonitorCSAudioInjection Remora EngineCSSpeech Manager CSVoiceTriggerA ssetHandlerDelegateCSAudioRecorderDelegateCSAudio ProviderDelegateCSOpportuneSpeakEventMonitorDelegateQCSTUPhone CallStateMonitorCSPreventSystemSleepPowerAssertionF LexKwdCSAssetManagerEnablePolicyFactoryCSVoiceTrigger AwareZeroFilter ACSRemote VADCircular BufferCSMicUsageReporterCSNetworkAvailability Monitor CSPostBuildInstallServ iceCSVoiceTriggerFirstPassJarvis CSKeywordAnalyzerNDEAPIScore Delegate &1*CSSmartSiriVolume CSSmartSiriVolume Processor RAJAudioDeviceCSSmartSiriVolume Estimate CSSuddenT ermination ProtectorCSNNVADEndpointAnalyzer SNResultsObservingqqa BCSAttSiriFlexKwdNodeCSFlexKeywordSpotterDelegate!
CSGestureMonitor CSRawAudio Injection Provider CSAsset ControllerCSEventMonitorDelegateUtils RTModelCSVoiceTrigger Enabled Policy Darwin CSAudioSessionProviding ProxyCSAudio SessionProviding Delegate!
CSSmartSiriVolume Run PolicyFactory CSAudioStreamRequestCS SpringboardStartMonitor CSP2PService CSMacWakeSleepMonitorCSAttSiriSSRNodeDelegate CSAttSiriSSRNodeCSSpeaker Re cognitionAssetDownloadMonitorDelegate!
CSMyriad PHash Factors CSMyriad PHashSignalEstimate CSX PCListener CSEndpointer Asset ManagerCSAsset ManagerDelegateCSFirst UnlockMonitorDelegateCSAudioStreamVCSAtt SiriCache
dEndpointInfoCSAttSiriEndpointerNodeDelegateCSAttSiriEndpointer NodeCSEndpointAnalyzerDelegateCSAttSiriOSDNodeDelegate!
CSVoiceTriggerFidesClientFides RecordInfoHelperCSAudio TimeConversionProviding ProxyCSSiriAudioSessionCSSiriAudio RouteCSAudioAlertProvidingProxyCSAudioAlert Providing
DelegateCSAlwaysOnProcessorStateMonitorCSVoiceTriggerFirstPassHearstAP/
CSManualDuckingHandlerCSDefaultAudioRouteChangeMonitorMacDelegateCSFlexKeywordResultCSFlexKeywordSpotter_ EARSpeechRecognitionResultStreamCSAudioInjection XPCListenerCSSelf Trigger DetectorEnabled Policy MacCSCommandControlBehavior MonitorCSAVVCRecording Client Monitor CSSmart SiriVolumeEnable PolicyCSAttSiriTimer CSOpportuneSpeakListnerTestServiceCSOpportune SpeakListenerDelegateCSOtherAppRecordingStateMonitor CSAudioInjectionBuiltInEngine QCSVoiceTriggerEnabledPolicy Horseman CSAutomatic Volume Enabled MonitorCSVoiceTriggerEnabled Policy Helper CSEndpointerSettings CSAlways Enabled PolicyCSFallbackAudioSessionReleaseProviding ProxyCSAudioSession Monitor CSAudio SessionEventProviding Delegate CSAttSiriAudioSrcNode!
CSSiriLauncherCSEventMonitor CSBuiltInVoiceTriggerCSVoiceTriggerXPCServiceProxy DelegateCSStateMachineDelegateCSAttSiriStateMonitorDelegateCSMacWakeSleepMonitorDele gateVA%CSEndpointerProxyCSEndpointAnalyzer ImplDelegate2!
SmartSiriVolume CSFirstUnlockMonitor CSAudioServerCrashMonitor CSAudioServerCrashEvent Providing Delegate CSAtt SiriOSDNodeCSAttSiriSignalDataAggregator ProtocolCSVTSecon dPassLatencyMetricsCSSelf TriggerDetector CSContinuousAudioFingerprintEnabledPolicyFactory Audio FileCSAudioDevice InfoCSSpeechEndpointAssetMetaUpdate MonitorCSAttSiriS tateMonitorLiminalCSSiriAssertion Monitor CSAudio Session Info ProviderCSUserIdentityClassifier CSAtt SiriAttending Trigger Event InfoCSAudioProviderCSAudioPreprocessorDele gate#!"Ŏ1CSVoiceTrigger InfoCSVoiceTriggerAOPModeEnabled PolicyFactorySpeaker RecognitionCSAssetControllerFactoryCSSAC InfoMonitorCSDarkWake PowerAssertionMacCSSpeaker RecognitionAssetDownloadMonitorCSAVCallConnected Monitor CSFallback AudioSessionReleaseProviderCSSpeaker RecognitionAssetMetaUpdateMonitorCSPreMyriad Voice TriggerMetaD ataCSPreMyriad Coordinator CSSecondPassProgress Delegate 5CSVoiceTriggerAssetHandlerFromFileCSAttSiriControllerCSSiriEnabled MonitorDelegate CSAtt SiriFlexKwdNodeDelegat eCSAttSiriSpeechDetectionNodeDelegate
CSPhraseSpotterEnabledMonitorCSEndpointerMetricsCSActivation XPCClientCSAdBlocker Asset Download Monitor CSVoiceTriggerAssetChangeMonitorCSVoiceTriggerXPCConnectionCSA
udioInjectionEngine!
CSSiriDebugConnection NSXPCLanguageCodeCSHostPowerSourceMonitorCSMyriad SelfTriggerCoordinatorCSContinuousAudioFingerprintEnabledPolicy CSAudio RouteChangeMonitorImpl MacCSActivation XPC ConnectionCSAudioInjectionDeviceaCSClamshellStateMonitorCSVoiceTriggerFileLoggerCSEndpointDelay ReporterCSVoice Profile RetrainManagerCSConnectionL istenerCSConnectionServiceDelegateCSVoiceTrigger AOPModeEnabled Policy IOSCSVoiceTrigger XPC Service ProxyCSVoiceTriggerAOPModeEnabled Policy MacCSAttSiriRequestContextCS AdBlockerAssetMetaUpdateMonitorCSVoiceTriggerAssetHandlerMac
CSSiriClientBehavior MonitorCSAudioProcessWaitingBufferCSAttSiriAsrNodeCoreEmbedded SpeechRecognizerDelegate14b1A#
CSLanguage Code Update Monitor ImplDarwinCSTrialAsset Download MonitorCSAssetCSOpportune SpeakEventMonitor CSOpportuneSpeak Behavior Monitor Delegate CSSystemUserActivityMoni torCSActivationEvent NotificationHandlerCSAudioConverterÁCSAdBlockerAsset DecoderFactoryCSVoiceTrigger SecondPass RequestOption% CSHybridEndpointer CSSelfTriggerDetectorEnabled PolicyASMacCSHangUpEnabledMonitorCSCXPhone CallStateMonitormachXPCCSVoiceTrigger RTModelCSPowerAssertionMacCSCommandCo ntrolStreamEventMonitor CSCommandControlBehavior MonitorDelegateCSPhone CallStateMonitor CSVoiceTriggerAssetMetaUpdateMonitorCSSpeechDetection DevicePresentMonitorCSAU dio TandemStreamCSTrialAsset ManagerCSPhraseNDEAPIScorer#CSAdBlocker Asset Decoder V3CSActivationXPCListenerCSActivateXPCConnectionDelegateCSRemoteRecordClient2CSConti nuousAudioFingerprintProviderc24@0:8@16#16@0:8@16@0:8@24@0:8:16@32@0:8:16@24@40@0:8:16@24@32c16@0:8c24@0:8#16c24@0:8:16Vv16@0:8Q16@0:8^{_NSZone=} 16@0:8c24@0:8@"Protocol"16@"NSString"16@0:8v24@0:8@16v32@0:8@16@24v24@0:8@"CSRemoteControlClient"16v32@0:8@"CSRemoteControlClient"16@"NSData"24v40@0:8@16@24@32v40 @0:8@"CSRemoteControlClient"16@"NSString"24@"NSString"32v24@0:8@?16c32@0:8@16@24v40@0:8@16@24@?32v28@0:8c16@?20v24@0:8q16c40@0:8@16q24@?32v24@0:8@?<v@? c>16v24@0:8@?<v@?c@"NSData"@"NSDictionary"Q>16c32@0:8@"SSRVoice Profile"16@"CSAsset"24v40@0:8@"CSAsset"16@"NSString"24@?<v@?c@"NSError">32v28@0:8c16@?<v@? c>20v24@0:8@?<v@?cc>16c40@0:8@"NSArray"16q24@?<v@? @"NSError">32v24@0:8@?<v@?Q>16v24@0:8@?<v@?>16v24@0:8@?<v@?q>16c56@0:8@16@24Q32@40@? 48v28@0:8Q16c24v24@0:8@"NSString"16v24@0:8@"CSRemoteDevice ProtocolInfo"16c56@0:8@"NSArray"16@"NSData"24Q32@"NSString"40@?<v@? @"NSError">48v24@0:8@?<v@? 40116@0:8@"NSObject<OS_dispatch_queue>"@"OS_xpc_remote_connection"@"CSDispatch Group"@"NSHashTable"I@"OS_remote_device"@"NSString"@"CSRemoteDevice Protocol Info"v40@ 0:8@"NSObject<OS_xpc_object>"16@"NSObject<OS_xpc_object>"24@"NSObject<OS_xpc_object>"32v40@0:8@"CSXPCConnection"16@"NSObject<OS_xpc_object>"24@"NSObject<OS_xpc_
@"NSArray"@"NSArray"@"NSArray">16v28@0:8c16@?<v@?c@"NSError">20@24@0:8@16v16@0:8c32@0:8d16^@24v48@0:8@16@24Q32@?40v48@0:8@16Q24@32@?
object>"32v24@0:8Q16@"<CSAudio MetricProviding>"@"CSXPCConnection"QQ24@0:8@16v32@0:8Q16@?
24124@0:8Q16q16@0:8qr*16@0:8iv44@0:8@16Q24c32@36v40@0:8@16Q24Q32v56@0:8@16Q24@32@40Q48v44@0:8@"CSAudioInjectionEngine"16Q24c32@"NSError"36v40@0:8@"CSAudioInjectionEngine"16Q24Q32v56@0:8@"CSAudioInjectionEngine"16Q24@"NSData"32@"NSData"40Q48v32@0:8@"CSAudioInjection Engine"16@"CSAudioChunkForTV"24@24@0:8Q16v20 @0:8c16c44@0:8@16f24@?28@?
36c@"<CSAudioInjectionEngine Delegate>"@"CSKeywordAnalyzerNDAPI"@"CSAudioCircular Buffer"@"CSAudioInjectionDevice"@"NSUUID"@72@0:8q16q24d32@40d48@56q64@64@0: AudioStreamBasic Description="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFrames Per Packet"I"mBytesPerFrame"I"m Channels PerFrame"I"mBitsPerChannel"I"mReserved"I}@"NSURL"d20@0:8f16v20@0:8f16v28@0:8@16c24@32@0:8d16Q24q24@0:8@16d24@0:8 [80s] 16@"NSMutableArray"@"NSMutableData"@"CSAudioStreamHolding"@"CSAudioProvider"@"
8q16q24d32@40d48@56d16@0:8v24@0:8d16d@"NSArray"f16@0:8f@"NSMutableDictionary"@"NSData"@32@0:8@16@24^{Opaque ExtAudioFile=}{
CSVoiceTriggerSecondPass"@"CSAsset"@"CSVoiceTriggerSecondChance Context"v40@0:8@"CSActivationEvent NotificationHandler"16@"CSActivationEvent"24@?<v@? c@"NSError">32v48@0:8@16@24@32@40v60@0:8@16@24c32@36@44@52v48@0:8@16@24Q32@40v56@0:8@16@24Q32@40@48v48@0:8@"CSAccessorySiriClientBehavior Monitor"16@"CSAudioRecordContext"24@"CSAudioStartStreamOption"32@"NSString"40v60@0:8@"CSAccessorySiriClientBehaviorMonitor"16@"CSAudioRecordContext"24c32@"CSAudioStartStreamOption"36@"NSString"44@"NSString"52v48@0:8@"CSAccessorySiriClientBehaviorMonitor"16@"CSAudioStopStreamOption"24Q32@"NSString"40v56@0:8@"CSAccessorySiriClientBehaviorMonitor"16@"CSAudio StopStreamOption"24Q32@"NSString"40@"NSString"48v32@0:8Q16@24v32@0:8Q16@"NSString"24v28@0:8c16@20v32@0:8@16@? 40@"<CSVoiceTriggerDelegate>"@"<CSSecondPass ProgressDelegate>"@"NSMutableOrdered Set"v32@0:8@16@"NSString"24v28@0:8@"CSScreen LockMonitor"16c24v36@0:8@16Q24c32v36@0 :8@"CSBluetooth Wireless SplitterMonitor"16024c32v28@0:8@"CSSystemUserActivityMonitor"16c24@40@0:8@16@24@32@48@0:8@16@24@32@40v44@0:8@16@24@32c40^{__IOPMConnection= 16@0:8v24@0:8^{__IOPMConnection=}
24v56@0:8@16@24@32@40@? 48v48@0:8@16@24@32@16v2000:8116@"CSRemoteControlClient"@"NSObject<OS_dispatch_source>"@"CSPolicy"@"CSVoiceTriggerEventsCoordinator"@"<CSDarwinVoiceTriggerHandlerDelegate>"@"CSDarwinPreventSystemSleepManager"@"CSVoiceTrigger DarwinHandlerTestContext"^{__IOPMConnection=}@
32@0:8q16Q24v24@0:8@"CSAudioServerCrashMonitor"16v32@0:8@16Q24@"AVVoiceTriggerClient"@24@0:8q16v40@0:8q16q24q32v32@0:8q16q24@"<CSStateMachineDelegate>"v36@0:8@ 16c24@28v32@0:8@16q24v28@0:8@16124v36@0:8@16124d28v36@0:8@16124@28v40@0:8@16Q24q32v40@0:8@16Q24@32v28@0:8@"AVVoiceController"16c24v36@0:8@"AVVoiceController"16c24 @"NSError"28v32@0:8@"AVVoiceController"16q24v24@0:8@"AVVoiceController"16v28@0:8@"AVVoiceController"16124v36@0:8@"AVVoiceController"16124d28v32@0:8@"AVVoiceController"16@"NSError"24v36@0:8@"AVVoiceController"16124@"NSError"28v40@0:8@"AVVoiceController"16@"AVVCAlert Information"24@"NSError"32v32@0:8@"AVVoiceController"16@"AVVCAudioBuffer"24v28@0:8c16@"NSArray"20v44@0:8@"AVVoiceController"16Q24c32@"NSError"36v40@0:8@"AVVoiceController"16Q24q32v40@0:8@"AVVoiceController"16024@"AVVCAudioBuffer"32v32@0:8@"AVVoiceController"16Q24v72@0:8@16Q24@32@40Q48Q56c64168v72@0:8@"CSAudio Decoder"16024@"NSData"32@"NSData"40Q48Q56c64168v40@0:8@16@24Q32v40@0:8@"CSAudioFileReader"16@"NSData"24Q32v36@0:8@"CSAudioFileReader"16c24@"NSError"28v32@0:8@"CSAudioFileReader"16q24v32@0:8Q16@"NSError"24v32@0:8@"NSData"16Q24v24@0:8@"CSRemote RecordClient"16v28@0:8@"CSUserSession ActiveMonitor"16c24v24@0:8@"<CSAudioServerCrashEventProvidingDelegate>"16v24@ 0:8@"<CSAudio SessionEvent ProvidingDelegate>"16@32@0:8@16^@24@24@0:8^@16v28@0:8c16Q20c40@0:8@16Q24^@32c40@0:8@16@24^@32c32@0:8@16^@24@32@0: 8Q16@24f24@0:8Q16c24@0: 8Q16c32@0:8Q16^@24c40@0:8q16Q24^@32c40@0:8Q16Q24^@32v40@0:8Q16c24@28c36v60@0:8@16Q24@32Q40Q48156@28@0:8@16124c36@0:8@16q24c32c32@0:8q16@24v36@0:8c16Q20@28v32@0: 8q16Q24@32@0:8@16Q24@"AVVoiceController"{AudioBufferList ="mNumber Buffers"I"mBuffers"[1{AudioBuffer="mNumberChannels"I"mDataByteSize"I"mData"^v}]} ^{AudioBuffer List=I [1{AudioBuffer=II^v}]}@"CSRemoteRecordClient"@"CSAudioFileReader"@"CSReusableBuffer Pool"@"<CSAudioServerCrashEventProviding Delegate>"@"<CSAudio SessionEvent Providing Delegate>"@"16@24@0:8@"CSAttSiriController"16v24@0:8@"<CSAttSiriNode>"16@"CSAttSiriController"16@0:8v24@0:8@"CSAttSiriController"16@"NSArray"16@0:8v24@0:8@"NSArray"16@"CSAsset"16@0:8v24@0:8@"CSAsset"16@"CSAttSiriController"v36@0:8@16@24c32v24@0:8c16c20v40@0:8@16q24@?
NSMutableSet"@20@0:8116c28@0:8116^I20c32@0:8116120^124@? @24@0:8^{_NSZone=}
@0:8@"LBLocalSpeechRecognition Settings"16Vv32@0:8Q16@"NSString"24Vv24@0:8@"NSString"16Vv48@0:8@"NSString"16@"NSString"24@"NSString"32@"NSString"40Vv32@0:8@"
cc@"NSArray">60v32@0:8Q16@?<v@?
32@"NSDate"@"SSRVoice Profile Manager"v72@0:8q16q24d32@40d48@56q64v32@0:8d16@?24v72@0:8q16q24d32@"NSArray"40d48@"NSString"56q64v24@0:8@?<v@? @"NSError"@"NSString">16v32@0:8d16@?<v@?c@"NSArray">24v24@0:8@?<v@? @"NSError"d>16v24@0:8@?<v@? @"NSError"Q>16v32@0:8d16@24v32@0:8d16@"CSEndpointerMetrics"24Vv32@0:8@16Q24Vv24@0:8@16Vv32@0:8Q16@24Vv48@0:8@16@24@32@40Vv32@0:8@16@24Vv32@0:8@"NSString"16Q24Vv24 AFSpeechCorrection Info"16@"NSString"24Vv40@0:8@16@24@32Vv48@0:8@16Q24@32d40Vv48@0:8@16Q24c32c36@40Vv48@0:8@16@24q32@40Vv56@0:8@16Q24@32d40@48Vv40@0:8@"NSString"16 @"NSString"24@"NSArray"32Vv32@0:8@"NSString"16@"AF Speech Package"24Vv48@0:8@"NSString"16024@"AFSpeech Package"32d40Vv48@0:8@"NSString"16024c32c36@"NSArray"40Vv48@0: 8@"NSDictionary"16@"NSString"24q32@"NSError"40Vv24@0:8@"AFVoice IdScore Card"16Vv48@0:8@"NSString"16@"NSString"24@"NSArray"320"AFSpeech InfoPackage"40Vv56@0:8@"NSString"16024@"AFSpeechPackage"32d40@"AFSpeechInfoPackage"48Vv40@0:8@"NSString"16@"AFSpeechPackage"24@"AFSpeechInfoPackage"32v24@0:8@"CSAttSiriRequestContext"16v24@0:8@"CSAttSiriAttendingTriggerEventInfo"16v24@0:8@"NSDictionary"16v68@0:8Q16d24d32d40@48c56@?60v68@0:8Q16d24d32d40@"NSString"48c56@?<v@? c>24@36@0:8@16c24c28c32@"CSConnectionListener"@"CSSpeechManager"v52@0:8@16@24c32@36@44v44@0:8@16c24@28@36v40@0:8@"CSSiriClientBehavior Monitor"16@"CSAudioRecordContext"24@"CSAudioStartStreamOption"32v52@0:8@"CSSiriClientBehavior Monitor"16@"CSAudio RecordContext"24c32@"CSAudioStartStreamOption"36@"NSString"44v40@0:8@"CSSiriClient Behavior Monitor"16@"CSAudioStopStreamOption"24032v40@0:8@"CSSiriClientBehaviorMonitor"16@"CSAudioStopStreamOption"24@"NSString"32v44@0:8@"CSSiriClientBehavior Monitor"16c24@"NSString"28@"CSAudio RecordContext"36v36@0:8@"CSSiriClientBehavior Monitor"16@"CSAudioStream"24c32v24@0:8@"CSSiriClientBehavior Monitor"16v32@0:8@"CSPhone CallStateMonitor"16Q24@56@0:8@16@24@32@40@48@"CSVoiceTriggerAirPodWearer DetectionConfig"@"CSPhone CallStateMonitor"@"CSOtherAppRecordingStateMonitor"@"CSSiriClientBehavior Monitor"@"CSVoiceTriggerEnabledMonitor"v32@0:8@16d24v32@0:8@"<CSAudio Stream Providing>"16q24v32@0:8@"<CSAudioStream Providing>"16@"CSAudioChunk"24v32@0:8@"<CSAudioStreamProviding>"16@"CSAudioChunkForTV"24v32@0:8@"<CSAudioStream Providing>"16d24v44@0:8@16@24c32@36@"<CSAudioStreamProviding>"@"<CSTrigger InfoProviding>"@"CSAudioStream"@"CSAudioRecordContext"@32@0:8Q16Q24@"NS Number"v36@0:8@16c24Q28@52@0:8@16@24@32c40@44@"CSAsset Manager"@"CSTrialAsset Manager"@"CSTrialAsset DownloadMonitor"v32@0:8116@20c28v32@0:8Q16Q24v36@0:8@"<CSAttSiriNode>"16c24@"NSError"28v32@0:8@"<CSAtt SiriNode>"16@"CSAudioChunk"24@36@0:8Q16@24c32@"NSDictionary"v40@0:8@"CSPhraseNDEAPIScorer"16Q24Q32v28@0:8@"CSVoiceTriggerEnabledMonitor"16c24v32@0:8@"CSMediaPlaying Monitor"16q24v28@0:8@16f24v28@0:8@"CSVolumeMonitor"16f24v32@0:8@"SSRSpeaker RecognitionController"16@"NSDictionary"24v32@0:8@"CSSelfTrigger Detector"16@"NSDictionary"24@44 @0:8c16@20@28@36@20@0:8c16v56@0:8Q16@24@32@40@?48v40@0:8Q16Q24Q32v36@0:8@16@24f32v44@0:8Q16@24c32@36@? 16@0:8@"CSVoiceTriggerSecondPassConfig"@"CSPhraseDetector"@"CSPhraseNDEAPIScorer"@"SSRSpeaker RecognitionController"@"SSRSpeaker RecognitionContext"@"CSPlainAudioFileWriter"@"CSAudioTimeConverter"@"CSVoiceTriggerFirstPassMetrics"@"CSVT SecondPassLatencyMetrics"v40@0:8@"CSVoiceTrigger AwareZeroFilter"16@"NSData"24Q32v40@0:8@"CSBeepCanceller"16@"NSData"24Q32@24@0:8f16120v32@0:8f16c20@24c20@0:8f16116@0:8v20@0:8116@"<CSAudioPreprocessorDelegate>"@"CSAudio SampleRateConverter"@"CSVoiceTriggerAwareZeroFilter"@"CSBeepCanceller"@"CSAudioZeroCounter"c32@0:8^c16^Q24Q24@0: 8Q16@"<CSBiometric MatchMonitorDelegate>"c32@0:8@16024@"<CSXPCConnectionDelegate>"@"NSObject<OS_xpc_object>"@"CSAudioSession Providing Proxy"@"CSFallbackAudioSessionReleaseProviding Proxy"@"CSAudioStreamProvidingProxy"@"CSAudioAlert Providing Proxy"@"CSAudioMeterProviding Proxy"@"CSAudioMetricProviding Proxy"v32@0:8@"CSAudioRouteChangeMonitor"16q24v60@0:8@16@24Q32@40c48@? 52v32@0:8@"NSDictionary"16@"NSString"24v40@0:8@"NSDictionary"16@"NSString"24@?<v@?>32v24@0:8@"NSData"16v60@0:8@"NSDictionary"16@"NSData"24Q32@"NSString"40c48@?
<v@?
>52@2000:8f16@"<CSSPGEndpointAnalyzerDelegate>"@40@0: 8@16@24Q32@36@0:8@16f24Q28@52@0:8Q16@24@32f40Q44@48@0:8Q16@24@32040@"NSObject<OS_dispatch_group>"c24@0:8d16@"<CSAudioFileReaderDelegate>"v24@0:8@"CSDarwinVoiceTriggerHandler"16@"OS_remote_device_browser"@"CSAudioInjectionEngine"v40@0:8@"CSVoiceTriggerXPCConnection"16@"NSObject<OS_xpc_object>"24@"NSObject<OS_xpc_object>"32124@0:8@16Vv24@0:8@?16Vv32@0:8@16@?24Vv40@0:8@16q24@?32Vv24@0:8@?<v@? @"NSString">16Vv32@0:8@"NSString"16@? <v@?@"NSString">24Vv40@0:8@"NSArray"16q24@?<v@?@"NSError">32Vv24@0:8@?<v@?Q>16Vv24@0:8@?<v@?>16Vv24@0:8@?<v@?c>16Vv24@0:8@?<v@? q>16@96@0:8{AudioStreamBasic Description=dIIIIIIII}16{AudioStreamBasicDescription=dIIIIIIII}56^{Opaque AudioConverter=}96@0:8{AudioStreamBasic Description=dIIIIIIII}
16{AudioStreamBasicDescription=dIIIIIIII}56^{Opaque AudioConverter=}C16@0:8v52@0:8@16c24@28@36@44v48@0:8@16Q24@32@40@"CSAtt SiriOSDNode"@"CSAttSiriNLDAClassifier Node"@"CSAttSiriSSRNode"v32@0:8@"CSAlarmMonitor"16q24v32@0:8@"CSTimer Monitor"16q24v28@0:8@"CSAutomaticVolumeEnabled Monitor"16c24@28@0:8f16@20@40@0:8Q16@24Q32@"<CSConnection ServiceDelegate>"@"<CSSmartSiriVolume Processor>"c32@ 0:8@"NSXPCListener"16@"NSXPC Connection"24@"CSGibraltarVoiceTriggerHandler"@"NSXPCListener"v52@0:8@16@24f32Q36Q44v52@0:8@"CSAudio Converter"16@"NSArray"24f32Q36Q44@"CSAudioConverter"@68@0:8@16f24{AudioStreamBasicDescription=dIIIIIIII}28{Audio StreamBasicDescription=dIIIIIIII} 16@0:8v56@0:8{AudioStreamBasicDescription=dIIIIIIII}16^{Opaque ExtAudioFile=}16@0:8v24@0:8^{Opaque ExtAudio File=}16v48@0:8Q16@24@32@?
40@56@0:8Q16@24@32@40Q48v24@0:8@"NSCoder"16@24@0:8@"NSCoder
"16@44@0:8@16c24@28@36@52@0:8@16c24@28@36@44v48@0:8@16@24^@32^@40@44@0:8@16@24c32Q36@"CSXPCListener"@"
CSActivationXPCListener"@"CSVoiceTriggerXPCListener"@"CSAudioInjection XPCListener"@"CSDarwinVoiceTriggerHandlerPool"@"CSCoreSpeechServicesListener"@"CSAttSiriConnectionManager"@32@0:8@16d24@"CSAttSiriEndpointerNode"@"CSAttSiriUresNode"v56@0:8q16@24@32@40@?48v44@0:8@16@24f32@?36v48@0:8@16@24f32136@? 40v32@0:8@"NSString"16@?<v@? @"NSString">24v56@0:8q16@"NSString"24@"NSString"32@"NSString"40@?<v@?c@"NSError"@"NSUUID">48v44@0:8@"NSURL"16@"NSUUID"24f32@?<v@? c@"NSError"QQ>36v48@0:8@"NSURL"16@"NSUUID"24f32136@?<v@?c@"NSError"QQ>40v32@0:8@"NSUUID"16@?<v@?c@"NSError">24v24@0:8@?<v@? c@"NSError"@"NSUUID">16{AudioStreamBasic Description=dIIIIIIII}
20@0:8116@"NSMapTable"c24@0:8^@16c48@0:8Q16Q24@32^@40v28@0:8116f20f24v24@0:8f16f20v24@0:8@"<CSAudioSession Providing Delegate>"16c48@0:8Q16Q24@"NSString"32^@40@40@0 :8@16@24^@32@40@0: 8Q16Q24Q32v40@0:8Q16Q24@32c32@0:8@"CSAudio RecordContext"16^@24@"CSAudioStream"40@0:8@"CSAudioStreamRequest"16@"NSString"24^@32v40@0:8@"
CSAudioStreamRequest"16@"NSString"24@?<v@?@"CSAudioStream"@"NSError">32v40@0:8@"CSAudioStream"16@"CSAudioStream"24@?<v@? c@"NSError">32c40@0:8@"CSAudio Stream"16@"CSAudioStreamRequest"24^@32v40@0:8@"CSAudioStream"16@"CSAudioStreamRequest"24@?<v@? c@"NSError">32v40@0:8@"CSAudio Stream"16@"CSAudioStartStreamOption"24@?<v@?c@"NSError">32v40@0:8@"CSAudioStream"16@"CSAudioStopStreamOption"24@?<v@? c@"NSError">32@"CSAudioChunk"32@0:8Q16Q24@"CSAudio Chunk"40@0:8Q16Q24Q32@"CSAudio Chunk"24@0:8Q16v40@0:8Q16Q24@"NSURL"32v32@0:8Q16@"NSURL"24@"CSAudioStreamHolding"32@0:8@"NSString"16d24v24@0:8@"CSAudioStreamHolding"16@"CSAudio RecordDeviceInfo"16@0:8@"CSAudio DeviceInfo"16@0:8@"NSDictionary"16@0:8c24@0:8q16v24@0:8@"<CSAudioAlert ProvidingDelegate>"16c36@0:8@"NSURL"16q24c32124@0:8@16v24@0:8@"<CSAudioSessionInfoProvidingDelegate>"16124@0:8@"NSString"16v32@0:8@"CSAudioRecordContext"16@?<v@? @"NSDictionary"@"NSDictionary">24@"<CSAudio Session ProvidingDelegate>"@"<CSAudioStream ProvidingDelegate>"@"<CSAudioAlertProviding Delegate>"@"<CSXPCClientDelegate>"v36@0:8@16d24f32@"<CSOpportune SpeakListenerDelegate>"@"CSSPGEndpoint Analyzer"@"<CSAudioSession Providing>"v48@0:8@16@24@32040v36@0:8c16@20@28@"<CSAudioMeter Providing>"v32@0:8@"CSAssetController"16024v40@0:8Q16@24@?32v48@0:8Q16@24Q32@?40v48@0:8Q16Q24@32@? 40@"CSAssetDownloadingOption"@24@0:8d16@"CSPrevent SystemSleepPowerAssertion"v36@0:8Q16Q24c32v32@0:8Q16@"CSAudioRecordContext"24v24@0:8@"CSAudioChunk"16@"<CSEndpointAnalyzerDelegate>"16@0:8v24@0:8@"<CSEndpointAnalyzer Delegate>"16@"<CSEndpointAnalyzer ImplDelegate>"16@0:8v24@0:8@"<CSEndpointAnalyzer ImplDelegate>"16v24@0:8@"CSServerEndpointFeatures"16v32@0:8@"NSString"16@"NSString"24v32@0:8@"OSDFeatures"16d24v32@0:8@"NSDate"16Q24v28@0:8@"CSServerEndpointFeatures"16c24@"<CSEndpointAnalyzerDelegate>"@"<CSEndpointAnalyzer ImplDelegate>"v40@0:8@"CSVoiceTriggerAssetHandler"16@"NSString"24@"CSAsset"32v68@0:8@16Q24@32@40Q48Q56164v40@0:8 @16q24@32v68@0:8@"CSAudioRecorder"16024@"NSData"32@"NSData"40Q48Q56164v40@0:8@"CSAudioRecorder"16024@"CSAudioChunkForTV"32v44@0:8@"CSAudioRecorder"16024c32@"NSError"36v40@0:8@"CSAudioRecorder"16024q32v32@0:8@"CSAudioRecorder"16q24v40@0:8@"CSAudioRecorder"16q24@"NSError"32v24@0:8@"CSAudioRecorder"16v32@0:8@"CSAudioRecorder"16@"NSDictionary"24v28@0:8@"CSAudioRecorder"16c24v32@0:8@"CSAudioRecorder"16@"NSError"24v32@0:8@"CSAudio Provider"16024v28@0:8@""16c24v32@0:8@?16@?24v40@0:8Q16@?24@?
CSOpportuneSpeakEventMonitor
32@"CSAudioRecorder"@"CSFallbackAudioSessionReleaseProvider"@"<CSSpeechManagerDelegate>"@"CSBuiltInVoiceTrigger"@"CSPreMyriad Coordinator"@"CSVoiceTriggerFileLogger"@"CSSelfTriggerDetector"@"CSKeyword Detector"@"CSMyriadPHash"@"CSMyriad SelfTriggerCoordinator"@"CSVoiceTriggerFidesClient"@"CSVoiceTriggerFirstPassJarvis"@"CSVoiceTriggerFirstPass Hearst"@"CSVoiceTriggerFirstPassHearst AP"@"CSVoiceTriggerFirstPassRemora"@"CSVoiceProfile Retrain Manager"@"CSOpportuneSpeakListner TestService"@"CSPostBuildInstallService"@"CSSmartSiriVolumeManager"v48@0:8^{__CFString=}16d24^132^{__CFString=}40v32@0:8^116^__CFString=} 24@"<CSVoiceTrigger AwareZeroFilterDelegate>"@"CSAudioZeroFilter"@28@0:8f16120f24v32@0:8r^v16Q24{unique_ptr<corespeech:: CSAudioCircularBufferImpl<unsigned char>, std::default_delete<corespeech:: CSAudioCircularBufferImpl<unsigned char>>>="__ptr_"{__compressed_pair<corespeech:: CSAudioCircularBufferImpl<unsigned char> *, std::default_delete<corespeech:: CSAudioCircular BufferImpl<unsigned char>>>="__value_"^v}}c24@0:8^{?=[81]} 16@"STMediaStatusDomainPublisher"@"NSSet"v40@0:8@"CSKeywordAnalyzerNDEAPI"16@"CSKeyword Analyzer NDEAPIResult"24Q32@"CSKeywordAnalyzerNDEAPI"@"CSKeywordAnalyzerNDEAPIResult"@"CSVoiceTriggerRTModel"@28@0:8f16@"CSAsset"20@"CSSmartSiriVolume Estimate"40@0:8Q16@"NSNumber"24Q32v28@0:8116q20v52@0:8@ std::default_delete<SmartSiriVolume>>="__ptr_"{__compressed_pair<SmartSiriVolume *, std::default_delete<SmartSiriVolume>>="_ _value_"^{SmartSiriVolume}}}{
16q24c32Q36Q44f24@0:8q16f24@0:8f16f20f20@0:8f16f36@0:8f16f20f24f28f32f44@0:8f16f20f24f28f32f36f40f28@0:8f16f20f24^f24@0:8@16{unique_ptr<SmartSiriVolume,
vector<float, std::allocator<float>>="__begin_"^f"__end_"^f"__end_cap_"{__compressed_pair<float *, std::allocator<float>>="__value_"^f}}@
"NSUserDefaults"v32@0:8@"<SNRequest>"16@"<SNResult>"24v32@0:8@"<SNRequest>"16@"NSError"24v24@0:8@"<SNRequest>"16d24@0:8@16v32@0:8d16Q24@"SNAudioStreamAnalyzer"@"AVAudioFormat"@"<CSAudioFileWriter>"v24@0:8@"CSFLexKeyword Result"16@"CSFlexKeywordSpotter"@"CSAttSiriRequestContext"^{__SFILE=*iiss{__sbuf=*i}i^v^?^?^?^? 16^{__sFILE=xiiss{__sbuf=xi}i^v^?APAP^?{__sbuf=xi}^{__sFILEX}i[3C][1C]{__sbuf=xi}iq}v4000:8@16Q24@?32v4000:8@16@?24@?
{__sbuf=xi}^{__sFILEX}i[3C][1c]{__sbuf=xi}iq}16@0:8v24@0:8^{__sFILE=xiiss{__sbuf=xi}i^v^?APAP^?{__sbuf=xi}^{__sFILEX}i[3C][1c]{__sbuf=xi}iq}
32@40@0:8@16024@32v32@0:8^@16Q24@48@0:8q16Q24Q32@40@40@0:8Q16Q24@32v24@0:8@"<CSAudioSessionProviding>"16v32@0:8@"<CSAudioSession Providing>"16@"NSDictionary"24v28@
0:8@"<CSAudio Session Providing>"16c24v44@0:8c16@20@28@36@"CSManualDuckingHandler"v44@0:8@16@24c32@?
36v72@0:8@16@24@32c40Q44@52c60@64@80@0:8@16@24@32c40Q44@52c60@64@?
72@"<CSADCompanionServiceProvider>"v32@0:8@"<CSAttSiriNode>"16@"NSDictionary"24v44@0:8@16f24f28d32c40@"SSRVoiceProfile"@40@0:8S16C20C24Q28C36S16@0:8CS@40@0:
8S16C20C24d28C36@28@0:8Q16c24d32@0:8^f16Q24S28@0:8^f16124v48@0:8^f16Q24Q32^v40v40@0:8^f16Q24^v32@80@0:8Q16Q24Q32c40f44@48Q56@64Q72@28@0:8@16c24s16@0:8v20@0:
8s16v20@0:8C16^f^{Opaque FFTSetup=}sd24@0:8@?
16v24@0:8@"CSAsset Manager"16v28@0:8@"CSFirstUnlockMonitor"16c24@"CSAudioStreamRequest"@"CSAudioStartStreamOption"@"CSEndpointerMetrics"v40@0:8@16d24@32v40@0:8@"
<CSAttSiriNode>"16d24@"CSEndpointerMetrics
"32v32@0:8@"<CSAttSiriNode>"16d24v32@0:8@"<CSEndpointAnalyzer>"16d24v40@0:8@"<CSEndpointAnalyzer>"16d24@"
CSEndpointerMetrics"32v40@0:8@16@24d32v48@0:8@16@24Q32Q40v44@0:8@16Q24Q32c40v40@0:8@"<CSAttSiriNode>"16@"OSDFeatures"24d32v48@0:8@"<CSAttSiriNode>"16@"NSDate"24032040v44@0:8@"<CSAttSiriNode>"16Q24Q32c40v48@0:8Q16@24@32@40v76@0:8q16q24d32@40d48@56q64c72@"CSEndpointer Proxy"@"CSEndpointLatency Info"@"CSAttSiriCached Endpoint Info"v32@0:8q16@24@"CSSiriAudioRoute"v40@0:8@"<CSAudioAlertProviding>"16q24@"NSError"32@"<CSAudioAlert Providing>"@64@0:8@16@24@32@40@48@56@"CSOSTransaction"@"CSOpportune SpeakEvent Monitor"v28@0:8@"CSDefaultAudioRouteChangeMonitorMac"16c24@44@0:8@16f24q28q36v72@0:8@16q24q32d40@48d56q64v32@0:8@".EARSpeechRecognizer"16@"_EARSpeechRecognition Result"24v32@0:8@"_EARSpeechRecognizer"16@"NSError"24v32@0:8@"_EARSpeechRecognizer"16@"NSArray"24v48@0:8@".EARSpeechRecognizer"16@"NSArray"24@"NSArray"32@"NSArray"40v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeech Recognition ResultPackage"24v32@0:8@"_EARSpeechRecognizer"16d24v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognition"24v72@0:8@"_EARSpeechRecognizer"16q24q32d40@"NSArray"48d56q64@"<CSFLexKeywordSpotter Delegate>"@".EARSpeechRecognizer"@"_EARSpeechRecognitionAudioBuffer"@"CSAudioInjection XPC"v32@0:8@16c24f28v28@0:8@"CSOpportune SpeakListener"16c24v32@0:8@"CSOpportuneSpeakListener"16c24f28@"CSOpportuneSpeakListener"q24@0:8q16v48@0:8@16@24@32^v40v40@0:8q16Q24@32v28@0:8@"CSVoiceTriggerXPCServiceProxy"16c24v32@0:8@"CSAttSiriState Monitor"16Q24v28@0:8@"CSMacWake Sleep Monitor"16c24v56@0:8Q16@24@32@40@48@"CSVoiceTriggerFirstPassConfig"@"CSKeyword AnalyzerNDAPIResult"@"CSStateMachine"@"CSVoiceTriggerAlwaysOnProcessor"@"CSAudio RouteChangeMonitor"@"CSDarkWakePowerAssertion Mac"@"CSPowerAssertionMac"v32@0:8@"<CSEndpointAnalyzerImpl>"16d24v40@0:8@"<CSEndpointAnalyzer Impl>"16Q24Q32@"<CSEndpointAnalyzer Impl>"c32@0:8Q16Q24@"CSContinuousVoice TriggerConfig"c32@0:8@16@? 24@"CSAudioRecordDeviceInfo"Q40@0:8@16@24@32v52@0:8@16@24Q32Q40148v52@0:8@"CSAudioPreprocessor"16@"NSData"24Q32Q40148@56@0:8Q16q24@32@40@48@48@0:8Q16q24@32@40c32@ 0:8Q16q24@"<CSAudioProviderDelegate>"@"CSAudioPreprocessor"@"CSAudioRecordDeviceIndicator"@"CSMicUsageReporter"@"CSADPPrevent Standby Assertion"v40@0:8Q16@24d32v40@ 0:8Q16@"NSString"24d32@"<CSSecondPassProgress Providing>"@"CS PreMyriad Voice TriggerMetaData"v28@0:8@"CSSiri Enabled Monitor"16c24v32@0:8@"<CSAtt SiriNode>"16@"CSAttSiriAttending Trigger Event Info"24@132@0:8@16@24@32@40@48@56c64@68@76@84@92@100@108c116c120c124c128@"CSAttSiriRCHandler"@"CSAttSiriAsrNode"@"CSAttSiriAudioSrc Node"@"CSSiriEnabled Monitor"@"CSAttSiriFlexKwd Node"@"CSAtt SiriAFTMNode"@"CSAtt SiriSpeech DetectionNode"@72@0:8d16Q24@32q40@48@56d64@"<CSVoiceTriggerAsset ChangeDelegate>"@"<CSVoiceTriggerXPCConnectionDelegate>"c84@0:8@16f24{Audio StreamBasicDescription=dIIIIIIII}28@?68@? 76@24@0:8^{AudioBufferList=I [1{AudioBuffer=II^v}]}16^{Opaque Audio Converter=}16@0:8v24@0:8^{Opaque AudioConverter=}16^{AudioBufferList = I [1{AudioBuffer=II^v}]} 16@0:8v24@0:8^{AudioBufferList = I [1{AudioBuffer=II^v}]}16@"CSAudioInjectionFileOption"^{__CFRunLoopSource=}@"<CSMyriadSelfTriggerCoordinatorDelegate>"c20@0:8116@"<CSActivateXPCConnectionDelegate>"@48@0:8q16@24@32@40^{IONotificationPort=}@32@0:8@16c24c28v24@0:8@?<v@? @>16@"NSXPCInterface"@v36@0:8c16@20d28v28@0:8c16d20@"CSSiriAssertion Monitor"@"CSVoiceTriggerAssetDownload Monitor"@"CSLanguageCodeUpdateMonitor"@"CSFirstUnlock Monitor"v32@0:8@"CoreEmbeddedSpeechRecognizer"16@"CESRModelProperties"24v32@0:8@"Core Embedded SpeechRecognizer"16@"NSArray"24v32@0:8@"CoreEmbeddedSpeechRecognizer"16d24v32@0:8@"CoreEmbedded SpeechRecognizer"16@"AF SpeechRecognition"24v32@0:8@"CoreEmbeddedSpeechRecognizer"16@"AFSpeech Package"24v40@ 0:8@"CoreEmbedded SpeechRecognizer"16@"NSDictionary"24@"NSError"32v72@0:8@"CoreEmbeddedSpeechRecognizer"16q24q32d40@"NSArray"48d56q64v40@0:8@"CoreEmbedded SpeechRecognizer"16@"NSArray"24@"AFSpeech InfoPackage"32v40@0:8@"CoreEmbedded SpeechRecognizer"16@"AFSpeechPackage"24@"AFSpeechInfoPackage"32@36@0:8@16@ 24c32v40@0:8d16@24Q32v52@0:8@16Q24d32c40@44@"CoreEmbedded SpeechRecognizer"@"CSAudio ProcessWaitingBuffer"@"LBLocalSpeech Recognition Settings"@"CSEndpointDelay Reporter"v52@0:8@16@24@32c40@44v48@0:8@"CSOpportuneSpeakBehavior Monitor"16@"CSAudio RecordContext"24@"NSString"32@"CSAudioStartStreamOption"40v52@0: 8@"CSOpportuneSpeakBehavior Monitor"16@"CSAudioRecordContext"24@"NSString"32c40@"CSAudioStartStreamOption"44v32@0:8@"CSOpportuneSpeakBehavior Monitor"16@"CSAudioStopStreamOption"24@"CSActivation Event"v44@0:8@16c24Q28Q36@"<CSAudio ConverterDelegate>"@68@0:8Q16@24@32@40@48c56@60v40@0:8@"CSCommandControlBehavior Monitor"16@"CSAudioRecordContext"24@"CSAudioStartStreamOption"32v44@0:8@"CSCommandControlBehavior Monitor"16@"CSAudioRecordContext"24c32@"CSAudioStartStreamOption"36v32@0 :8@"CSCommandControlBehavior Monitor"16@"CSAudioStopStreamOption"24@60@0:8@16@24Q32Q40@48c56@"<CSPhraseNDEAPIScorerDelegate>"@"CSShadowMicScoreCreator"v40@0:8@"CSActivationXPC Connection"16@"NSObject<OS_xpc_object>"24@"NSObject<OS_xpc_object>"32@"<CSRemoteRecordClientDelegate>"softlink:r:path: /System/Library/ PrivateFrameworks/SystemStatus.framework/SystemStatusX`NX!
 ́d°ÖT#ÊOT_AFLanguageCodeDidChangeDarwin Notification_AFMach Absolute Time Add TimeInterval_AFPreferencesAssistantEnabled_AFSiriActivationHoneycomb Device Voice Trigger_ AFSiriActivationServiceGetPort_AFSiriActivationUserInfoKey_AFSiriActivation Voice KeywordDetected_AFSiriActivation VoiceTriggerActivate_ AFSiriActivation Voice Trigger Prewarm_AFUserIdentityClassficationGetName_ASAttributeCompatibility Version_ASAttributeContentVersion_AVAudioSession PortDisplayPort_ AVEncoderBitRateKey_AVFormatIDKey_AVLinear PCMBitDepth Key_AVLinear PCMIS Float Key_AVLinear PCMIsNonInterleaved_AVNumberOfChannelsKey_AVSampleRateConverter AlgorithmKey _AVSampleRateConverterAlgorithm_Mastering_AVSampleRateKey_AVVoice ActivationDeviceIDKey_AVVoiceActivationModeKey_AVVoiceControllerBluetoothDoAPRoute_ AVVoiceControllerMetricAudioSessionSetActiveTime_AVVoiceControllerMetricAudioSessionSetInactive Time_AVVoiceControllerMetric DataBeginHostTime_
AVVoiceControllerMetric DataEndHostTime_AnalyticsSendEventLazy_AudioComponentRegister_AudioConverterConvertComplexBuffer_AudioConverter Dispose_
AudioConverterFillComplexBuffer_AudioConverterGetProperty_AudioConverterNew_AudioConverterReset_AudioConverter SetProperty_AudioDevice Duck_AudioFileClose_
AudioFileOpenURL_AudioObjectAddPropertyListenerBlock_AudioObjectGetPropertyData_AudioObjectGetPropertyDataSize_AudioObjectHasProperty_
AudioObjectRemove Property Listener Block_CC_SHA1_CC_SHA256_CFBooleanGetTypeID_CFBooleanGetValue_CFDictionaryGetValue_CFGetTypeID_CFNotificationCenterAddObserver_ CFNotificationCenterGetDarwin NotifyCenter_CFNotificationCenterPostNotification_CFNotification CenterRemoveObserver_CFRelease_CFRunLoop AddSource_CF Run LoopGetCurrent CFRunLoopGetMain_CFRunLoopRemoveSource CFStringCreateWithCString_CFStringGetTypeID_CSHasAOP_CSISASMacWithAOP_CSISAppleSilicon Mac_CSIsBridgeOS_CSIS CommunalDevice_ CSIsHorseman_CSIsHorseman Junior_CSISIOS_CSISIPad_CSISIPhone_CSIsInternalBuild_CSIsMac_CSIS OSX_CSIS TV_CSIS Torpedo_CSIsWatch_CSLogContextFacilityCoreSpeech_ CSLogInitIfNeeded_CSMachAbsolute TimeGetTime Interval_CSMach Absolute Time Subtract Time Interval_CSSafeSetOutErrorWithNSError_CSShouldCensorSpeech_ CoreEmbeddedSpeechRecognizerInstanceUUIDInteractive_CoreEmbedded SpeechRecognizerSourceAssistant_CoreEmbedded SpeechRecognizerSource Dictation_ CoreEmbedded SpeechRecognizerTaskSearchOr Messaging_CoreEmbeddedSpeechRecognizerTaskSiriDictation_ExtAudioFileCreateWithURL_ExtAudioFileDispose_ ExtAudioFileGetProperty_ExtAudioFileOpenURL_ExtAudioFileRead_ExtAudioFileSeek_ExtAudioFileSetProperty_ExtAudio FileWrap AudioFileID_ExtAudioFileWrite_ IOALLowPowerChange_IOMasterPort_IONotificationPortCreate_IONotificationPortDestroy_IONotification PortGetRunLoopSource_10ObjectRelease_ IOPMAssertionCreateWithDescription_IOPMAssertionCreateWithName_IOPMAssertionDeclare NotificationEvent_IOPMAssertionRelease_IOPMAssertionSetProperty_
IOPMConnectionAcknowledgeEvent_IOPMConnectionCreate_IOPMConnectionRelease_IOPMConnectionSetDispatchQueue_IOPMConnectionSetNotification_IOPMISADarkWake_ IOPMISASleep_IOPMI SAUserWake_IOPSGetTime RemainingEstimate_IOPSNotificationCreateRunLoopSource_IORegisterForSystem Power_IORegistryEntryCreateCFProperty_ IORegistryEntry FromPath_IOService Add InterestNotification_IOServiceGetMatchingService_IOServiceMatching_IOServiceNameMatching_LBLocalSpeechServiceName_ MKBDeviceUnlockedSinceBoot_MKBGetDeviceLockState_NSClassFromString_NSFile Protection Complete UnlessOpen_NSFile Protection Complete UntilFirstUserAuthentication_ NSFileProtectionKey_NSLocalizedDescriptionKey_NSOSStatusErrorDomain NSStringFromClass_NSURLCreationDateKey_NSURLISDirectoryKey_NSURLNameKey_ NSWorkspaceSession DidBecomeActive Notification_NSWorkspaceSessionDid ResignActiveNotification_SHMediaItemTitle_SSRLogContextFacility CoreSpeech_ SSRSpeaker RecognitionAssetArrayKey_SSRSpeaker RecognitionAssetKey_SSRSpeaker RecognitionLocaleKey_SSRSpeakerRecognition MaxAudio DurationSecs_ SSRSpeaker RecognitionOSTransactionRequired_SSRSpeaker RecognitionProfileArrayKey_SSRSpeaker RecognitionSiriAppDomain_SSRSpeaker RecognitionSiriCCAppDomain_ SSRSpeaker RecognitionSiriDebug AppDomain_SSRSpeaker RecognitionStyleKey_SSRSpeaker RecognitionUsePayloadProfileKey_SSRSpeaker Recognition VTEvent InfoKey_ SSRVoice RetrainingAssetKey_SSRVoice RetrainingFilterToVoice TriggerUtterances Key_SSRVoiceRetrainingPayloadProfileKey_SSRVoice Retraining Voice ProfileKey_XPC_ACTIVITY_ POST_INSTALL__Block_object_assign__Block_object_dispose__IDSCopy IDFor Device Unique ID__MACleanV1Repository__NSConcreteStackBlock__Unwind_Resume__ZNKSt3__120__vector _base_common ILb1EE20__throw_length_errorEv__ZNSt11logic_error C2EPKc__ZNSt12length_errorD1Ev__ZNSt12out_of_rangeD1Ev__ZSt9terminatev__ZTIST12length_error__ ZTIST12out_of_range__ZTISt9exception__ZTVSt12length_error__ZTVSt12out_of_range__ZdaPv__ZdlPv__Znam__Znwm___NSArray@__struct___NSDictionary@__struct__ darwin___assert_rtn___bzero___cxa_allocate_exception___cxa_begin_catch___cxa_end_catch___cxa_free_exception___cxa_throw___error___exp10f___gxx_personality_v0_ timer__os_feature_enabled_impl__os_log_debug_impl__os_log_error_impl__os_log_fault_impl__os_log_impl__os_signpost_emit_with_name_impl__set_user_dir_suffix__sl_ dlopen__xpc_error_connection_interrupted__xpc_error_connection_invalid__xpc_error_key_description__xpc_type_array__xpc_type_bool__xpc_type_data__xpc_type_ dictionary__xpc_type_double__xpc_type_error__xpc_type_int64__xpc_type_string__xpc_type_uint64_abort_report_np_bootstrap_port_calloc_compression_decode_buffer_ create_dispatch_group_enter_dispatch_group_leave_dispatch_group_notify_dispatch_group_wait_dispatch_once_dispatch_queue_attr_make_with_autorelease_frequency_ signal_dispatch_semaphore_wait_dispatch_set_target_queue_dispatch_source_cancel_dispatch_source_create_dispatch_source_set_event_handler_dispatch_source_set_timer
chkstk_
KCFBooleanFalse___kCFBoolean True___objc_personality_v0___stack_chk_fail___stack_chk_guard__dispatch_main_q__dispatch_source_type_signal__dispatch_source_type_
compression_encode_buffer_confstr_cosf_dispatch_after_dispatch_assert_queue $V2_dispatch_async_dispatch_async_and_wait_dispatch_get_global_queue_dispatch_group_
dispatch_queue_attr_make_with_qos_class_dispatch_queue_create_dispatch_queue_create_with_target $V2_dispatch_resume_dispatch_semaphore_create_dispatch_semaphore_
_dispatch_source_testcancel_dispatch_suspend_dispatch_sync_dispatch_time_dlopen_dlsym_exit_expf_fopen_fread_free_fseek_getenv_getpwuid_getuid_
KAFPreferencesDidChangeDarwin Notification_kCFAllocatorDefault_kCFBooleanTrue_kCF Run LoopCommon Modes_kCFRunLoopDefaultMode_kCSAudioSyncedFileSuffix_
KCSDiagnosticReporterAudioDeliveryWatchDogFire_KCSDiagnosticReporter Audio DidStartWatchDogFire_kCSDiagnosticReporter AudioDidStopWatchDogFire_ KCSDiagnosticReporterAudioResourceNotAvailable_kCSDiagnostic Reporter AudioStreamDeallocDuringStreaming_kCSDiagnostic ReporterConsective False FirstPassTriggers_ KCSDiagnostic ReporterRemoteCoreSpeechSubtypeAudioRecording Failed_kCSDiagnosticReporterVoiceTrigger APLeak_kCSDiagnostic ReporterVoice Trigger APStuck In Transition_ KCSDiagnostic ReporterVoiceTrigger SecondPass CompleteWatch DogFire_kCSF SelfLoggingMHUUIDKey_KCSF SelfLoggingSecondPass ResultKey_kCSPreferencesDomain_ KIOMasterPortDefault_KSSR SpeakerModelRetrainRequired_kSSRSpeakerModelUpdated_KSSRSpeaker RecognitionAudioProcessed DurationKey_ KSSRSpeaker RecognitionCombinationWeight_KSSRSpeakerRecognitionKnownUserPSRExpScores Key_KSSRSpeaker RecognitionKnownUser PSRScoresKey_ KSSRSpeakerRecognitionKnown UserSATExpScores Key_KSSRSpeaker RecognitionKnownUser SATScoresKey_kSSRSpeaker Recognition Known UserScoresKey_ KSSRSpeakerRecognition LowScore ThresholdKey_kSSRSpeakerRecognition NumEnrollmentUtterances_kSSRSpeaker Recognition NumSpeakerVector_ KSSRSpeaker Recognition PSRAdditionalContextKey_KSSR SpeakerRecognition SATAdditionalContextKey_KSSRSpeaker RecognitionSegmentCounterKey_ KSSRSpeakerRecognitionSegmentStartTimeKey_KSSRSpeakerVoice ProfileSync_kVTPreferencesCan Use Voice TriggerDuring Phone CallDidChangeDarwin Notification_ KVTPreferences Remote DarwinVoiceTriggerEnabled DidChangeDarwin Notification_kdebug_trace_log10_log10f_log2_log2f_mach_absolute_time_mach_continuous_time_mach_task_self__malloc_memcpy_memmove_memset_notify_cancel_notify_get_state_notify_post_notify_register_check_notify_register_dispatch_nwi_ifstate_get_flags_nwi_state_copy_
nwi_state_get_first_ifstate_nwi_state_get_notify_key_nwi_state_release_objc_alloc_objc_alloc_init_objc_autorelease_objc_autorelease PoolPop_objc_
autoreleasePool Push_objc_autoreleaseReturnValue_objc_copyWeak_objc_destroyWeak_objc_enumeration Mutation_objc_getClass_objc_getProperty_objc_initWeak_objc_
LoadWeakRetained_objc_msgSend_objc_msgSendSuper2_objc_msgSend_stret_objc_opt_class_objc_opt_isKind Of Class_objc_opt_new_objc_opt_responds To Selector_objc_release_
objc_retain_objc_retainAutorelease_objc_retainAutoreleaseReturnValue_objc_retainAutoreleasedReturnValue_objc_retainBlock_objc_setProperty_atomic_objc_setProperty_ transaction_create_realpath$DARWIN_EXTSN_remote_device_cancel_remote_device_copy_device_with_uuid_remote_device_copy_property_remote_device_copy_service_remote_ device_copy_unique_of_type_remote_device_copy_uuid_remote_device_get_type_remote_device_set_connected_callback_remote_device_set_disconnected_callback_remote_
nonatomic_copy_objc_store Strong_objc_storeWeak_objc_unsafeClaimAutoreleased ReturnValue_os_log_type_enabled_os_signpost_enabled_os_signpost_id_generate_os_
device_start_browsing_remote_device_type_get_description_rootless_check_datavault_flag_rootless_convert_to_datavault_rootless_mkdir_datavault_sandbox_init_with_
parameters_signal_strerror_task_info_vDSP_DFT_Execute_vDSP_DFT_zrop_CreateSetup_vDSP_biquadm_vDSP_biquadm_CreateSetup_vDSP_biquadm_DestroySetup_vDSP_biquadm_
ResetState_vDSP_conv_vDSP_create_fftsetup_vDSP_ctoz_vDSP_destroy_fftsetup_vDSP_fft_zip_vDSP_hamm_window_vDSP_meanv_vDSP_rmsqv_vDSP_svdiv_vDSP_sve_vDSP_svesq_vDSP_
vabs_vDSP_vadd_vDSP_vclip_vDSP_vclr_vDSP_vdiv_vDSP_vflt16_vDSP_vma_vDSP_vmma_vDSP_vmul_vDSP_vsadd_vDSP_vsma_vDSP_vsmul_vDSP_vsq_vDSP_vsub_vDSP_ztoc_vDSP_zvcma_
VDSP_zvma_vDSP_zvmags_vDSP_zvmul_vvsqrtf_xpc_activity_get_state_xpc_activity_register_xpc_activity_set_state_xpc_activity_should_defer_xpc_array_append_value_xpc_
array_apply_xpc_array_create_xpc_bool_create_xpc_bool_get_value_xpc_connection_activate_xpc_connection_cancel_xpc_connection_copy_entitlement_value_xpc_connection
_create_mach_service_xpc_connection_send_message_xpc_connection_send_message_with_reply_xpc_connection_send_message_with_reply_sync_xpc_connection_set_event_
handler_xpc_connection_set_target_queue_xpc_copy_clean_description_xpc_data_create_xpc_data_get_bytes_ptr_xpc_data_get_length_xpc_dictionary_apply_xpc_dictionary_
create_xpc_dictionary_create_reply_xpc_dictionary_get_array_xpc_dictionary_get_bool_xpc_dictionary_get_dictionary_xpc_dictionary_get_double_xpc_dictionary_get_
int64_xpc_dictionary_get_string_xpc_dictionary_get_uint64_xpc_dictionary_get_value_xpc_dictionary_set_bool_xpc_dictionary_set_double_xpc_dictionary_set_int64_xpc_ dictionary_set_string_xpc_dictionary_set_uint64_xpc_dictionary_set_value_xpc_double_create_xpc_double_get_value_xpc_file_transfer_create_with_path_xpc_get_type_ xpc_int64_create_xpc_int64_get_value_xpc_remote_connection_activate_xpc_remote_connection_cancel_xpc_remote_connection_create_with_remote_service_xpc_remote_ connection_send_message_xpc_remote_connection_send_message_with_reply_xpc_remote_connection_set_event_handler_xpc_string_create_xpc_string_get_string_ptr_xpc_
uint64_create_xpc_uint64_get_value__NSConcreteGlobalBlock_CoreEmbedded SpeechRecognizerTaskBetoDictation_CoreEmbedded SpeechRecognizerTaskBeto_ CoreEmbedded SpeechRecognizerTaskWebSearch_CoreEmbeddedSpeechRecognizerTaskVoiceMail_CoreEmbeddedSpeechRecognizerTaskTshot_
CoreEmbeddedSpeechRecognizerTaskDictation___CFConstantStringClass Reference_OBJC_CLASS_$_NSConstant Dictionary_OBJC_CLASS_$_NSConstantFloatNumber_OBJC_CLASS_$_ NSConstantIntegerNumber_OBJC_CLASS_$_NSConstantDouble Number_OBJC_CLASS_$_NSConstantArray_OBJC_CLASS_$_CSUtils_OBJC_CLASS_$_CSAsset_OBJC_CLASS_$_ AVVCContextSettings_OBJC_CLASS_$_AVVCStartRecordSettings_OBJC_CLASS_$_AVVCAudioBuffer_OBJC_CLASS_$_CSAudioRecordContext_OBJC_CLASS_$_NSHashTable_OBJC_CLASS_$_ NSNumber_OBJC_CLASS_$_NSData_OBJC_CLASS_$_NSFileManager_OBJC_CLASS_$_NSDictionary_OBJC_CLASS_$_CSAudioChunk_OBJC_CLASS_$_NSString_OBJC_CLASS_$_MAAsset_OBJC_CLASS_ $_NSArray_OBJC_CLASS_$_CSDispatch Group_OBJC_CLASS_$_NSUUID_OBJC_CLASS_$_NSError_OBJC_CLASS_$_NSMutableString_OBJC_CLASS_$_SSR Voice ProfileManager_OBJC_CLASS_$_
NSMutableArray_OBJC_CLASS_$_CSFPreferences_OBJC_CLASS_$_NSMutable Dictionary_OBJC_CLASS_$_SSREncryptedAudioFileReader_OBJC_CLASS_$_
CSFAudioStreamBasicDescriptionFactory_OBJC_CLASS_$_CSAudioCircularBuffer_OBJC_CLASS_$_CSConfig_OBJC_CLASS_$_CSAudio TimeConverter Pool_OBJC_CLASS_$_ CSVoiceTriggerFirstPassConfigDecoder_OBJC_CLASS_$_CSKeywordAnalyzerNDAPI_OBJC_CLASS_$_SHCustomCatalog_OBJC_CLASS_ $ _SHSignature_OBJC_CLASS_ $_SHMediaItem_OBJC_CLASS
$_NSURL_OBJC_CLASS_$_NSDateFormatter_OBJC_CLASS_$_NSLocale_OBJC_CLASS_$_NSDate_OBJC_CLASS_$_NSMutableData_OBJC_CLASS_$_VTPreferences_OBJC_CLASS_$_CSFTimeUtils_
OBJC_CLASS_$_NSMutableOrderedSet_OBJC_CLASS_$_NSWorkspace_OBJC_CLASS_$_CSDarwinVoiceTriggerEventInfoProvider_OBJC_CLASS_$_CSFVoice TriggerEventInfoSelfLogger_OBJC_
CLASS $ SSRAESKeyManager_OBJC_CLASS_$_SSRUtils_OBJC_CLASS_$_AFPreferences_OBJC_CLASS_$_NSMutableSet_OBJC_CLASS_$_CSReusableBufferPoolConfiguration_OBJC_CLASS_$_ CSReusableBuffer Pool_OBJC_CLASS_$_AVVoiceController_OBJC_CLASS_$_AVVCPrepareRecordSettings_OBJC_CLASS_$_CSDiagnosticReporter_OBJC_CLASS_$_AVVCDuckSettings_OBJC_
CLASS_$_AVVCDuckOverride_OBJC_CLASS_$_AVVCConfigureAlertBehaviorSettings_OBJC_CLASS_$_CSAudioChunk ForTV_OBJC_CLASS_$_CSAudio Decoder_OBJC_CLASS_$_ CSFLPCMTypeConverter_OBJC_CLASS_$_NSDistributedNotificationCenter_OBJC_CLASS_$_AFMyriadContext_OBJC_CLASS_$_AFMyriad PerceptualAudioHash_OBJC_CLASS_$_
SSRVoiceProfile Retraining Context_OBJC_CLASS_$_NSXPCInterface_OBJC_CLASS_$_CSVoiceTrigger SecondPassConfigDecoder_OBJC_CLASS_$_CSPower Logger_OBJC_CLASS_$_ CSPhraseDetector_OBJC_CLASS_$_SSRSpeaker RecognitionContext_OBJC_CLASS_$_SSRSpeaker RecognitionController_OBJC_CLASS_$_AFAnalytics_OBJC_CLASS_$_
CSPlainAudioFileWriter_OBJC_CLASS_$_CSAudioFileManager_OBJC_CLASS_$_CSKeywordAnalyzer NDEAPIResult_OBJC_CLASS_$_CSBeepCanceller_OBJC_CLASS_$_CSAudioZeroCounter_ OBJC_CLASS_$_CSFAudio MetricsSelfLogger_OBJC_CLASS_$_CSKeyword AnalyzerNDEAPI_OBJC_CLASS_$_AVVoice
TriggerClient_OBJC_CLASS_$_NSSet_OBJC_CLASS_$_NSNotificationCenter
_OBJC_CLASS_$_NSXPCListener_OBJC_CLASS_$_MHSchemaMHClientEvent_OBJC_CLASS_$_SISchemaUUID_OBJC_CLASS_$_MHSchema MHClientEventMetadata_OBJC_CLASS_$_
MHSchemaMHStatisticDistribution Info_OBJC_CLASS_$_MHSchemaMHEndpointer AccessibleContext_OBJC_CLASS_$_AssistantSiriAnalytics_OBJC_CLASS_$_MHSchemaMHEndpoint Detected _OBJC_CLASS_$_AFInstanceContext_OBJC_CLASS_$_MHSchemaMHEndpointLatency InfoReported_OBJC_CLASS_$_NSMapTable_OBJC_CLASS_$_NSExpression_OBJC_CLASS_$_ SNAudioStreamAnalyzer_OBJC_CLASS_$_SNDetectSpeechUtterance Request_OBJC_CLASS_$_AVAudioPCMBuffer_OBJC_CLASS_$_MHSchemaMHEndpointerTimeoutMetadata_OBJC_CLASS_$_
CSAudioTimeConverter_OBJC_CLASS_$_LBLocalSpeechRecognizerClient_OBJC_CLASS_$_CSAudioZeroFilter_OBJC_CLASS_$_NSProcess Info_OBJC_CLASS_$_AVAudioFormat_OBJC_CLASS_$_
MAAssetQuery_OBJC_CLASS_$_MADownloadOptions_OBJC_CLASS_$_CSMobileAssetVersions_OBJC_CLASS_$_VTBlob Builder_OBJC_CLASS_$_NSPredicate_OBJC_CLASS_$_ NSRegularExpression_OBJC_CLASS_$_AFMultiUserConnection_OBJC_CLASS_$_AFVoiceIdScoreCard_OBJC_CLASS_$_MHSchema MHSpeakerFalse TriggerMitigated_OBJC_CLASS_$_ NSJSONSerialization_OBJC_CLASS_$_DESRecordStore_OBJC_CLASS_$_CSOSTransaction_OBJC_CLASS_$__EARSpeechRecognizer_OBJC_CLASS_$_NSUserDefaults_OBJC_CLASS_$_ AFMyriadGoodnessScoreOverrideState_OBJC_CLASS_$_AFSiriActivationConnection_OBJC_CLASS_$_CSContinuous Voice TriggerConfigDecoder_OBJC_CLASS_$_
CSADPPreventStandbyAssertion_OBJC_CLASS_$_AFUIApplicationSiriTaskDeliverer_OBJC_CLASS_$_AFSiriTaskmaster_OBJC_CLASS_$_AFSiriDebugUIRequest_OBJC_CLASS_$_
MHSchemaMHEndpoint Delay Context_OBJC_CLASS_$_SISchemaUEIUserSpeaking Context_OBJC_CLASS_$_SISchemaUEIUserSpeakingStarted_OBJC_CLASS_$_SISchemaUEIUserSpeaking Ended_ OBJC_CLASS_$_CoreEmbedded SpeechRecognizer_OBJC_CLASS_$_CESRAssetConfig_OBJC_CLASS_$_LBLocalSpeech RecognitionSettings_OBJC_CLASS_$_CESRSpeech Parameters_OBJC_CLASS_
$_NSRunLoop__objc_empty_cache_OBJC_CLASS_$_NSObject_OBJC_METACLASS_$_NSObject_OBJC_METACLASS_$_CSPolicy_OBJC_CLASS_$_CSPolicy__mh_execute_headerÀqZZȧa(
ABCDEFGHIJKLMNOPQRSTUVWXYZ [\]^_`abcdefghijklmnopq_mh_execute_header_AFLanguageCode DidChangeDarwin Notification_AFMachAbsolute Time AddTimeInterval_ AFPreferences AssistantEnabled_AFSiriActivationHoneycomb Device VoiceTrigger_AFSiriActivationServiceGetPort_AFSiriActivationUser InfoKey_ AFSiriActivation VoiceKeyword Detected_AFSiriActivation Voice TriggerActivate_AFSiriActivation Voice Trigger Prewarm_AFUserIdentityClassficationGetName_ ASAttributeCompatibilityVersion_ASAttributeContentVersion_AVAudio Session PortDisplayPort_AVEncoderBitRateKey_AVFormatIDKey_AVLinear PCMBitDepthKey_ AVLinear PCMISFloat Key_AVLinear PCMIsNonInterleaved_AVNumberOfChannels Key_AVSampleRateConverterAlgorithmKey_AVSampleRate ConverterAlgorithm_Mastering_AVSampleRateKey _AVVoice Activation Device IDKey_AVVoice ActivationModeKey_AVVoiceControllerBluetoothDoAPRoute_AVVoice ControllerMetricAudioSessionSetActiveTime_ AVVoiceControllerMetricAudio SessionSetInactive Time_AVVoiceControllerMetricDataBeginHostTime_AVVoiceControllerMetric DataEndHostTime_AnalyticsSendEventLazy_ AudioConverterReset_AudioConverterSetProperty_AudioDeviceDuck_AudioFileClose_AudioFileOpenURL_AudioObjectAddPropertyListenerBlock_AudioObjectGetPropertyData_
AudioComponentRegister_AudioConverterConvertComplexBuffer_AudioConverterDispose_AudioConverterFillComplexBuffer_AudioConverterGetProperty_Audio ConverterNew_
AudioObjectGetPropertyDataSize_AudioObjectHas Property_AudioObjectRemove PropertyListenerBlock_CC_SHA1_CC_SHA256_CFBooleanGetTypeID_CFBooleanGetValue_ CFDictionaryGetValue_CFGetTypeID_CFNotificationCenter AddObserver_CFNotificationCenterGetDarwin Notify Center_CFNotificationCenterPostNotification_ CFNotificationCenter RemoveObserver_CFRelease CFRunLoopAddSource_CFRunLoopGetCurrent_CFRunLoopGetMain_CF RunLoop RemoveSource_CF StringCreateWithCString_ CFStringGetTypeID_CSHas AOP_CSI SASMacWithAOP_CSIS Apple Silicon Mac_CSIs BridgeOS_CSISCommunalDevice_CSIsHorseman_CSIsHorsemanJunior_CSISIOS_CSIs IPad_CSIsIPhone_ CSIsInternalBuild_CSIsMac_CSISOSX_CSISTV_CSISTorpedo_CSISWatch_CSLogContextFacilityCoreSpeech_CSLogInitIfNeeded_CSMach Absolute Time GetTimeInterval_ CSMachAbsolute Time Subtract Time Interval_CSSafe SetOutErrorWithNSError_CSShould CensorSpeech_Core EmbeddedSpeechRecognizerInstanceUUIDInteractive_ CoreEmbeddedSpeechRecognizerSourceAssistant_Core EmbeddedSpeechRecognizerSource Dictation_CoreEmbedded SpeechRecognizerTaskBeto_ CoreEmbedded SpeechRecognizerTaskBeto Dictation_Core Embedded SpeechRecognizerTaskDictation_CoreEmbedded SpeechRecognizerTaskSearchOrMessaging_ CoreEmbedded SpeechRecognizerTaskSiriDictation_Core Embedded SpeechRecognizerTaskTshot_Core EmbeddedSpeechRecognizerTaskVoiceMail_ CoreEmbedded SpeechRecognizerTaskWebSearch_ExtAudioFileCreateWithURL_ExtAudioFileDispose_ExtAudioFileGetProperty_ExtAudioFileOpenURL_ExtAudioFileRead_ IONotification Port Destroy_IONotification PortGetRun LoopSource_10ObjectRelease_IOPMAssertionCreateWithDescription_IOPMAssertionCreateWithName__ IOPMAssertion Declare NotificationEvent_IOPMAssertionRelease_IOPMAssertionSetProperty_IOPMConnection AcknowledgeEvent_IOPMConnectionCreate_IOPMConnectionRelease_
ExtAudioFileSeek_ExtAudioFileSetProperty_ExtAudioFileWrapAudioFileID_ExtAudioFileWrite_IOAllowPowerChange_IOMasterPort_IONotification PortCreate_
IOPMConnectionSetDispatchQueue_IOPMConnectionSetNotification_IOPMISADarkWake_IOPMISASleep_IOPMI SAUserWake_IOPSGetTimeRemainingEstimate_ IOPSNotificationCreateRunLoopSource_IORegisterForSystem Power_IORegistryEntryCreateCFProperty_IORegistryEntry FromPath_IOService AddInterestNotification_ IOServiceGetMatchingService_1OServiceMatching_IOServiceNameMatching_LBLocalSpeechService Name _MKBDeviceUnlocked Since Boot_MKBGetDeviceLockState_NSClassFromString_ NSFileProtectionComplete Unless Open_NSFileProtectionComplete UntilFirstUser Authentication_NSFileProtectionKey_NSLocalizedDescriptionKey_NSOSStatusErrorDomain_ NSStringFromClass_NSURLCreationDateKey_NSURLISDirectory Key_NSURLNameKey_NSWorkspace Session Did BecomeActive Notification_ NSWorkspaceSession Did ResignActive Notification_OBJC_CLASS_$_AFAnalytics_OBJC_CLASS_$_AFInstanceContext_OBJC_CLASS_$_AFMultiUserConnection_OBJC_CLASS_$_ AFMyriadContext_OBJC_CLASS_$_AFMyriad Goodness Score Override State_OBJC_CLASS_$_AFMyriad PerceptualAudio Hash_OBJC_CLASS_$_AFPreferences_OBJC_CLASS_$_ AFSiriActivationConnection_OBJC_CLASS_$_AFSiriDebugUI Request_OBJC_CLASS_$_AFSiriTaskmaster_OBJC_CLASS_$_AFUIApplicationSiriTaskDeliverer_OBJC_CLASS_$_ AFVoiceIdScoreCard_OBJC_CLASS_$_AVAudioFormat_OBJC_CLASS_$_AVAudioPCMBuffer_OBJC_CLASS_$_AVVCAudioBuffer_OBJC_CLASS_$_AVVCConfigureAlertBehavior Settings_OBJC_ CLASS $ AVVCContextSettings_OBJC_CLASS_$_AVVCDuckOverride_OBJC_CLASS_$_AVVCDuckSettings_OBJC_CLASS_$_AVVCPrepareRecordSettings_OBJC_CLASS_$_
AVVCStartRecordSettings_OBJC_CLASS_$_AVVoiceController_OBJC_CLASS_$_AVVoice TriggerClient_OBJC_CLASS_ $ _AssistantSiriAnalytics_OBJC_CLASS_$_CESRAssetConfig_OBJC_
CLASS_$_CESRSpeech Parameters_OBJC_CLASS_$_CSADPPreventStandbyAssertion_OBJC_CLASS_$_CSAsset_OBJC_CLASS_$_CSAudioChunk_OBJC_CLASS_$_CSAudioChunk ForTV_OBJC_CLASS_$_ CSAudioCircular Buffer_OBJC_CLASS_$_CSAudioDecoder_OBJC_CLASS_$_CSAudioFileManager_OBJC_CLASS_$_CSAudioRecordContext_OBJC_CLASS_$_CSAudioTime Converter_OBJC_CLASS_$ _CSAudioTimeConverterPool_OBJC_CLASS_$_CSAudioZeroCounter_OBJC_CLASS_$_CSAudioZeroFilter_OBJC_CLASS_$_CSBeepCanceller_OBJC_CLASS_$_CSConfig_OBJC_CLASS_$_ CSContinuousVoice TriggerConfigDecoder_OBJC_CLASS_$_CSDarwinVoiceTriggerEvent InfoProvider_OBJC_CLASS_$_CSDiagnosticReporter_OBJC_CLASS_$_CSDispatchGroup_OBJC_CLASS _$_CSFAudioMetricsSelfLogger_OBJC_CLASS_$_CSF Audio StreamBasicDescriptionFactory_OBJC_CLASS_$_CSFLPCMTypeConverter_OBJC_CLASS_$_CSF Preferences_OBJC_CLASS_$_ CSFTimeUtils_OBJC_CLASS_$_CSFVoiceTriggerEvent InfoSelfLogger_OBJC_CLASS_$_CSKeyword AnalyzerNDAPI_OBJC_CLASS_$_CSKeywordAnalyzerNDEAPI_OBJC_CLASS_$_ CSKeywordAnalyzerNDEAPIResult_OBJC_CLASS_$_CS MobileAssetVersions_OBJC_CLASS_$_CSOSTransaction_OBJC_CLASS_$_CSPhrase Detector_OBJC_CLASS_$_CSPlainAudioFileWriter_ OBJC_CLASS_$_CSPolicy_OBJC_CLASS_$_CSPower Logger_OBJC_CLASS_$_CSReusableBuffer Pool_OBJC_CLASS_$_CSReusableBufferPoolConfiguration_OBJC_CLASS_$_CSUtils_OBJC_CLASS_ $_CSVoiceTriggerFirstPassConfigDecoder_OBJC_CLASS_$_CSVoiceTriggerSecondPassConfigDecoder_OBJC_CLASS_$_CoreEmbedded SpeechRecognizer_OBJC_CLASS_$_DESRecordStore_ MADownloadOptions_OBJC_CLASS_$_MHSchemaMHClientEvent_OBJC_CLASS_$_MHSchemaMHClientEventMetadata_OBJC_CLASS_$_MHSchemaMHEndpoint DelayContext_OBJC_CLASS_$_
OBJC_CLASS_$_LBLocalSpeech RecognitionSettings_OBJC_CLASS_$_LBLocalSpeechRecognizerClient_OBJC_CLASS_$_MAAsset_OBJC_CLASS_$_MAAssetQuery_OBJC_CLASS_$_
MHSchemaMHEndpoint Detected_OBJC_CLASS_$_MHSchemaMHEndpointLatency InfoReported_OBJC_CLASS_$_MHSchemaMHEndpointerAccessibleContext_OBJC_CLASS_$_ MHSchemaMHEndpointerTimeoutMetadata_OBJC_CLASS_$_MHSchemaMHSpeakerFalse Trigger Mitigated_OBJC_CLASS_$_MHSchemaMHStatisticDistribution Info_OBJC_CLASS_$_NSArray_OBJC _CLASS_$_NSConstantArray_OBJC_CLASS_$_NSConstantDictionary_OBJC_CLASS_$_NSConstant Double Number_OBJC_CLASS_$_NSConstant Float Number_OBJC_CLASS_$_ NSConstantIntegerNumber_OBJC_CLASS_$_NSData_OBJC_CLASS_$_NSDate_OBJC_CLASS_$_NSDateFormatter_OBJC_CLASS_$_NSDictionary_OBJC_CLASS_$_
NSDistributed NotificationCenter_OBJC_CLASS_$_NSError_OBJC_CLASS_$_NSExpression_OBJC_CLASS_$_NSFile Manager_OBJC_CLASS_$_NSHashTable_OBJC_CLASS_$_ CLASS_$_NSMutableOrderedSet_OBJC_CLASS_$_NSMutableSet_OBJC_CLASS_$_NSMutableString_OBJC_CLASS_$_NSNotification Center_OBJC_CLASS_$_NSNumber_OBJC_CLASS_$_NSObject_ OBJC_CLASS_$_NSPredicate_OBJC_CLASS_$_NSProcessInfo_OBJC_CLASS_$_NSRegularExpression_OBJC_CLASS_$_NSRun Loop_OBJC_CLASS_$_NSSet_OBJC_CLASS_$_NSString_OBJC_CLASS_$_ NSURL_OBJC_CLASS_$_NSUUID_OBJC_CLASS_$_NSUserDefaults_OBJC_CLASS_$_NSWorkspace_OBJC_CLASS_$_NSXPC Interface_OBJC_CLASS_$_NSX PCListener_OBJC_CLASS_$_SHCustomCatalog
NSJSONSerialization_OBJC_CLASS_$_NSLocale_OBJC_CLASS_$_NSMapTable_OBJC_CLASS_$_NSMutableArray_OBJC_CLASS_$_NSMutableData_OBJC_CLASS_$_NSMutable Dictionary_OBJC_
_OBJC_CLASS_$_SHMediaItem_OBJC_CLASS_$_SHSignature_OBJC_CLASS_$_SISchemaUEIUserSpeakingContext_OBJC_CLASS_$_SISchemaUEIUserSpeakingEnded_OBJC_CLASS_$_SISchemaUEIUserSpeakingStarted_OBJC_CLASS_$_SISchemaUUID_OBJC_CLASS_$_SNAudioStreamAnalyzer_OBJC_CLASS_ $_ SNDetectSpeechUtteranceRequest_OBJC_CLASS_$_
SSRAESKeyManager_OBJC_CLASS_$_SSREncryptedAudioFileReader_OBJC_CLASS_$_SSRSpeakerRecognitionContext_OBJC_CLASS_$_SSRSpeaker RecognitionController_OBJC_CLASS_$_
SSRUtils_OBJC_CLASS_$_SSRVoice ProfileManager_OBJC_CLASS_$_SSRVoiceProfile RetrainingContext_OBJC_CLASS_$_VTBlob Builder_OBJC_CLASS_$_VTPreferences_OBJC_CLASS_$__ EARSpeechRecognizer_OBJC_METACLASS_$_CSPolicy_OBJC_METACLASS_$_NSObject_SHMediaItemTitle_SSRLogContextFacility CoreSpeech_SSRSpeakerRecognitionAssetArrayKey_ SSRSpeaker RecognitionAssetKey_SSRSpeaker RecognitionLocaleKey_SSRSpeakerRecognition MaxAudio DurationSecs_SSRSpeaker RecognitionOSTransactionRequired_ SSRSpeaker RecognitionProfileArrayKey_SSRSpeaker RecognitionSiriAppDomain_SSRSpeaker RecognitionSiriCCAppDomain_SSRSpeaker RecognitionSiriDebugAppDomain_ SSRSpeaker RecognitionStyleKey_SSRSpeaker RecognitionUsePayload ProfileKey_SSRSpeaker Recognition VTEvent InfoKey_SSRVoice RetrainingAssetKey_
SSRVoice RetrainingFilterToVoiceTriggerUtterances Key_SSR Voice RetrainingPayload ProfileKey_SSRVoiceRetrainingVoiceProfileKey_XPC_ACTIVITY_POST_INSTALL__Block_object_ base_commonILb1EE20__throw_length_errorEv__ZNSt11logic_errorC2EPKc__ZNSt12length_errorD1Ev__ZNSt12out_of_range D1Ev__ZSt9terminatev__ZTIST12length_error__
assign__Block_object_dispose__IDSCopyIDForDeviceUniqueID__MAClean V1Repository__NSConcreteGlobalBlock__NSConcreteStackBlock__Unwind_Resume__ZNKST3__120__vector_
ZTIST12out_of_range__ZTISt9exception__ZTVSt12length_error__ZTVSt12out_of_range__Zda Pv__ZdlPv__Znam__Znwm___CFConstantStringClass Reference___NSArray@__struct___
NSDictionary@__struct____chkstk_darwin___assert_rtn___bzero___cxa_allocate_exception___cxa_begin_catch___cxa_end_catch___cxa_free_exception___cxa_throw___error_ signal__dispatch_source_type_timer__objc_empty_cache__os_feature_enabled_impl__os_log_debug_impl__os_log_error_impl__os_log_fault_impl__os_log_impl__os_signpost_
exp10f___gxx_personality_v0___kCFBooleanFalse___kCFBoolean True___objc_personality_v0___stack_chk_fail___stack_chk_guard__dispatch_main_q__dispatch_source_type_
emit_with_name_impl__set_user_dir_suffix__sl_dlopen__xpc_error_connection_interrupted__xpc_error_connection_invalid__xpc_error_key_description__xpc_type_array__ xpc_type_bool__xpc_type_data__xpc_type_dictionary__xpc_type_double__xpc_type_error__xpc_type_int64__xpc_type_string__xpc_type_uint64_abort_report_np_bootstrap_ dispatch_get_global_queue_dispatch_group_create_dispatch_group_enter_dispatch_group_leave_dispatch_group_notify_dispatch_group_wait_dispatch_once_dispatch_queue_ attr_make_with_autorelease_frequency_dispatch_queue_attr_make_with_qos_class_dispatch_queue_create_dispatch_queue_create_with_target$V2_dispatch_resume_dispatch_
port_calloc_compression_decode_buffer_compression_encode_buffer_confstr_cosf_dispatch_after_dispatch_assert_queue $V2_dispatch_async_dispatch_async_and_wait_
semaphore_create_dispatch_semaphore_signal_dispatch_semaphore_wait_dispatch_set_target_queue_dispatch_source_cancel_dispatch_source_create_dispatch_source_set_ event_handler_dispatch_source_set_timer_dispatch_source_testcancel_dispatch_suspend_dispatch_sync_dispatch_time_dlopen_dlsym_exit_expf_fopen_fread_free_fseek_
getenv_getpwuid_getuid_KAFPreferencesDidChangeDarwin Notification_kCFAllocator Default_kCFBoolean True_kCFRunLoop Common Modes_kCFRun LoopDefaultMode_ KCSAudioSyncedFileSuffix_kCSDiagnosticReporterAudioDeliveryWatch DogFire_kCSDiagnosticReporter Audio DidStartWatchDogFire_
KCSDiagnostic ReporterAudioDidStopWatch DogFire_KCSDiagnosticReporterAudioResource Not Available_kCSDiagnosticReporterAudioStreamDeallocDuringStreaming_ KCSDiagnosticReporterConsectiveFalseFirstPass Triggers_kCSDiagnosticReporter RemoteCoreSpeechSubtypeAudio Recording Failed_kCSDiagnosticReporterVoice TriggerAPLeak_ KCSDiagnosticReporterVoice Trigger APStuck In Transition_KCSDiagnosticReporterVoiceTriggerSecondPassCompleteWatchDogFire_kCSFSelfLoggingMHUUIDKey_ KCSFSelfLoggingSecondPass ResultKey_kCSPreferences Domain_KIOMaster PortDefault_kSSRSpeaker ModelRetrainRequired_KSSRSpeaker ModelUpdated_ KSSRSpeakerRecognition AudioProcessed DurationKey_KSSRSpeaker Recognition CombinationWeight_KSSRSpeakerRecognitionKnown UserPSRExpScoresKey_ KSSRSpeakerRecognitionKnownUserPSRScoresKey_KSSRSpeaker RecognitionKnownUserSATExpScoresKey_KSSRSpeakerRecognitionKnown UserSATScoresKey_ KSSRSpeakerRecognitionKnownUserScoresKey_kSSRSpeaker Recognition LowScore Threshold Key_KSSRSpeaker RecognitionNumEnrollmentUtterances_ KSSRSpeakerRecognition NumSpeakerVector_KSSRSpeaker RecognitionPSRAdditionalContextKey_KSSRSpeaker RecognitionSATAdditionalContextKey_
KSSRSpeakerRecognitionSegmentCounterKey_KSSRSpeakerRecognitionSegmentStartTimeKey_KSSRSpeaker VoiceProfileSync_
KVTPreferencesCanUseVoice TriggerDuring Phone CallDidChangeDarwin Notification_kVTPreferences Remote DarwinVoiceTriggerEnabled DidChangeDarwin Notification_kdebug_trace_ log10_log10f_log2_Log2f_mach_absolute_time_mach_continuous_time_mach_task_self__malloc_memcpy_memmove_memset_notify_cancel_notify_get_state_notify_post_notify_ register_check_notify_register_dispatch_nwi_ifstate_get_flags_nwi_state_copy_nwi_state_get_first_ifstate_nwi_state_get_notify_key_nwi_state_release_objc_alloc_ enumerationMutation_objc_getClass_objc_getProperty_objc_initWeak_objc_loadWeakRetained_objc_msgSend_objc_msgSendSuper2_objc_msgSend_stret_objc_opt_class_objc_opt_ iskindOfClass_objc_opt_new_objc_opt_responds To Selector_objc_release_objc_retain_objc_retainAutorelease_objc_retainAuto release ReturnValue_objc_
objc_alloc_init_objc_autorelease_objc_autoreleasePoolPop_objc_autorelease PoolPush_objc_autorelease ReturnValue_objc_copyWeak_objc_destroyWeak_objc_
retainAutoreleased ReturnValue_objc_retainBlock_objc_setProperty_atomic_objc_setProperty_nonatomic_copy_objc_store Strong_objc_storeWeak_objc_
unsafeClaimAutoreleased ReturnValue_os_log_type_enabled_os_signpost_enabled_os_signpost_id_generate_os_transaction_create_realpath$DARWIN_EXTSN_remote_device_
cancel_remote_device_copy_device_with_uuid_remote_device_copy_property_remote_device_copy_service_remote_device_copy_unique_of_type_remote_device_copy_uuid_remote _device_get_type_remote_device_set_connected_callback_remote_device_set_disconnected_callback_remote_device_start_browsing_remote_device_type_get_description_ rootless_check_datavault_flag_rootless_convert_to_datavault_rootless_mkdir_datavault_sandbox_init_with_parameters_signal_strerror_task_info_vDSP_DFT_Execute_vDSP_
DFT_zrop_CreateSetup_vDSP_biquadm_vDSP_biquadm_CreateSetup_vDSP_biquadm_DestroySetup_vDSP_biquadm_ResetState_vDSP_conv_vDSP_create_fftsetup_vDSP_ctoz_vDSP_destroy
_fftsetup_vDSP_fft_zip_vDSP_hamm_window_vDSP_meanv_vDSP_rmsqv_vDSP_svdiv_vDSP_sve_vDSP_svesq_vDSP_vabs_vDSP_vadd_vDSP_vclip_vDSP_vclr_vDSP_vdiv_vDSP_vflt16_vDSP_
vma_vDSP_vmma_vDSP_vmul_vDSP_vsadd_vDSP_vsma_vDSP_vsmul_vDSP_vsq_vDSP_vsub_vDSP_ztoc_vDSP_zvcma_vDSP_zvma_vDSP_zvmags_vDSP_zvmul_vvsqrtf_xpc_activity_get_state_
xpc_activity_register_xpc_activity_set_state_xpc_activity_should_defer_xpc_array_append_value_xpc_array_apply_xpc_array_create_xpc_bool_create_xpc_bool_get_value_
xpc_connection_activate_xpc_connection_cancel_xpc_connection_copy_entitlement_value_xpc_connection_create_mach_service_xpc_connection_send_message_xpc_connection_
send_message_with_reply_xpc_connection_send_message_with_reply_sync_xpc_connection_set_event_handler_xpc_connection_set_target_queue_xpc_copy_clean_description_
xpc_data_create_xpc_data_get_bytes_ptr_xpc_data_get_length_xpc_dictionary_apply_xpc_dictionary_create_xpc_dictionary_create_reply_xpc_dictionary_get_array_xpc_
dictionary_get_bool_xpc_dictionary_get_dictionary_xpc_dictionary_get_double_xpc_dictionary_get_int64_xpc_dictionary_get_string_xpc_dictionary_get_uint64_xpc_
dictionary_get_value_xpc_dictionary_set_bool_xpc_dictionary_set_double_xpc_dictionary_set_int64_xpc_dictionary_set_string_xpc_dictionary_set_uint64_xpc_dictionary
_set_value_xpc_double_create_xpc_double_get_value_xpc_file_transfer_create_with_path_xpc_get_type_xpc_int64_create_xpc_int64_get_value_xpc_remote_connection_
activate_xpc_remote_connection_cancel_xpc_remote_connection_create_with_remote_service_xpc_remote_connection_send_message_xpc_remote_connection_send_message_with_
reply_xpc_remote_connection_set_event_handler_xpc_string_create_xpc_string_get_string_ptr_xpc_uint64_create_xpc_uint64_get_value


